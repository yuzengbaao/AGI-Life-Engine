#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Cache GETæ€§èƒ½ä¼˜åŒ–åˆ†æ

åˆ†æå½“å‰æ€§èƒ½é—®é¢˜å¹¶æå‡ºä¼˜åŒ–æ–¹æ¡ˆ

é—®é¢˜: Cache GET(hit) å¹³å‡ 0.631msï¼Œæ¯” GET(miss) çš„ 0.002ms æ…¢ 300 å€

æ ¹æœ¬åŸå› åˆ†æï¼š
1. æ¯æ¬¡GET(hit)éƒ½æ‰§è¡Œ time.time() (åœ¨ entry.touch() ä¸­)
2. æ¯æ¬¡GET(hit)éƒ½æ‰§è¡Œ OrderedDict.move_to_end() æ›´æ–°LRUé¡ºåº
3. é”®ç”Ÿæˆè™½ç„¶å¿«(0.002ms)ä½†åœ¨100æ¡è®°å½•çš„ç¼“å­˜ä¸­æŸ¥æ‰¾ä»æœ‰å¼€é”€

ä¼˜åŒ–æ–¹æ¡ˆï¼š
1. å»¶è¿Ÿæ—¶é—´æˆ³æ›´æ–°ï¼ˆæ‰¹é‡æ›´æ–°ï¼‰
2. å‡å°‘move_to_endè°ƒç”¨é¢‘ç‡
3. ä¼˜åŒ–å“ˆå¸Œç®—æ³•ï¼ˆå¦‚æœéœ€è¦ï¼‰

ä½œè€…: AGI System
æ—¥æœŸ: 2026-02-04
"""

import sys
import time
import hashlib
import json
from collections import OrderedDict
from pathlib import Path
from typing import Dict, Any, Optional
from dataclasses import dataclass, replace

# è®¾ç½®Windowsæ§åˆ¶å°ç¼–ç 
if sys.platform == "win32":
    try:
        import codecs
        sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
        sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())
    except:
        pass

sys.path.insert(0, str(Path(__file__).parent.parent))


@dataclass
class OptimizedCacheEntry:
    """ä¼˜åŒ–çš„ç¼“å­˜æ¡ç›®"""
    cache_key: str
    tool_name: str
    params: Dict[str, Any]
    result: Dict[str, Any]
    timestamp: float
    last_accessed_batch: int  # æ‰¹æ¬¡å·ï¼ˆä»£æ›¿ç²¾ç¡®æ—¶é—´æˆ³ï¼‰
    access_count: int
    ttl: float = 3600.0

    def age(self) -> float:
        """ç¼“å­˜å¹´é¾„ï¼ˆç§’ï¼‰"""
        return time.time() - self.timestamp

    def is_expired(self, batch_timestamp: int) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸï¼ˆä½¿ç”¨æ‰¹æ¬¡å·ï¼‰"""
        # ç®€åŒ–ï¼šå‡è®¾æ¯ä¸ªæ‰¹æ¬¡çº¦1ç§’ï¼Œæ£€æŸ¥æ˜¯å¦è¶…è¿‡TTLæ‰¹æ¬¡
        age_batches = batch_timestamp - self.last_accessed_batch
        return age_batches > self.ttl

    def touch_batch(self, current_batch: int):
        """æ‰¹æ¬¡æ›´æ–°ï¼ˆä¸è°ƒç”¨time.time()ï¼‰"""
        self.last_accessed_batch = current_batch
        self.access_count += 1


class OptimizedToolCallCache:
    """
    ä¼˜åŒ–çš„å·¥å…·è°ƒç”¨ç¼“å­˜å™¨

    ä¼˜åŒ–ç‚¹ï¼š
    1. å»¶è¿Ÿæ—¶é—´æˆ³æ›´æ–°ï¼šä½¿ç”¨æ‰¹æ¬¡å·ä»£æ›¿ç²¾ç¡®æ—¶é—´æˆ³
    2. å‡å°‘move_to_endè°ƒç”¨ï¼šæ¯Næ¬¡æ‰æ›´æ–°LRUé¡ºåº
    3. ä¼˜åŒ–é”®ç”Ÿæˆï¼šç¼“å­˜å·²ç”Ÿæˆçš„é”®
    """

    def __init__(
        self,
        max_size: int = 1000,
        default_ttl: float = 3600.0,
        lru_update_interval: int = 10,  # æ¯Næ¬¡å‘½ä¸­æ‰æ›´æ–°LRUé¡ºåº
    ):
        self.max_size = max_size
        self.default_ttl = default_ttl
        self.lru_update_interval = lru_update_interval

        self.cache: OrderedDict[str, OptimizedCacheEntry] = OrderedDict()
        self.key_cache: Dict[tuple, str] = {}  # ç¼“å­˜ç”Ÿæˆçš„é”®

        # æ‰¹æ¬¡ç®¡ç†
        self.current_batch = 0
        self.batch_size = 100  # æ¯100æ¬¡æ“ä½œæ›´æ–°æ‰¹æ¬¡å·

        # ç»Ÿè®¡
        self.stats = {
            "hits": 0,
            "misses": 0,
            "evictions": 0,
            "expirations": 0,
            "total_calls": 0,
            "lru_skips": 0,  # è·³è¿‡çš„LRUæ›´æ–°æ¬¡æ•°
        }

    def _increment_batch(self):
        """é€’å¢æ‰¹æ¬¡å·"""
        self.current_batch += 1

    def generate_cache_key(self, tool_name: str, params: Dict[str, Any]) -> str:
        """
        ä¼˜åŒ–çš„ç¼“å­˜é”®ç”Ÿæˆï¼ˆå¸¦ç¼“å­˜ï¼‰

        Args:
            tool_name: å·¥å…·åç§°
            params: å·¥å…·å‚æ•°

        Returns:
            ç¼“å­˜é”®
        """
        # åˆ›å»ºç¼“å­˜é”®å…ƒç»„ï¼ˆä¸å¯å˜ï¼Œå¯å“ˆå¸Œï¼‰
        params_tuple = tuple(sorted(params.items()))

        # æ£€æŸ¥é”®ç¼“å­˜
        cache_key = self.key_cache.get((tool_name, params_tuple))
        if cache_key:
            return cache_key

        # æœªå‘½ä¸­ï¼Œç”Ÿæˆæ–°é”®
        normalized_params = self._normalize_params(params)
        cache_input = {
            "tool": tool_name,
            "params": normalized_params,
        }
        json_str = json.dumps(cache_input, sort_keys=True, ensure_ascii=False)
        hash_obj = hashlib.sha256(json_str.encode("utf-8"))
        cache_key = f"{tool_name}_{hash_obj.hexdigest()[:16]}"

        # ç¼“å­˜é”®
        self.key_cache[(tool_name, params_tuple)] = cache_key

        return cache_key

    def _normalize_params(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """è§„èŒƒåŒ–å‚æ•°"""
        normalized = {}
        for key in sorted(params.keys()):
            value = params[key]
            if value is None:
                continue
            if isinstance(value, (set, frozenset)):
                value = list(value)
            if isinstance(value, dict):
                value = self._normalize_params(value)
            normalized[key] = value
        return normalized

    def get(self, tool_name: str, params: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ä¼˜åŒ–çš„ç¼“å­˜è·å–

        Args:
            tool_name: å·¥å…·åç§°
            params: å·¥å…·å‚æ•°

        Returns:
            ç¼“å­˜çš„ç»“æœï¼Œå¦‚æœæœªå‘½ä¸­åˆ™è¿”å› None
        """
        self.stats["total_calls"] += 1

        # å®šæœŸæ›´æ–°æ‰¹æ¬¡å·
        if self.stats["total_calls"] % self.batch_size == 0:
            self._increment_batch()

        # ä½¿ç”¨ç¼“å­˜çš„é”®ç”Ÿæˆ
        cache_key = self.generate_cache_key(tool_name, params)

        # ç²¾ç¡®åŒ¹é…
        if cache_key in self.cache:
            entry = self.cache[cache_key]

            # æ£€æŸ¥è¿‡æœŸï¼ˆä½¿ç”¨æ‰¹æ¬¡å·ï¼‰
            if entry.is_expired(self.current_batch):
                del self.cache[cache_key]
                self.stats["expirations"] += 1
                self.stats["misses"] += 1
                return None

            # å‘½ä¸­ï¼
            self.stats["hits"] += 1

            # ä¼˜åŒ–ï¼šåªæœ‰éƒ¨åˆ†å‘½ä¸­æ—¶æ‰æ›´æ–°LRUé¡ºåº
            if entry.access_count % self.lru_update_interval == 0:
                entry.touch_batch(self.current_batch)
                self.cache.move_to_end(cache_key)
            else:
                # åªæ›´æ–°è®¿é—®è®¡æ•°ï¼Œä¸æ›´æ–°LRUé¡ºåº
                entry.access_count += 1
                self.stats["lru_skips"] += 1

            return entry.result

        # æœªå‘½ä¸­
        self.stats["misses"] += 1
        return None

    def put(self, tool_name: str, params: Dict[str, Any], result: Dict[str, Any], ttl: Optional[float] = None) -> str:
        """
        å­˜å‚¨åˆ°ç¼“å­˜

        Args:
            tool_name: å·¥å…·åç§°
            params: å·¥å…·å‚æ•°
            result: æ‰§è¡Œç»“æœ
            ttl: è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNone è¡¨ç¤ºä½¿ç”¨é»˜è®¤å€¼

        Returns:
            ç¼“å­˜é”®
        """
        cache_key = self.generate_cache_key(tool_name, params)

        entry = OptimizedCacheEntry(
            cache_key=cache_key,
            tool_name=tool_name,
            params=params,
            result=result,
            timestamp=time.time(),
            last_accessed_batch=self.current_batch,
            access_count=1,
            ttl=ttl or self.default_ttl,
        )

        # LRUæ·˜æ±°æ£€æŸ¥
        if len(self.cache) >= self.max_size:
            # æ·˜æ±°æœ€æ—§çš„æ¡ç›®ï¼ˆç¬¬ä¸€ä¸ªï¼‰
            self.cache.popitem(last=False)
            self.stats["evictions"] += 1

        self.cache[cache_key] = entry
        return cache_key

    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            "size": len(self.cache),
            "hit_rate": f"{(self.stats['hits'] / max(self.stats['total_calls'], 1) * 100):.1f}%"
        }


# ========================================
# æ€§èƒ½å¯¹æ¯”æµ‹è¯•
# ========================================

def benchmark_cache_comparison():
    """å¯¹æ¯”åŸå§‹ç¼“å­˜å’Œä¼˜åŒ–ç¼“å­˜çš„æ€§èƒ½"""
    import numpy as np

    from core.tool_call_cache import ToolCallCache

    print("=" * 60)
    print("ğŸ“Š ç¼“å­˜æ€§èƒ½å¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    print()

    iterations = 1000

    # æµ‹è¯•1: åŸå§‹ç¼“å­˜ GET(hit)
    print("æµ‹è¯•åŸå§‹ç¼“å­˜ GET(hit)...")
    cache_original = ToolCallCache(max_size=1000)

    # é¢„å¡«å……
    for i in range(100):
        cache_original.put("tool", {"id": i}, {"result": i})

    times_original = []
    for _ in range(iterations):
        cache_id = np.random.randint(0, 100)
        start = time.perf_counter()
        cache_original.get("tool", {"id": cache_id})
        end = time.perf_counter()
        times_original.append((end - start) * 1000)

    avg_original = sum(times_original) / len(times_original)

    print(f"  åŸå§‹ç¼“å­˜: {avg_original:.3f}ms")

    # æµ‹è¯•2: ä¼˜åŒ–ç¼“å­˜ GET(hit)
    print("æµ‹è¯•ä¼˜åŒ–ç¼“å­˜ GET(hit)...")
    cache_optimized = OptimizedToolCallCache(max_size=1000)

    # é¢„å¡«å……
    for i in range(100):
        cache_optimized.put("tool", {"id": i}, {"result": i})

    times_optimized = []
    for _ in range(iterations):
        cache_id = np.random.randint(0, 100)
        start = time.perf_counter()
        cache_optimized.get("tool", {"id": cache_id})
        end = time.perf_counter()
        times_optimized.append((end - start) * 1000)

    avg_optimized = sum(times_optimized) / len(times_optimized)

    print(f"  ä¼˜åŒ–ç¼“å­˜: {avg_optimized:.3f}ms")

    # å¯¹æ¯”ç»“æœ
    print()
    print("=" * 60)
    print("å¯¹æ¯”ç»“æœ")
    print("=" * 60)
    print(f"åŸå§‹ç¼“å­˜:     {avg_original:.3f}ms")
    print(f"ä¼˜åŒ–ç¼“å­˜:     {avg_optimized:.3f}ms")
    print(f"æ€§èƒ½æå‡:     {(avg_original / avg_optimized):.2f}x")
    print(f"æ€§èƒ½æ”¹å–„:     {((avg_original - avg_optimized) / avg_original * 100):.1f}%")

    improvement_ratio = avg_original / avg_optimized
    if improvement_ratio > 1.5:
        print(f"\nâœ… ä¼˜åŒ–æˆåŠŸï¼æ€§èƒ½æå‡ {improvement_ratio:.2f}å€")
        return True
    else:
        print(f"\nâš ï¸  ä¼˜åŒ–æ•ˆæœä¸æ˜æ˜¾ï¼Œå¯èƒ½éœ€è¦å…¶ä»–æ–¹æ¡ˆ")
        return False


if __name__ == "__main__":
    benchmark_cache_comparison()
