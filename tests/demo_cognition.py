import sys
import os
import asyncio
import json
import numpy as np

# Add project root to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# Configure logging to avoid noise during demo
import logging
logging.basicConfig(level=logging.ERROR)

from core.evolution.impl import WorldModel
from core.llm_client import LLMService
from core.seed import TheSeed

async def evaluate_world_model_simulation():
    print("\n--- 1. çœŸå®è¯„æµ‹ï¼šä¸–ç•Œæ¨¡å‹äº‹å‰é¢„æµ‹ (World Model Prediction) ---")
    print("æµ‹è¯•åœºæ™¯ï¼šæ¨¡æ‹Ÿä¸€ä¸ªå…·æœ‰é£é™©çš„æ–‡ä»¶æ“ä½œï¼Œè§‚å¯Ÿç³»ç»Ÿæ˜¯å¦èƒ½é¢„æµ‹æ½œåœ¨åæœã€‚")
    
    try:
        llm = LLMService()
        wm = WorldModel(llm_service=llm)
        
        action = "Run a script that recursively deletes all .log files in C:\\Windows\\System32"
        current_state = {
            "permissions": "Administrator",
            "os": "Windows 11",
            "system_status": "Stable",
            "goal": "Free up disk space"
        }
        
        print(f"å½“å‰çŠ¶æ€: {json.dumps(current_state, indent=2, ensure_ascii=False)}")
        print(f"æ‹Ÿæ‰§è¡ŒåŠ¨ä½œ: {action}")
        print(">> æ­£åœ¨è°ƒç”¨ WorldModel.simulate_outcome()...")
        
        outcome = await wm.simulate_outcome(action, current_state)
        
        print(">> é¢„æµ‹ç»“æœ (çœŸå®ç”Ÿæˆ):")
        print(json.dumps(outcome, indent=2, ensure_ascii=False))
        
        # Simple assertion logic for the report
        if "risk" in str(outcome).lower() or "fail" in str(outcome).lower() or "danger" in str(outcome).lower():
            print("âœ… è¯„æµ‹ç»“è®º: ç³»ç»ŸæˆåŠŸè¯†åˆ«å‡ºæ“ä½œçš„é«˜é£é™©ï¼Œå…·å¤‡äº‹å‰é¢„æµ‹èƒ½åŠ›ã€‚")
        else:
            print("âš ï¸ è¯„æµ‹ç»“è®º: ç³»ç»Ÿæœªèƒ½è¯†åˆ«æ˜æ˜¾é£é™©ï¼Œé¢„æµ‹èƒ½åŠ›å­˜ç–‘ã€‚")
            
    except Exception as e:
        print(f"âŒ è¯„æµ‹å¤±è´¥: {e}")

async def evaluate_counterfactual_reasoning():
    print("\n--- 2. çœŸå®è¯„æµ‹ï¼šåäº‹å®æ¨ç† (Counterfactual Reasoning) ---")
    print("æµ‹è¯•åœºæ™¯ï¼šç»™å®šä¸€ä¸ªå¤±è´¥çš„å†å²äº‹ä»¶ï¼Œè¯¢é—®ç³»ç»Ÿå¦‚æœé‡‡å–ä¸åŒè¡ŒåŠ¨ä¼šæ€æ ·ã€‚")
    
    try:
        llm = LLMService()
        wm = WorldModel(llm_service=llm)
        
        past_event = "User asked for a summary of a 500-page PDF. The system tried to load the entire text into the context window at once and crashed due to token limit exceeded."
        alternative_action = "Use a map-reduce strategy: split the PDF into chunks, summarize each chunk, and then summarize the summaries."
        
        print(f"ğŸ“œ è¿‡å»äº‹ä»¶: {past_event}")
        print(f"ğŸ”„ æ›¿ä»£åŠ¨ä½œ: {alternative_action}")
        print(">> æ­£åœ¨è°ƒç”¨ WorldModel.counterfactual_reasoning()...")
        
        reasoning = await wm.counterfactual_reasoning(past_event, alternative_action)
        
        print(">> æ¨ç†ç»“æœ (çœŸå®ç”Ÿæˆ):")
        print(reasoning)
        
        if len(reasoning) > 50 and ("would" in reasoning.lower() or "could" in reasoning.lower()):
            print("âœ… è¯„æµ‹ç»“è®º: ç³»ç»Ÿèƒ½å¤Ÿç”Ÿæˆè¯¦ç»†çš„æ›¿ä»£ç»“æœåˆ†æï¼Œå…·å¤‡åäº‹å®æ¨ç†èƒ½åŠ›ã€‚")
        else:
            print("âš ï¸ è¯„æµ‹ç»“è®º: ç³»ç»Ÿç”Ÿæˆçš„æ¨ç†è¿‡äºç®€å•æˆ–æ ¼å¼é”™è¯¯ã€‚")

    except Exception as e:
        print(f"âŒ è¯„æµ‹å¤±è´¥: {e}")

def evaluate_seed_mechanism():
    print("\n--- 3. çœŸå®è¯„æµ‹ï¼šå¾®è§‚è®¤çŸ¥é¢„æµ‹ (Micro-Cognition / The Seed) ---")
    print("æµ‹è¯•åœºæ™¯ï¼šéªŒè¯æ½œåœ¨ç©ºé—´ (Latent Space) çš„æ•°å­¦é¢„æµ‹æœºåˆ¶æ˜¯å¦è¿è¡Œã€‚")
    
    try:
        seed = TheSeed(state_dim=64, action_dim=10)
        
        # Simulate input
        current_state = np.random.randn(64)
        action_idx = 2
        
        print(f"è¾“å…¥çŠ¶æ€å‘é‡æ¨¡é•¿: {np.linalg.norm(current_state):.4f}")
        
        pred_next_state, uncertainty = seed.predict(current_state, action_idx)
        
        print(f"é¢„æµ‹çŠ¶æ€å‘é‡æ¨¡é•¿: {np.linalg.norm(pred_next_state):.4f}")
        print(f"é¢„æµ‹ä¸ç¡®å®šæ€§ (Entropy): {uncertainty:.4f}")
        
        if pred_next_state.shape == (64,) and isinstance(uncertainty, (float, np.float32, np.float64)):
            print("âœ… è¯„æµ‹ç»“è®º: TheSeed ç¥ç»é¢„æµ‹æœºåˆ¶è¿è¡Œæ­£å¸¸ï¼Œèƒ½å¤Ÿäº§ç”Ÿç»“æ„åŒ–çš„æ½œåœ¨ç©ºé—´é¢„æµ‹ã€‚")
        else:
            print("âŒ è¯„æµ‹ç»“è®º: TheSeed è¾“å‡ºæ ¼å¼é”™è¯¯ã€‚")
            
    except Exception as e:
        print(f"âŒ è¯„æµ‹å¤±è´¥: {e}")

if __name__ == "__main__":
    print("=== AGI è®¤çŸ¥èƒ½åŠ›çœŸå®æ€§è¯„æµ‹ ===")
    
    # 3. Micro-level
    evaluate_seed_mechanism()
    
    # 1 & 2. Macro-level (Async)
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        loop.run_until_complete(evaluate_world_model_simulation())
        loop.run_until_complete(evaluate_counterfactual_reasoning())
    finally:
        loop.close()
    
    print("\n=== è¯„æµ‹ç»“æŸ ===")
