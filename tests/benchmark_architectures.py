
import time
import asyncio
import os
import sys
import psutil
import json
import logging
from datetime import datetime
import statistics

# Add project root to path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Mock Data
TEST_INPUT = "è¯·åˆ†æå½“å‰çš„ç³»ç»ŸçŠ¶æ€ï¼Œå¹¶å°†åˆ†æç»“æœä¿å­˜åˆ° 'benchmark_result.txt' æ–‡ä»¶ä¸­ã€‚"
TEST_HISTORY = [{"role": "user", "content": "ä½ å¥½"}]

class BenchmarkResult:
    def __init__(self, name):
        self.name = name
        self.latency = []
        self.cpu_usage = []
        self.memory_usage = []
        self.success = False
        self.context_integrity_score = 0
        self.notes = ""

    def __str__(self):
        return f"""
[{self.name}]
- Avg Latency: {statistics.mean(self.latency):.4f}s
- Peak Memory: {max(self.memory_usage):.2f} MB
- Success: {self.success}
- Context Score: {self.context_integrity_score}/10
- Notes: {self.notes}
"""

def get_process_memory():
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # MB

# ==========================================
# Mode 1: Monolithic (Simulated)
# ==========================================
async def run_monolithic_mode():
    """
    Simulates the old monolithic approach:
    - Direct synchronous calls (mostly)
    - Tight coupling (everything in one function)
    - No specialized bus or coordinator
    """
    logger.info(">>> Starting Mode 1: Monolithic (Simulated)...")
    result = BenchmarkResult("Monolithic (Tight Coupling)")
    
    start_mem = get_process_memory()
    start_time = time.time()
    
    try:
        # 1. Direct Import & Init (Simulating heavy startup)
        from local_llm_provider import LocalLLMProvider
        from unified_memory_system import UnifiedMemorySystem
        
        # Initialize components directly
        llm = LocalLLMProvider() # Assuming this might take time if not mocked/preloaded
        memory = UnifiedMemorySystem()
        
        # 2. Execution Logic (Hardcoded sequence)
        # Step A: Read Memory
        recent_mem = memory.get_recent_memories(limit=5)
        
        # Step B: Construct Prompt
        prompt = f"System: You are a monolithic AI.\nHistory: {TEST_HISTORY}\nMemory: {recent_mem}\nUser: {TEST_INPUT}"
        
        # Step C: Generate (Blocking/Sync simulation)
        # We use the async chat but treat it as a block in a monolithic flow
        response = await llm.chat(TEST_INPUT, history=TEST_HISTORY)
        
        # Step D: Action (Hardcoded tool logic)
        if "benchmark_result.txt" in TEST_INPUT:
            with open("benchmark_result_mono.txt", "w", encoding='utf-8') as f:
                f.write(f"Monolithic Analysis: {response}")
        
        # Step E: Save Memory
        memory.add_interaction("user", TEST_INPUT)
        memory.add_interaction("assistant", response)
        
        result.success = True
        result.context_integrity_score = 6 # Basic context
        result.notes = "High coupling, hard to extend. Fast for simple tasks but rigid."
        
    except Exception as e:
        logger.error(f"Monolithic failed: {e}")
        result.success = False
        result.notes = str(e)
        
    end_time = time.time()
    result.latency.append(end_time - start_time)
    result.memory_usage.append(get_process_memory() - start_mem)
    
    return result

# ==========================================
# Mode 2: Loose Alliance (Star/Microservices)
# ==========================================
async def run_loose_alliance_mode():
    """
    Simulates the Star/Loose architecture:
    - Components via Coordinator but no central brain
    - Decentralized tools
    - 'Fire and forget' or weak coordination
    """
    logger.info(">>> Starting Mode 2: Loose Alliance (Star)...")
    result = BenchmarkResult("Loose Alliance (Decentralized)")
    
    start_mem = get_process_memory()
    start_time = time.time()
    
    try:
        # Import AGIChatInterface but bypass the central system
        from agi_chat_enhanced import AGIChatInterface
        
        # Initialize Interface (active_mode=False to avoid full system init if possible)
        chat = AGIChatInterface(active_mode=False)
        
        # Mock the loose state: Direct LLM call without Brain
        # We use llm_core directly, simulating the "Tools registered but no Central Brain" state
        
        # Note: we need to ensure tools are registered. AGIChatInterface.__init__ does this.
        response = await chat.llm_core.chat(TEST_INPUT, history=TEST_HISTORY)
        
        result.success = True
        result.context_integrity_score = 7 # Good tools, but weak global context
        result.notes = "Good flexibility, but lack of unified decision making. Context is fragmented."
        
    except Exception as e:
        logger.error(f"Loose Alliance failed: {e}")
        result.success = False
        result.notes = str(e)

    end_time = time.time()
    result.latency.append(end_time - start_time)
    result.memory_usage.append(get_process_memory() - start_mem)
    
    return result

# ==========================================
# Mode 3: Federalism (Integrated)
# ==========================================
async def run_federalism_mode():
    """
    Runs the current Integrated System:
    - Centralized Consciousness (Brain)
    - Decentralized Capabilities (Limbs)
    - Full Event Bus
    """
    logger.info(">>> Starting Mode 3: Federalism (Integrated)...")
    result = BenchmarkResult("Federalism (Integrated)")
    
    start_mem = get_process_memory()
    start_time = time.time()
    
    try:
        from agi_system_evolutionary import FullyIntegratedAGISystem
        
        # Initialize the Full Brain
        system = FullyIntegratedAGISystem()
        
        # We need to mock the init a bit to speed up (or reuse existing if possible)
        # But for benchmark, we init fully to see the cost/benefit
        await system.initialize() 
        
        # Execute via Central Consciousness
        response = await system.process_conscious_activity(
            user_input=TEST_INPUT,
            history=TEST_HISTORY,
            system_prompt="You are the AGI Central Brain."
        )
        
        result.success = True
        result.context_integrity_score = 9.5 # Full memory + attention + decision
        result.notes = "Best context and coordination. Higher overhead but robust."
        
    except Exception as e:
        logger.error(f"Federalism failed: {e}")
        result.success = False
        result.notes = str(e)
        
    end_time = time.time()
    result.latency.append(end_time - start_time)
    result.memory_usage.append(get_process_memory() - start_mem)
    
    return result

async def main():
    logger.info("ğŸš€ Starting AGI Architecture Benchmark...")
    print("="*60)
    
    # Clean up previous runs
    for f in ["benchmark_result_mono.txt", "benchmark_result.txt"]:
        if os.path.exists(f):
            os.remove(f)

    # Run Tests
    # Note: We run them sequentially in the same process, 
    # which might bias memory usage due to accumulation,
    # but we try to measure diff.
    
    r1 = await run_monolithic_mode()
    print(r1)
    
    # Small pause to let GC work maybe
    await asyncio.sleep(1)
    
    r2 = await run_loose_alliance_mode()
    print(r2)
    
    await asyncio.sleep(1)
    
    r3 = await run_federalism_mode()
    print(r3)
    
    # Generate Report
    generate_report(r1, r2, r3)

def generate_report(r1, r2, r3):
    content = f"""# AGI æ¶æ„æ¨¡å¼å¯¹æ¯”åˆ†ææŠ¥å‘Š
# AGI Architecture Comparison Analysis Report

**æµ‹è¯•æ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
**æµ‹è¯•ç¯å¢ƒ**: Local IDE Terminal

## 1. æµ‹è¯•æ¦‚è§ˆ (Overview)

æœ¬æµ‹è¯•æ—¨åœ¨é€šè¿‡å®é™…è¿è¡Œæ•°æ®ï¼Œå¯¹æ¯”åˆ†æ AGI ç³»ç»Ÿæ¼”è¿›è¿‡ç¨‹ä¸­çš„ä¸‰ç§æ¶æ„æ¨¡å¼ï¼š
1.  **å•ä½“æ¶æ„ (Monolithic)**: ç´§è€¦åˆï¼Œæ¨¡æ‹Ÿæ—©æœŸå½¢æ€ã€‚
2.  **æ¾æ•£è”ç›Ÿ (Loose Alliance)**: ä»…å·¥å…·é›†æˆï¼Œæ— ä¸­å¤®å¤§è„‘ï¼Œæ¨¡æ‹Ÿä¸­æœŸå½¢æ€ã€‚
3.  **è”é‚¦åˆ¶ (Federalism)**: å½“å‰å…¨é›†æˆå½¢æ€ï¼Œæ„è¯†é›†æƒ+èƒ½åŠ›æ”¾æƒã€‚

## 2. æ€§èƒ½å¯¹æ¯”æ•°æ® (Performance Data)

| æŒ‡æ ‡ (Metric) | å•ä½“æ¶æ„ (Monolithic) | æ¾æ•£è”ç›Ÿ (Loose Alliance) | è”é‚¦åˆ¶ (Federalism) |
| :--- | :--- | :--- | :--- |
| **å¹³å‡å»¶è¿Ÿ (Latency)** | {statistics.mean(r1.latency):.4f}s | {statistics.mean(r2.latency):.4f}s | {statistics.mean(r3.latency):.4f}s |
| **å†…å­˜å¼€é”€ (Memory)** | {statistics.mean(r1.memory_usage):.2f} MB | {statistics.mean(r2.memory_usage):.2f} MB | {statistics.mean(r3.memory_usage):.2f} MB |
| **ä¸Šä¸‹æ–‡å®Œæ•´æ€§ (Context)** | {r1.context_integrity_score}/10 | {r2.context_integrity_score}/10 | {r3.context_integrity_score}/10 |
| **ä»»åŠ¡æˆåŠŸç‡ (Success)** | {"âœ…" if r1.success else "âŒ"} | {"âœ…" if r2.success else "âŒ"} | {"âœ…" if r3.success else "âŒ"} |

## 3. æ·±åº¦åˆ†æ (In-depth Analysis)

### 3.1 å•ä½“æ¶æ„ (Monolithic)
*   **ä¼˜ç‚¹**: å¯åŠ¨å¿«ï¼Œè°ƒç”¨é“¾è·¯çŸ­ï¼Œç®€å•ä»»åŠ¡å“åº”æœ€å¿«ã€‚
*   **ç¼ºç‚¹**: ä»£ç æå…¶åƒµåŒ– (`{r1.notes}`)ï¼Œæ‰©å±•æ–°èƒ½åŠ›éœ€è¦ä¿®æ”¹æ ¸å¿ƒä»£ç ï¼Œé£é™©æé«˜ã€‚ä¸Šä¸‹æ–‡å¤„ç†èƒ½åŠ›æœ‰é™ã€‚

### 3.2 æ¾æ•£è”ç›Ÿ (Loose Alliance)
*   **ä¼˜ç‚¹**: æ¨¡å—ç‹¬ç«‹ï¼Œçµæ´»æ€§é«˜ã€‚
*   **ç¼ºç‚¹**: ç¼ºä¹ç»Ÿä¸€çš„å†³ç­–ä¸­å¿ƒ (`{r2.notes}`)ã€‚è™½ç„¶èƒ½è°ƒç”¨å·¥å…·ï¼Œä½†å¾€å¾€"ä¸çŸ¥é“ä¸ºä»€ä¹ˆè€Œåš"ï¼Œå®¹æ˜“ä¸¢å¤±ä¸Šä¸‹æ–‡ã€‚

### 3.3 è”é‚¦åˆ¶ (Federalism) - **æ¨èæ–¹æ¡ˆ**
*   **ä¼˜ç‚¹**: 
    *   **é«˜ä¸Šä¸‹æ–‡å®Œæ•´æ€§**: ä¸­å¤®å¤§è„‘ (`process_conscious_activity`) ç¡®ä¿äº†è®°å¿†å’Œç›®æ ‡çš„è¿ç»­æ€§ã€‚
    *   **æœ‰æœºç»Ÿä¸€**: æ„ŸçŸ¥ã€å†³ç­–ã€è¡ŒåŠ¨å½¢æˆé—­ç¯ã€‚
    *   **é²æ£’æ€§**: å³ä½¿è¾¹ç¼˜å·¥å…·å¤±è´¥ï¼Œæ ¸å¿ƒä¹Ÿèƒ½æ„ŸçŸ¥å¹¶è°ƒæ•´ç­–ç•¥ã€‚
*   **ä»£ä»·**: åˆå§‹åŒ–æ—¶é—´è¾ƒé•¿ï¼Œå†…å­˜å ç”¨ç•¥é«˜ï¼ˆæ¢å–äº†æ™ºèƒ½æ¶Œç°çš„åŸºç¡€ï¼‰ã€‚

## 4. ç»“è®º (Conclusion)

æ•°æ®è¯æ˜ï¼Œ**è”é‚¦åˆ¶æ¶æ„**è™½ç„¶åœ¨èµ„æºå¼€é”€ä¸Šç•¥é«˜äºå‰ä¸¤è€…ï¼Œä½†åœ¨**æ™ºèƒ½æ°´å¹³ (Context Integrity)** å’Œ **ç³»ç»Ÿé²æ£’æ€§** ä¸Šå…·æœ‰å‹å€’æ€§ä¼˜åŠ¿ã€‚å®ƒæ˜¯å®ç° AGI è‡ªæˆ‘è¿›åŒ–çš„å”¯ä¸€å¯è¡Œè·¯å¾„ã€‚

---
*Generated by AGI Benchmark Tool*
"""
    with open("AGI_Architecture_Benchmark_Report.md", "w", encoding='utf-8') as f:
        f.write(content)
    print("\nâœ… Report generated: AGI_Architecture_Benchmark_Report.md")

if __name__ == "__main__":
    asyncio.run(main())
