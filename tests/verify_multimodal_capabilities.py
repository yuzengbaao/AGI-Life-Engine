#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AGI Multimodal Capabilities Verification Script
AGI å¤šæ¨¡æ€èƒ½åŠ›çœŸå®æ€§éªŒè¯è„šæœ¬

åŠŸèƒ½:
1. éªŒè¯è§†è§‰æ„ŸçŸ¥ (æ‘„åƒå¤´)
2. éªŒè¯å¬è§‰æ„ŸçŸ¥ (éº¦å…‹é£ + Whisper ASR)
3. éªŒè¯è¡¨è¾¾èƒ½åŠ› (æ‰¬å£°å™¨ TTS)
4. éªŒè¯å¤šæ¨¡æ€èåˆé€»è¾‘ (Multimodal Fusion)
5. ç”Ÿæˆè¯„æµ‹æŠ¥å‘Šæ•°æ®

Author: AGI System
Date: 2025-12-03
"""

import sys
import os
import asyncio
import logging
import numpy as np
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from agi_chat_enhanced import AGIChatInterface
from multimodal_fusion import MultimodalFusion, ModalityFeature

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("MultimodalTest")

async def verify_multimodal():
    print("\n" + "="*60)
    print("ğŸ§ª AGI Multimodal Capabilities Verification (çœŸå®æ€§éªŒè¯)")
    print("="*60 + "\n")
    
    results = {
        "vision": {"status": "pending", "details": ""},
        "hearing": {"status": "pending", "details": ""},
        "speech": {"status": "pending", "details": ""},
        "fusion": {"status": "pending", "details": ""}
    }

    # 1. åˆå§‹åŒ– AGI Chat Interface
    print("ğŸ”„ Initializing AGI Interface (connecting to hardware)...")
    try:
        chat = AGIChatInterface()
        # æ¨¡æ‹Ÿåˆå§‹åŒ–ï¼Œå› ä¸ºæˆ‘ä»¬åªéœ€è¦è°ƒç”¨ handler
        # chat._initialize_system() # Constructor already calls this
        print("âœ… AGI Interface Initialized")
    except Exception as e:
        print(f"âŒ Failed to initialize AGI Interface: {e}")
        return

    # ---------------------------------------------------------
    # 2. æµ‹è¯•è§†è§‰ (Vision) - Capture Webcam
    # ---------------------------------------------------------
    print("\nğŸ‘ï¸ Testing Vision (Webcam)...")
    try:
        # å°è¯•æ‹ç…§
        vision_result = await chat._handle_capture_webcam(filename="test_vision_verify.jpg")
        
        if "error" in vision_result:
            print(f"âš ï¸ Vision Warning: {vision_result['error']}")
            results["vision"]["status"] = "failed_hardware"
            results["vision"]["details"] = vision_result['error']
        else:
            print(f"âœ… Vision Success: Captured {vision_result['file_path']} ({vision_result.get('resolution')})")
            results["vision"]["status"] = "success"
            results["vision"]["details"] = f"Captured resolution: {vision_result.get('resolution')}"
            
    except Exception as e:
        print(f"âŒ Vision Error: {e}")
        results["vision"]["status"] = "error"
        results["vision"]["details"] = str(e)

    # ---------------------------------------------------------
    # 3. æµ‹è¯•å¬è§‰ (Hearing) - Record Audio + ASR
    # ---------------------------------------------------------
    print("\nğŸ‘‚ Testing Hearing (Microphone + Whisper)...")
    try:
        # å½•åˆ¶ 2 ç§’
        audio_result = await chat._handle_record_audio(duration=2, filename="test_audio_verify.wav")
        
        if "error" in audio_result:
            print(f"âš ï¸ Hearing Warning: {audio_result['error']}")
            results["hearing"]["status"] = "failed_hardware"
            results["hearing"]["details"] = audio_result['error']
        else:
            print(f"âœ… Hearing Success: Recorded {audio_result['file_path']}")
            print(f"   Transcription: {audio_result.get('transcription')}")
            results["hearing"]["status"] = "success"
            results["hearing"]["details"] = f"ASR Result: {audio_result.get('transcription')}"

    except Exception as e:
        print(f"âŒ Hearing Error: {e}")
        results["hearing"]["status"] = "error"
        results["hearing"]["details"] = str(e)

    # ---------------------------------------------------------
    # 4. æµ‹è¯•è¡¨è¾¾ (Speech) - TTS
    # ---------------------------------------------------------
    print("\nğŸ‘„ Testing Speech (TTS)...")
    try:
        speech_result = await chat._handle_speak(text="Multimodal system verification in progress.")
        
        if "error" in speech_result:
            print(f"âš ï¸ Speech Warning: {speech_result['error']}")
            results["speech"]["status"] = "failed_hardware"
            results["speech"]["details"] = speech_result['error']
        else:
            print(f"âœ… Speech Success: Audio output triggered.")
            results["speech"]["status"] = "success"
            results["speech"]["details"] = "TTS Triggered"

    except Exception as e:
        print(f"âŒ Speech Error: {e}")
        results["speech"]["status"] = "error"
        results["speech"]["details"] = str(e)

    # ---------------------------------------------------------
    # 5. æµ‹è¯•èåˆ (Fusion) - Multimodal Logic
    # ---------------------------------------------------------
    print("\nğŸ§  Testing Multimodal Fusion Logic...")
    try:
        fusion = MultimodalFusion(unified_dim=128)
        
        # æ¨¡æ‹Ÿç‰¹å¾å‘é‡ (å› ä¸ºè¿™é‡Œæ²¡æœ‰åŠ è½½ CLIP ç­‰é‡å‹æ¨¡å‹)
        # å‡è®¾: è§†è§‰ç‰¹å¾ (2048ç»´), å¬è§‰ç‰¹å¾ (1024ç»´)
        vision_feat = ModalityFeature(
            modality="image",
            features=np.random.rand(2048).astype(np.float32),
            metadata={"source": "webcam"}
        )
        
        audio_feat = ModalityFeature(
            modality="audio",
            features=np.random.rand(1024).astype(np.float32),
            metadata={"source": "microphone"}
        )
        
        # æ‰§è¡Œèåˆ
        fused = fusion.fuse_modalities([vision_feat, audio_feat])
        
        print(f"âœ… Fusion Success: Unified Vector Shape {fused.unified_features.shape}")
        print(f"   Contributions: {fused.modality_contributions}")
        
        # æµ‹è¯•è·¨æ¨¡æ€å…³è” (Knowledge Graph Triple Generation)
        triples = fusion.generate_kg_triples([vision_feat, audio_feat])
        print(f"âœ… Knowledge Generation: Created {len(triples)} triples")
        for t in triples:
            print(f"   - {t.subject} {t.predicate} {t.object} (conf={t.confidence:.2f})")

        results["fusion"]["status"] = "success"
        results["fusion"]["details"] = f"Fused {len(fused.modality_contributions)} modalities. Generated {len(triples)} triples."

    except Exception as e:
        print(f"âŒ Fusion Error: {e}")
        results["fusion"]["status"] = "error"
        results["fusion"]["details"] = str(e)

    # ---------------------------------------------------------
    # Summary
    # ---------------------------------------------------------
    print("\n" + "="*60)
    print("ğŸ“Š Verification Summary")
    print("="*60)
    print(json.dumps(results, indent=2))
    
    # Save results for report generation
    with open("multimodal_test_results.json", "w") as f:
        json.dump(results, f, indent=2)

if __name__ == "__main__":
    asyncio.run(verify_multimodal())
