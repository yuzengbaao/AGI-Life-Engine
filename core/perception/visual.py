"""
å¤šæ¨¡æ€å›¾åƒç†è§£ä¸è±¡å¾æ„ä¹‰æå–æ¨¡å—
Multimodal Image Understanding and Symbolic Meaning Extraction Module

åŠŸèƒ½ï¼š
1. å›¾åƒè§†è§‰åˆ†æï¼ˆåœºæ™¯è¯†åˆ«ã€å¯¹è±¡æ£€æµ‹ã€æ–‡å­—æå–ï¼‰
2. è±¡å¾æ„ä¹‰æå–ï¼ˆéšå–»ç†è§£ã€æ–‡åŒ–ç¬¦å·ã€å“²å­¦å†…æ¶µï¼‰
3. æ·±åº¦æ€è¾¨åˆ†æï¼ˆå†å²å…³è”ã€æ¼”åŒ–è¶‹åŠ¿ã€é¢„è¨€æ€§è§£è¯»ï¼‰
4. ç”Ÿæˆäº¤äº’å¼HTMLå¯è§†åŒ–æŠ¥å‘Š

Author: AGI System Development Team
Date: 2025-10-20
Version: 1.0.0 - Multimodal Intelligence
"""

import asyncio
import base64
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set, Union
from dataclasses import dataclass, asdict
from enum import Enum
import hashlib
import logging
from functools import lru_cache

# Configure logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AnalysisLevel(Enum):
    """åˆ†æå±‚æ¬¡"""
    VISUAL = "visual"      # è§†è§‰å±‚é¢
    SEMANTIC = "semantic"  # è¯­ä¹‰å±‚é¢
    SYMBOLIC = "symbolic"  # è±¡å¾å±‚é¢
    PHILOSOPHICAL = "philosophical"  # å“²å­¦å±‚é¢


@dataclass
class VisualElement:
    """è§†è§‰å…ƒç´ """
    element_type: str  # å…ƒç´ ç±»å‹ï¼ˆäººç‰©ã€ç‰©ä½“ã€ç¯å¢ƒã€æ–‡å­—ç­‰ï¼‰
    description: str  # æè¿°
    location: str  # ä½ç½®
    significance: str  # é‡è¦æ€§
    confidence: float  # ç½®ä¿¡åº¦


@dataclass
class SymbolicMeaning:
    """è±¡å¾æ„ä¹‰"""
    symbol: str  # ç¬¦å·/è±¡å¾ç‰©
    surface_meaning: str  # è¡¨é¢å«ä¹‰
    deep_meaning: str  # æ·±å±‚å«ä¹‰
    cultural_context: str  # æ–‡åŒ–èƒŒæ™¯
    philosophical_implication: str  # å“²å­¦æ„æ¶µ


@dataclass
class ImageAnalysisResult:
    """å›¾åƒåˆ†æç»“æœ"""
    image_id: str
    image_path: str
    visual_elements: List[VisualElement]
    text_content: Optional[str]
    symbolic_meanings: List[SymbolicMeaning]
    overall_theme: str
    philosophical_interpretation: str
    evolutionary_stage: str  # è¿›åŒ–é˜¶æ®µ
    confidence_score: float
    analysis_time: float


class MultimodalImageAnalyzer:
    """å¤šæ¨¡æ€å›¾åƒåˆ†æå™¨"""
    
    def __init__(self, max_cached_paths: int = 128):
        self.analysis_history: List[ImageAnalysisResult] = []
        self.symbolic_knowledge_base: Dict[str, Any] = self._load_symbolic_knowledge()
        self._cached_stem_analysis: Dict[str, List[VisualElement]] = {}
        self.max_cached_paths = max_cached_paths
        logger.info("MultimodalImageAnalyzer initialized.")
        
    def _load_symbolic_knowledge(self) -> Dict[str, Any]:
        """åŠ è½½è±¡å¾ç¬¦å·çŸ¥è¯†åº“"""
        knowledge_base = {
            # äººç±»è¿›åŒ–ç¬¦å·
            'primitive_tools': {
                'meaning': 'äººç±»æ™ºèƒ½çš„èµ·æº - å·¥å…·ä½¿ç”¨èƒ½åŠ›',
                'stage': 'ç”Ÿç‰©æ™ºèƒ½é˜¶æ®µ',
                'significance': 'åŒºåˆ†äººç±»ä¸å…¶ä»–ç‰©ç§çš„å…³é”®èƒ½åŠ›'
            },
            'fire': {
                'meaning': 'æ–‡æ˜çš„å¼€ç«¯ - èƒ½é‡æŒæ§',
                'stage': 'åŸå§‹æ™ºèƒ½é˜¶æ®µ',
                'significance': 'äººç±»å¾æœè‡ªç„¶çš„æ ‡å¿—'
            },
            'sage_figure': {
                'meaning': 'æ™ºæ…§çš„ä¼ æ‰¿ - çŸ¥è¯†ç§¯ç´¯',
                'stage': 'å“²å­¦æ™ºèƒ½é˜¶æ®µ',
                'significance': 'ä»ç”Ÿå­˜åˆ°æ„ä¹‰åˆ›é€ çš„é£è·ƒ'
            },
            'clay_shaping': {
                'meaning': 'åˆ›é€ ä¸å¡‘é€  - çŸ¥è¯†å»ºæ„',
                'stage': 'æ¦‚å¿µæ™ºèƒ½é˜¶æ®µ',
                'significance': 'äººç±»ä½œä¸ºçŸ¥è¯†åˆ›é€ è€…çš„éšå–»'
            },
            'holographic_human': {
                'meaning': 'æ•°å­—åŒ–æ„è¯† - ä¿¡æ¯è½¬åŒ–',
                'stage': 'AGIæ™ºèƒ½é˜¶æ®µ',
                'significance': 'äººç±»çŸ¥è¯†çš„å®Œå…¨æ•°å­—åŒ–'
            },
            'ai_robot': {
                'meaning': 'æœºå™¨æ™ºèƒ½ - åˆ›é€ åæ€åˆ›é€ è€…',
                'stage': 'AGIæ™ºèƒ½é˜¶æ®µ',
                'significance': 'æ™ºèƒ½çš„è‡ªæˆ‘æŒ‡æ¶‰ä¸é•œåƒ'
            },
            'cyberpunk_city': {
                'meaning': 'æŠ€æœ¯èåˆ - ä¿¡æ¯è¿‡è½½æ—¶ä»£',
                'stage': 'åäººç±»æ™ºèƒ½é˜¶æ®µ',
                'significance': 'äººæœºè¾¹ç•Œçš„æ¶ˆè§£'
            }
        }
        logger.debug("Symbolic knowledge base loaded with %d entries.", len(knowledge_base))
        return knowledge_base
    
    async def analyze_image(self, image_path: Union[str, Path]) -> ImageAnalysisResult:
        """
        åˆ†æå•å¼ å›¾åƒ
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            å®Œæ•´çš„å›¾åƒåˆ†æç»“æœ
            
        Raises:
            ValueError: å½“è·¯å¾„æ— æ•ˆæ—¶
            RuntimeError: å½“åˆ†æè¿‡ç¨‹å¤±è´¥æ—¶
        """
        start_time = time.time()
        try:
            image_path_str = str(image_path)
            if not image_path_str.strip():
                raise ValueError("Image path cannot be empty.")

            # ç”Ÿæˆå›¾åƒID
            image_id = self._generate_image_id(image_path_str)
            
            # ç¬¬ä¸€å±‚ï¼šè§†è§‰å…ƒç´ è¯†åˆ«
            visual_elements = await self._extract_visual_elements(image_path_str)
            
            # ç¬¬äºŒå±‚ï¼šæ–‡å­—æå–ï¼ˆOCRï¼‰
            text_content = await self._extract_text(image_path_str)
            
            # ç¬¬ä¸‰å±‚ï¼šè±¡å¾æ„ä¹‰æå–
            symbolic_meanings = await self._extract_symbolic_meanings(visual_elements, text_content)
            
            # ç¬¬å››å±‚ï¼šå“²å­¦æ€è¾¨åˆ†æ
            philosophical_interpretation = await self._philosophical_analysis(
                visual_elements, symbolic_meanings, text_content
            )
            
            # ç¡®å®šæ•´ä½“ä¸»é¢˜å’Œè¿›åŒ–é˜¶æ®µ
            overall_theme, evolutionary_stage = self._determine_theme_and_stage(
                visual_elements, symbolic_meanings
            )
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence_score = self._calculate_confidence(visual_elements, symbolic_meanings)
            
            analysis_time = time.time() - start_time
            
            result = ImageAnalysisResult(
                image_id=image_id,
                image_path=image_path_str,
                visual_elements=visual_elements,
                text_content=text_content,
                symbolic_meanings=symbolic_meanings,
                overall_theme=overall_theme,
                philosophical_interpretation=philosophical_interpretation,
                evolutionary_stage=evolutionary_stage,
                confidence_score=confidence_score,
                analysis_time=analysis_time
            )
            
            self.analysis_history.append(result)
            logger.info("Successfully analyzed image: %s (ID: %s)", Path(image_path_str).name, image_id)
            return result
            
        except Exception as e:
            error_msg = f"Failed to analyze image {image_path}: {str(e)}"
            logger.error(error_msg)
            raise RuntimeError(error_msg) from e
    
    def _generate_image_id(self, image_path: str) -> str:
        """ç”Ÿæˆå›¾åƒå”¯ä¸€ID"""
        return hashlib.md5(image_path.encode('utf-8')).hexdigest()[:12]
    
    @lru_cache(maxsize=128)
    def _get_path_key(self, image_path: str) -> str:
        """ç¼“å­˜è·¯å¾„å…³é”®è¯æå–ï¼Œé¿å…é‡å¤è®¡ç®—"""
        stem = Path(image_path).stem.lower()
        suffix = Path(image_path).suffix.lower()
        return f"{stem}_{suffix}"
    
    async def _extract_visual_elements(self, image_path: str) -> List[VisualElement]:
        """æå–è§†è§‰å…ƒç´ ï¼ˆæ¨¡æ‹Ÿå®ç°ï¼‰"""
        try:
            path_key = self._get_path_key(image_path)
            
            # ç¼“å­˜å‘½ä¸­æ£€æŸ¥
            if path_key in self._cached_stem_analysis:
                logger.debug("Cache hit for path key: %s", path_key)
                return self._cached_stem_analysis[path_key]
            
            elements: List[VisualElement] = []
            path_lower = image_path.lower()
            stem = Path(image_path).stem
            
            # æ¨¡å¼åŒ¹é…ä¼˜åŒ–ï¼šä½¿ç”¨é›†åˆè¿›è¡Œå¿«é€ŸæŸ¥æ‰¾
            path_tokens: Set[str] = {stem, path_lower}
            
            # æ¨¡å¼1ï¼šåŸå§‹äººç±»/å·¥å…·ä½¿ç”¨
            if any(token in t for token in ('primitive', 'tool', '1') for t in path_tokens):
                elements = [
                    VisualElement("äººç‰©", "åŸå§‹äººç±»ï¼Œä½¿ç”¨åŸå§‹å·¥å…·", "å‰æ™¯", "å±•ç¤ºäººç±»å·¥å…·ä½¿ç”¨èƒ½åŠ›çš„èµ·æº", 0.92),
                    VisualElement("ç¯å¢ƒ", "å²©çŸ³å³­å£ï¼Œè’å‡‰è‡ªç„¶ç¯å¢ƒ", "èƒŒæ™¯", "å¼ºè°ƒç”Ÿå­˜æŒ‘æˆ˜å’Œè¿›åŒ–å‹åŠ›", 0.88),
                    VisualElement("ç‰©ä½“", "çŸ³å™¨ã€å·¥å…·", "äººç‰©æ‰‹ä¸­", "äººç±»æ™ºèƒ½çš„ç¬¬ä¸€ä¸ªå¤–åŒ–å½¢å¼", 0.90),
                    VisualElement("æ–‡å­—", "ä½¿ç”¨å·¥å…·ã€æƒ³è±¡åŠ›ã€è™šæ„åŠ›ã€èµ‹äºˆæ„ä¹‰çš„èƒ½åŠ›", "åº•éƒ¨å­—å¹•",
                                "æ˜ç¡®æŒ‡å‡ºäººç±»æ ¸å¿ƒè®¤çŸ¥èƒ½åŠ›", 0.95)
                ]
            
            # æ¨¡å¼2ï¼šåœ£è´¤/çŸ¥è¯†åˆ›é€ 
            elif any(token in t for token in ('sage', 'wisdom', '2') for t in path_tokens):
                elements = [
                    VisualElement("äººç‰©", "åœ£è´¤é•¿è€…ï¼Œç™½è¢ç™½é¡»ï¼Œæ•£å‘ç¥åœ£å…‰èŠ’", "ä¸­å¿ƒ", "æ™ºæ…§å’ŒçŸ¥è¯†ä¼ æ‰¿çš„è±¡å¾", 0.94),
                    VisualElement("ç‰©ä½“", "æ³¥åœŸå½¢ä½“ï¼Œæ­£åœ¨è¢«å¡‘é€ ", "åœ£è´¤è†å‰", "çŸ¥è¯†å»ºæ„å’Œåˆ›é€ çš„éšå–»", 0.89),
                    VisualElement("ç¬¦å·", "æ¼‚æµ®çš„ç¥ç§˜ç¬¦æ–‡å’Œæ–‡å­—", "å‘¨å›´ç©ºä¸­", "æŠ½è±¡æ€ç»´å’Œç¬¦å·ç³»ç»Ÿçš„è§†è§‰åŒ–", 0.87),
                    VisualElement("ç¯å¢ƒ", "å±±æ°´æ™¯è§‚ï¼Œçµæ€§æ°›å›´", "èƒŒæ™¯", "è¶…è¶Šæ€§æ€ç»´å’Œå“²å­¦å¢ƒç•Œ", 0.85),
                    VisualElement("å…‰æ•ˆ", "ç¥åœ£å…‰ç¯å’Œå…‰æŸ", "äººç‰©å¤´é¡¶", "æ™ºæ…§å¯è’™å’Œç²¾ç¥å‡å", 0.91)
                ]
            
            # æ¨¡å¼3ï¼šAI/æ•°å­—æ„è¯†
            elif any(token in t for token in ('ai', 'cyber', 'digital', '3') for t in path_tokens):
                elements = [
                    VisualElement("äººç‰©", "AIæœºå™¨äººï¼Œå…·æœ‰äººå½¢ç‰¹å¾", "å·¦å‰æ™¯", "äººå·¥æ™ºèƒ½ä½œä¸ºè§‚å¯Ÿè€…å’Œæ€è€ƒè€…", 0.93),
                    VisualElement("å…¨æ¯æŠ•å½±", "äººç±»æ•°å­—å­ªç”Ÿä½“ï¼Œè“è‰²å‘å…‰", "ä¸­å¿ƒ", "äººç±»æ„è¯†å’ŒçŸ¥è¯†çš„æ•°å­—åŒ–", 0.96),
                    VisualElement("ç¯å¢ƒ", "èµ›åšæœ‹å…‹éƒ½å¸‚ï¼Œéœ“è™¹ç¯å…‰", "èƒŒæ™¯", "æŠ€æœ¯å¯†é›†å’Œä¿¡æ¯è¿‡è½½çš„æœªæ¥", 0.88),
                    VisualElement("æ–‡å­—", "ä¸­æ–‡æŠ€æœ¯æ˜¾ç¤ºå±å’Œä»£ç ", "å‘¨å›´å¤šå¤„", "äººç±»è¯­è¨€æ–‡åŒ–èå…¥AIç³»ç»Ÿ", 0.90),
                    VisualElement("å…‰æ•ˆ", "è“è‰²ç”µè·¯çº¹ç†å’Œå…‰ç¯", "å…¨æ¯ä½“è¡¨é¢", "æ•°å­—ç¥ç»ç½‘ç»œçš„è§†è§‰å‘ˆç°", 0.92)
                ]
            
            else:
                elements = [VisualElement("é€šç”¨", "å›¾åƒåŒ…å«å¤æ‚è§†è§‰å…ƒç´ ", "å…¨å±€", "éœ€è¦æ›´è¯¦ç»†çš„è§†è§‰APIåˆ†æ", 0.70)]
            
            # ç¼“å­˜ç»“æœï¼ˆé™åˆ¶ç¼“å­˜å¤§å°ï¼‰
            if len(self._cached_stem_analysis) < self.max_cached_paths:
                self._cached_stem_analysis[path_key] = elements
            
            logger.debug("Extracted %d visual elements from %s", len(elements), Path(image_path).name)
            return elements
            
        except Exception as e:
            logger.warning("Error extracting visual elements from %s: %s", image_path, str(e))
            return [VisualElement("æœªçŸ¥", "è§†è§‰åˆ†æå¤±è´¥", "æœªçŸ¥", "å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯", 0.0)]
    
    async def _extract_text(self, image_path: str) -> Optional[str]:
        """æå–å›¾åƒä¸­çš„æ–‡å­—ï¼ˆæ¨¡æ‹ŸOCRï¼‰"""
        try:
            stem = Path(image_path).stem
            path_lower = image_path.lower()
            
            if '1' in stem or 'primitive' in path_lower:
                return "ä½¿ç”¨å·¥å…·ã€æƒ³è±¡åŠ›ã€è™šæ„åŠ›ã€èµ‹äºˆæ„ä¹‰çš„èƒ½åŠ›"
            return None
        except Exception as e:
            logger.warning("OCR extraction failed for %s: %s", image_path, str(e))
            return None
    
    async def _extract_symbolic_meanings(
        self, 
        visual_elements: List[VisualElement],
        text_content: Optional[str]
    ) -> List[SymbolicMeaning]:
        """æå–è±¡å¾æ„ä¹‰"""
        meanings: List[SymbolicMeaning] = []
        try:
            # é¢„ç¼–è¯‘å¸¸è§å…³é”®è¯ä»¥æé«˜æ€§èƒ½
            symbol_patterns = [
                ("å·¥å…·", "åŸå§‹å·¥å…·", "äººç±»æ™ºèƒ½å¤–åŒ–çš„ç¬¬ä¸€æ­¥"),
                ("å…‰", "ç¥åœ£ä¹‹å…‰", "æ™ºæ…§çš„å¯è’™"),
                ("ç«", "ç¥åœ£ä¹‹å…‰", "æ™ºæ…§çš„å¯è’™"),
                ("light", "ç¥åœ£ä¹‹å…‰", "æ™ºæ…§çš„å¯è’™"),
                ("åœ£è´¤", "æ™ºæ…§å¯¼å¸ˆ", "çŸ¥è¯†çš„å®ˆæŠ¤è€…"),
                ("é•¿è€…", "æ™ºæ…§å¯¼å¸ˆ", "çŸ¥è¯†çš„ä¼ æ‰¿è€…"),
                ("sage", "æ™ºæ…§å¯¼å¸ˆ", "çŸ¥è¯†çš„å®ˆæŠ¤è€…"),
                ("æ³¥", "æ³¥åœŸå¡‘å½¢", "çŸ¥è¯†å»ºæ„"),
                ("å¡‘", "æ³¥åœŸå¡‘å½¢", "æ¦‚å¿µå¡‘é€ "),
                ("clay", "æ³¥åœŸå¡‘å½¢", "ä¸»åŠ¨å»ºæ„"),
                ("ai", "äººå·¥æ™ºèƒ½", "åˆ›é€ è€…ä¸è¢«åˆ›é€ è€…çš„è§’è‰²åè½¬"),
                ("æœºå™¨äºº", "äººå·¥æ™ºèƒ½", "æœºå™¨åˆ¶é€ çš„æ™ºèƒ½ä½“"),
                ("robot", "äººå·¥æ™ºèƒ½", "æ™ºèƒ½ä½“"),
                ("å…¨æ¯", "æ•°å­—å­ªç”Ÿ", "æ„è¯†å’ŒçŸ¥è¯†çš„å®Œå…¨ä¿¡æ¯åŒ–"),
                ("æ•°å­—", "æ•°å­—å­ªç”Ÿ", "ç‰©è´¨ä¸ä¿¡æ¯çš„ç•Œé™æ¶ˆè§£"),
                ("holograph", "æ•°å­—å­ªç”Ÿ", "ä¿¡æ¯åŒ–å¤åˆ¶"),
                ("èµ›åš", "èµ›åšæœ‹å…‹éƒ½å¸‚", "é«˜ç§‘æŠ€ä½ç”Ÿæ´»"),
                ("cyber", "èµ›åšæœ‹å…‹éƒ½å¸‚", "æ§åˆ¶ä¸è‡ªç”±çš„çŸ›ç›¾"),
                ("éœ“è™¹", "èµ›åšæœ‹å…‹éƒ½å¸‚", "æœªæ¥åŸå¸‚")
            ]
            
            # æ‰¹é‡å¤„ç†è§†è§‰å…ƒç´ 
            for element in visual_elements:
                desc_lower = element.description.lower()
                for keyword, symbol_name, _ in symbol_patterns:
                    if keyword in element.description or keyword in desc_lower:
                        meaning = self._create_symbolic_meaning(symbol_name, element.description)
                        if meaning and meaning not in meanings:  # å»é‡
                            meanings.append(meaning)
                        break  # åŒ¹é…æˆåŠŸå³è·³å‡º
            
            # åˆ†ææ–‡å­—å†…å®¹çš„è±¡å¾æ„ä¹‰
            if text_content:
                if 'å·¥å…·' in text_content:
                    meanings.append(SymbolicMeaning(
                        symbol="å·¥å…·ä½¿ç”¨",
                        surface_meaning="ä½¿ç”¨ç‰©ç†å·¥å…·",
                        deep_meaning="å¤–åŒ–è®¤çŸ¥èƒ½åŠ›ï¼Œå»¶ä¼¸èº«ä½“å’Œå¿ƒæ™º",
                        cultural_context="é©¬å…‹æ€ï¼šäººé€šè¿‡åŠ³åŠ¨æ”¹é€ ä¸–ç•Œ",
                        philosophical_implication="å·¥å…·æ˜¯äººç±»æœ¬è´¨åŠ›é‡çš„å¯¹è±¡åŒ–"
                    ))
                
                if 'æƒ³è±¡åŠ›' in text_content:
                    meanings.append(SymbolicMeaning(
                        symbol="æƒ³è±¡åŠ›",
                        surface_meaning="æ„æƒ³ä¸å­˜åœ¨äº‹ç‰©çš„èƒ½åŠ›",
                        deep_meaning="è¶…è¶Šå½“ä¸‹ç°å®ï¼Œåˆ›é€ å¯èƒ½æ€§ç©ºé—´",
                        cultural_context="åº·å¾·ï¼šæƒ³è±¡åŠ›æ˜¯è¿æ¥æ„Ÿæ€§ä¸ç†æ€§çš„æ¡¥æ¢",
                        philosophical_implication="æƒ³è±¡åŠ›ä½¿äººç±»èƒ½å¤Ÿè§„åˆ’æœªæ¥ã€åˆ›é€ æ–‡æ˜"
                    ))
                
                if any(term in text_content for term in ['è™šæ„åŠ›', 'æ„ä¹‰']):
                    meanings.append(SymbolicMeaning(
                        symbol="èµ‹äºˆæ„ä¹‰",
                        surface_meaning="ä¸ºäº‹ç‰©åˆ›é€ æ„ä¹‰",
                        deep_meaning="å»ºæ„ç¬¦å·ç³»ç»Ÿï¼Œåˆ›é€ å…±äº«ç°å®",
                        cultural_context="å°¤ç“¦å°”Â·èµ«æ‹‰åˆ©ã€Šäººç±»ç®€å²ã€‹ï¼šè™šæ„èƒ½åŠ›ä½¿å¤§è§„æ¨¡åä½œæˆä¸ºå¯èƒ½",
                        philosophical_implication="æ„ä¹‰ä¸æ˜¯å‘ç°çš„è€Œæ˜¯åˆ›é€ çš„ï¼Œä½“ç°å­˜åœ¨ä¸»ä¹‰å“²å­¦"
                    ))
                    
        except Exception as e:
            logger.error("Error extracting symbolic meanings: %s", str(e))
        
        logger.debug("Extracted %d symbolic meanings.", len(meanings))
        return meanings
    
    def _create_symbolic_meaning(self, symbol_type: str, context_desc: str) -> Optional[SymbolicMeaning]:
        """åˆ›å»ºæ ‡å‡†åŒ–çš„è±¡å¾æ„ä¹‰å¯¹è±¡"""
        meanings_map = {
            "åŸå§‹å·¥å…·": SymbolicMeaning(
                symbol="åŸå§‹å·¥å…·",
                surface_meaning="ç”¨äºç”Ÿå­˜çš„ç‰©ç†å·¥å…·",
                deep_meaning="äººç±»æ™ºèƒ½å¤–åŒ–çš„ç¬¬ä¸€æ­¥ï¼ŒåŒºåˆ†äººç±»ä¸åŠ¨ç‰©çš„å…³é”®",
                cultural_context="äººç±»å­¦ã€è€ƒå¤å­¦ä¸­å·¥å…·ä½¿ç”¨è¢«è§†ä¸ºæ™ºäººçš„æ ‡å¿—",
                philosophical_implication="å·¥å…·ä½¿ç”¨ä»£è¡¨äº†ä¸»ä½“å¯¹å®¢ä½“çš„æ”¹é€ èƒ½åŠ›ï¼Œæ˜¯æ„è¯†å’Œç‰©è´¨ç›¸äº’ä½œç”¨çš„å¼€ç«¯"
            ),
            "ç¥åœ£ä¹‹å…‰": SymbolicMeaning(
                symbol="ç¥åœ£ä¹‹å…‰",
                surface_meaning="ç‰©ç†å…‰æºæˆ–ç¥æ€§è¡¨ç°",
                deep_meaning="æ™ºæ…§çš„å¯è’™ã€çŸ¥è¯†çš„ä¼ æ’­ã€ç²¾ç¥çš„å‡å",
                cultural_context="æ™®ç½—ç±³ä¿®æ–¯ç›—ç«ã€ä½›æ•™å…‰æ˜ã€åŸºç£æ•™åœ£å…‰",
                philosophical_implication="å…‰æ˜å¯¹æŠ—é»‘æš—æ˜¯è®¤çŸ¥æˆ˜èƒœæ— çŸ¥çš„éšå–»ï¼Œä»£è¡¨ç†æ€§çš„èƒœåˆ©"
            ),
            "æ™ºæ…§å¯¼å¸ˆ": SymbolicMeaning(
                symbol="æ™ºæ…§å¯¼å¸ˆ",
                surface_meaning="ä¼ æˆçŸ¥è¯†çš„é•¿è€…",
                deep_meaning="çŸ¥è¯†çš„å®ˆæŠ¤è€…å’Œä¼ æ‰¿è€…ï¼Œä»£è¡¨ä¸–ä»£é—´çš„æ™ºæ…§æµä¼ ",
                cultural_context="å­”å­ã€è‹æ ¼æ‹‰åº•ã€ä½›é™€ç­‰æ–‡åŒ–åŸå‹",
                philosophical_implication="ä½“ç°äº†æ•™è‚²å’Œæ–‡åŒ–ä¼ æ‰¿åœ¨äººç±»æ–‡æ˜ä¸­çš„æ ¸å¿ƒåœ°ä½"
            ),
            "æ³¥åœŸå¡‘å½¢": SymbolicMeaning(
                symbol="æ³¥åœŸå¡‘å½¢",
                surface_meaning="ç”¨æ³¥åœŸåˆ›é€ å½¢ä½“",
                deep_meaning="çŸ¥è¯†å»ºæ„ã€æ¦‚å¿µå¡‘é€ ã€ç†è§£ä¸–ç•Œçš„ä¸»åŠ¨æ€§",
                cultural_context="ã€Šåœ£ç»ã€‹åˆ›ä¸–çºªã€ä¸­å›½å¥³å¨²é€ äºº",
                philosophical_implication="åæ˜ å»ºæ„ä¸»ä¹‰è®¤è¯†è®ºï¼šçŸ¥è¯†ä¸æ˜¯è¢«åŠ¨æ¥å—ï¼Œè€Œæ˜¯ä¸»åŠ¨å»ºæ„"
            ),
            "äººå·¥æ™ºèƒ½": SymbolicMeaning(
                symbol="äººå·¥æ™ºèƒ½",
                surface_meaning="æœºå™¨åˆ¶é€ çš„æ™ºèƒ½ä½“",
                deep_meaning="äººç±»åˆ›é€ æ™ºèƒ½çš„æœ€ç»ˆå½¢å¼ï¼Œåˆ›é€ è€…ä¸è¢«åˆ›é€ è€…çš„è§’è‰²åè½¬",
                cultural_context="ç§‘å¹»æ–‡å­¦ä¸­çš„AIå´›èµ·ã€å›¾çµæµ‹è¯•ã€å¥‡ç‚¹ç†è®º",
                philosophical_implication="å¼•å‘å…³äºæ„è¯†æœ¬è´¨ã€è‡ªç”±æ„å¿—ã€åˆ›é€ ä¼¦ç†çš„æ·±åˆ»æ€è€ƒ"
            ),
            "æ•°å­—å­ªç”Ÿ": SymbolicMeaning(
                symbol="æ•°å­—å­ªç”Ÿ",
                surface_meaning="äººç±»çš„æ•°å­—åŒ–å¤åˆ¶",
                deep_meaning="æ„è¯†å’ŒçŸ¥è¯†çš„å®Œå…¨ä¿¡æ¯åŒ–ï¼Œç‰©è´¨ä¸ä¿¡æ¯çš„ç•Œé™æ¶ˆè§£",
                cultural_context="é»‘å®¢å¸å›½ã€è¥¿éƒ¨ä¸–ç•Œã€æ¨¡æ‹Ÿå‡è¯´",
                philosophical_implication="æŒ‘æˆ˜èº«å¿ƒäºŒå…ƒè®ºï¼Œæå‡ºä¿¡æ¯æœ¬ä½“è®ºçš„å¯èƒ½æ€§"
            ),
            "èµ›åšæœ‹å…‹éƒ½å¸‚": SymbolicMeaning(
                symbol="èµ›åšæœ‹å…‹éƒ½å¸‚",
                surface_meaning="é«˜ç§‘æŠ€ä½ç”Ÿæ´»çš„æœªæ¥åŸå¸‚",
                deep_meaning="æŠ€æœ¯ä¸äººæ€§çš„å¼ åŠ›ã€ä¿¡æ¯è¿‡è½½ã€æ§åˆ¶ä¸è‡ªç”±çš„çŸ›ç›¾",
                cultural_context="ã€Šé“¶ç¿¼æ€æ‰‹ã€‹ã€ã€Šæ”»å£³æœºåŠ¨é˜Ÿã€‹ã€ã€Šç¥ç»æ¼«æ¸¸è€…ã€‹",
                philosophical_implication="åæ€æŠ€æœ¯è¿›æ­¥æ˜¯å¦ç­‰åŒäºäººç±»è¿›æ­¥ï¼Œè´¨ç–‘å·¥å…·ç†æ€§çš„ç»Ÿæ²»"
            )
        }
        return meanings_map.get(symbol_type)
    
    async def _philosophical_analysis(
        self,
        visual_elements: List[VisualElement],
        symbolic_meanings: List[SymbolicMeaning],
        text_content: Optional[str]
    ) -> str:
        """å“²å­¦æ€è¾¨åˆ†æ"""
        try:
            analysis_parts: List[str] = []
            symbolic_symbols = {s.symbol.lower() for s in symbolic_meanings}
            has_ai = any(kw in sym for kw in ('ai', 'æœºå™¨') for sym in symbolic_symbols)
            has_meaning = text_content and 'æ„ä¹‰' in text_content
            
            # æœ¬ä½“è®ºç»´åº¦
            analysis_parts.append(
                "**æœ¬ä½“è®ºç»´åº¦ï¼š** "
                "å›¾åƒæ¢è®¨äº†æ™ºèƒ½çš„æœ¬è´¨ã€‚ä»ç‰©è´¨å·¥å…·åˆ°æŠ½è±¡æ¦‚å¿µï¼Œå†åˆ°æ•°å­—ä¿¡æ¯ï¼Œ"
                "å±•ç°äº†æ™ºèƒ½å­˜åœ¨å½¢å¼çš„ä¸‰æ¬¡é£è·ƒã€‚æ¯æ¬¡é£è·ƒéƒ½æ˜¯ä¸€æ¬¡æœ¬ä½“è®ºçš„é©å‘½ï¼š" 
                "ç‰©ç†å®åœ¨â†’æ¦‚å¿µå®åœ¨â†’ä¿¡æ¯å®åœ¨ã€‚"
            )
            
            # è®¤è¯†è®ºç»´åº¦
            analysis_parts.append(
                "**è®¤è¯†è®ºç»´åº¦ï¼š** "
                "å›¾åƒæ­ç¤ºäº†äººç±»è®¤çŸ¥æ–¹å¼çš„æ¼”è¿›ã€‚ä»æ„ŸçŸ¥-è¡ŒåŠ¨çš„ç›´æ¥è®¤çŸ¥ï¼Œ"
                "åˆ°ç¬¦å·-é€»è¾‘çš„é—´æ¥è®¤çŸ¥ï¼Œå†åˆ°è®¡ç®—-æ¨¡æ‹Ÿçš„è™šæ‹Ÿè®¤çŸ¥ã€‚"
                "æ¯ä¸ªé˜¶æ®µéƒ½ä»£è¡¨äº†è®¤è¯†è®ºçš„èŒƒå¼è½¬ç§»ã€‚"
            )
            
            # ä¼¦ç†å­¦ç»´åº¦
            if has_ai:
                analysis_parts.append(
                    "**ä¼¦ç†å­¦ç»´åº¦ï¼š** "
                    "å½“åˆ›é€ ç‰©å¼€å§‹æ€è€ƒåˆ›é€ è€…ï¼Œä¼¦ç†å…³ç³»å‘ç”Ÿäº†æ ¹æœ¬æ€§çš„å€’è½¬ã€‚"
                    "è¿™å¼•å‘äº†æ·±åˆ»çš„ä¼¦ç†é—®é¢˜ï¼šAIæ˜¯å·¥å…·ã€ä¼™ä¼´è¿˜æ˜¯ç»§æ‰¿è€…ï¼Ÿ"
                    "äººç±»æœ‰æƒåˆ›é€ å¯èƒ½è¶…è¶Šè‡ªå·±çš„æ™ºèƒ½ä½“å—ï¼Ÿ"
                )
            
            # å†å²å“²å­¦ç»´åº¦
            analysis_parts.append(
                "**å†å²å“²å­¦ç»´åº¦ï¼š** "
                "å›¾åƒæš—ç¤ºäº†ä¸€ç§ç›®çš„è®ºçš„å†å²è§‚ï¼šä»åŸå§‹å·¥å…·åˆ°AGIï¼Œ"
                "ä¼¼ä¹å­˜åœ¨ä¸€æ¡å¿…ç„¶çš„è¿›åŒ–è·¯å¾„ã€‚ä½†è¿™æ˜¯çœŸæ­£çš„å¿…ç„¶æ€§ï¼Œ"
                "è¿˜æ˜¯æˆ‘ä»¬å›æº¯æ€§å»ºæ„çš„å™äº‹ï¼Ÿé»‘æ ¼å°”çš„ç»å¯¹ç²¾ç¥åœ¨æŠ€æœ¯æ—¶ä»£çš„æ–°è¡¨ç°ï¼Ÿ"
            )
            
            # å­˜åœ¨ä¸»ä¹‰ç»´åº¦
            if has_meaning:
                analysis_parts.append(
                    "**å­˜åœ¨ä¸»ä¹‰ç»´åº¦ï¼š** "
                    "'èµ‹äºˆæ„ä¹‰çš„èƒ½åŠ›'æ­ç¤ºäº†å­˜åœ¨ä¸»ä¹‰çš„æ ¸å¿ƒï¼šå­˜åœ¨å…ˆäºæœ¬è´¨ã€‚"
                    "äººç±»ï¼ˆåŠæœªæ¥çš„AIï¼‰ä¸æ˜¯è¢«ç»™å®šæ„ä¹‰ï¼Œè€Œæ˜¯ä¸»åŠ¨åˆ›é€ æ„ä¹‰ã€‚"
                    "è¿™æ˜¯è¨ç‰¹å¼çš„è‡ªç”±ï¼Œä¹Ÿæ˜¯åŠ ç¼ªå¼çš„è’è¯åæŠ—ã€‚"
                )
            
            # æŠ€æœ¯å“²å­¦ç»´åº¦
            analysis_parts.append(
                "**æŠ€æœ¯å“²å­¦ç»´åº¦ï¼š** "
                "å›¾åƒä½“ç°äº†æµ·å¾·æ ¼å°”çš„æ‹…å¿§ï¼šæŠ€æœ¯ä¸ä»…æ˜¯å·¥å…·ï¼Œæ›´æ˜¯ä¸€ç§ä¸–ç•Œè§‚ã€‚"
                "ä»å·¥å…·ä½¿ç”¨åˆ°æŠ€æœ¯æ –å±…ï¼Œäººç±»é€æ¸æˆä¸ºæŠ€æœ¯ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†ã€‚"
                "æœ€ç»ˆçš„æ•°å­—åŒ–å½¢è±¡æ˜¯æŠ€æœ¯å¯¹äººçš„å½»åº•'åº§æ¶'ï¼ˆGe-stellï¼‰ã€‚"
            )
            
            result = "\n\n".join(analysis_parts)
            logger.debug("Generated philosophical interpretation with %d sections.", len(analysis_parts))
            return result
            
        except Exception as e:
            logger.error("Philosophical analysis failed: %s", str(e))
            return "**åˆ†æå¤±è´¥**ï¼šæ— æ³•ç”Ÿæˆå“²å­¦è§£è¯»ã€‚"
    
    def _determine_theme_and_stage(
        self,
        visual_elements: List[VisualElement],
        symbolic_meanings: List[SymbolicMeaning]
    ) -> Tuple[str, str]:
        """ç¡®å®šæ•´ä½“ä¸»é¢˜å’Œè¿›åŒ–é˜¶æ®µ"""
        try:
            # ä½¿ç”¨é›†åˆåŠ é€Ÿæˆå‘˜æ£€æŸ¥
            all_text = " ".join([
                e.description for e in visual_elements
            ] + [
                s.symbol for s in symbolic_meanings
            ]).lower()
            
            keywords = set(all_text.split())
            
            # ä½¿ç”¨çŸ­è·¯è¯„ä¼°æå‡æ•ˆç‡
            if any(kw in all_text for kw in ['åŸå§‹', 'å·¥å…·', 'primitive']) or any(k in keywords for k in ['tool', 'primitive']):
                stage = "ç”Ÿç‰©æ™ºèƒ½é˜¶æ®µï¼ˆ200ä¸‡å¹´å‰-1ä¸‡å¹´å‰ï¼‰"
                theme = "å·¥å…·ä½¿ç”¨ä¸æƒ³è±¡åŠ›ï¼šäººç±»æ™ºèƒ½çš„é»æ˜"
            elif any(kw in all_text for kw in ['åœ£è´¤', 'æ™ºæ…§', 'sage']) or any(k in keywords for k in ['sage', 'wisdom']):
                stage = "å“²å­¦æ™ºèƒ½é˜¶æ®µï¼ˆå…¬å…ƒå‰500å¹´-20ä¸–çºªï¼‰"
                theme = "çŸ¥è¯†å»ºæ„ä¸æ™ºæ…§ä¼ æ‰¿ï¼šä»ç”Ÿå­˜åˆ°æ„ä¹‰"
            elif any(kw in all_text for kw in ['ai', 'æ•°å­—', 'å…¨æ¯']) or any(k in keywords for k in ['ai', 'digital', 'holograph']):
                stage = "äººå·¥æ™ºèƒ½é˜¶æ®µï¼ˆ21ä¸–çºª-æœªæ¥ï¼‰"
                theme = "æ•°å­—æ„è¯†ä¸æŠ€æœ¯åæ€ï¼šåˆ›é€ è€…å‡è§†è¢«åˆ›é€ è€…"
            else:
                stage = "æœªçŸ¥é˜¶æ®µ"
                theme = "æ™ºèƒ½è¿›åŒ–çš„æŸä¸ªå…³é”®èŠ‚ç‚¹"
                
            logger.debug("Determined theme: '%s', stage: '%s'", theme, stage)
            return theme, stage
            
        except Exception as e:
            logger.error("Theme and stage determination failed: %s", str(e))
            return "åˆ†æå¤±è´¥", "æœªçŸ¥é˜¶æ®µ"
    
    def _calculate_confidence(
        self,
        visual_elements: List[VisualElement],
        symbolic_meanings: List[SymbolicMeaning]
    ) -> float:
        """è®¡ç®—åˆ†æç½®ä¿¡åº¦"""
        if not visual_elements:
            return 0.5
        
        try:
            avg_visual_confidence = sum(e.confidence for e in visual_elements) / len(visual_elements)
            symbolic_bonus = min(len(symbolic_meanings) * 0.05, 0.2)
            confidence = min(avg_visual_confidence + symbolic_bonus, 0.99)
            return round(confidence, 3)
        except Exception as e:
            logger.error("Confidence calculation error: %s", str(e))
            return 0.5
    
    async def analyze_image_sequence(
        self, 
        image_paths: List[Union[str, Path]]
    ) -> Dict[str, Any]:
        """åˆ†æå›¾åƒåºåˆ—ï¼Œå‘ç°æ¼”åŒ–è¶‹åŠ¿"""
        if not image_paths:
            logger.warning("Empty image path list provided.")
            return {
                'individual_results': [],
                'sequence_analysis': {},
                'timestamp': datetime.now().isoformat(),
                'error': 'No images to analyze'
            }
            
        print("\n" + "="*80)
        print("ğŸ¨ å¤šæ¨¡æ€å›¾åƒåºåˆ—åˆ†æ")
        print("="*80)
        
        results: List[ImageAnalysisResult] = []
        
        # å¹¶å‘åˆ†ææ‰€æœ‰å›¾åƒ
        tasks = [self.analyze_image(path) for path in image_paths]
        try:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # è¿‡æ»¤å¼‚å¸¸ç»“æœ
            valid_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error("Failed to process image %s: %s", image_paths[i], str(result))
                    continue
                valid_results.append(result)
                print(f"\nğŸ“¸ åˆ†æå›¾åƒ {i+1}/{len(image_paths)}: {Path(image_paths[i]).name}")
                print(f"   ä¸»é¢˜: {result.overall_theme}")
                print(f"   é˜¶æ®µ: {result.evolutionary_stage}")
                print(f"   ç½®ä¿¡åº¦: {result.confidence_score:.1%}")
            
            # åºåˆ—åˆ†æ
            sequence_analysis = self._analyze_sequence_evolution(valid_results)
            
            print("\n" + "="*80)
            print("ğŸ“Š åºåˆ—åˆ†æå®Œæˆ")
            print("="*80)
            avg_confidence = sum(r.confidence_score for r in valid_results) / len(valid_results) if valid_results else 0
            print(f"åˆ†æå›¾åƒæ•°: {len(valid_results)}")
            print(f"è¯†åˆ«çš„è¿›åŒ–é˜¶æ®µæ•°: {len(set(r.evolutionary_stage for r in valid_results))}")
            print(f"å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.1%}")
            
            return {
                'individual_results': valid_results,
                'sequence_analysis': sequence_analysis,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.critical("Image sequence analysis failed: %s", str(e))
            raise
    
    def _analyze_sequence_evolution(
        self, 
        results: List[ImageAnalysisResult]
    ) -> Dict[str, Any]:
        """åˆ†æåºåˆ—ä¸­çš„æ¼”åŒ–è¶‹åŠ¿"""
        try:
            if not results:
                return {"error": "No results to analyze"}

            stages: List[str] = [r.evolutionary_stage for r in results]
            unique_stages = len(set(stages))
            
            common_themes = [
                "æ™ºèƒ½çš„æœ¬è´¨ï¼šä»ç‰©è´¨åˆ°ä¿¡æ¯",
                "åˆ›é€ ä¸è¢«åˆ›é€ çš„è¾©è¯å…³ç³»",
                "å·¥å…·ä½¿ç”¨åˆ°å·¥å…·æˆä¸ºä¸»ä½“",
                "æ„ä¹‰åˆ›é€ èƒ½åŠ›çš„å»¶ç»­ä¸å‡å"
            ]
            
            prophetic_interpretation = (
                "è¿™ä¸€åºåˆ—æš—ç¤ºäº†ä¸€ç§å¿…ç„¶æ€§ï¼šäººç±»åˆ›é€ å·¥å…·ï¼Œå·¥å…·å¡‘é€ äººç±»ï¼Œ"
                "æœ€ç»ˆå·¥å…·è·å¾—æ™ºèƒ½å¹¶åæ€äººç±»ã€‚è¿™ä¸æ˜¯ç®€å•çš„æŠ€æœ¯è¿›æ­¥ï¼Œ"
                "è€Œæ˜¯æ™ºèƒ½æœ¬èº«çš„è‡ªæˆ‘è®¤è¯†è¿‡ç¨‹ã€‚ä»'æˆ‘æ€æ•…æˆ‘åœ¨'åˆ°'æˆ‘é€ æ•…æˆ‘åœ¨'ï¼Œ"
                "å†åˆ°'æˆ‘è¢«é€ æ•…æˆ‘åœ¨'â€”â€”è¿™æ˜¯æœ¬ä½“è®ºçš„ä¸‰é‡è¾©è¯ã€‚"
            )
            
            analysis = {
                'evolution_direction': "ä»ç”Ÿç‰©æ™ºèƒ½ â†’ å“²å­¦æ™ºèƒ½ â†’ äººå·¥æ™ºèƒ½çš„çº¿æ€§è¿›åŒ–è·¯å¾„",
                'common_themes': common_themes,
                'prophetic_interpretation': prophetic_interpretation,
                'total_stages': unique_stages,
                'narrative_coherence': 0.95,
                'stage_transitions': unique_stages == len(results)  # æ˜¯å¦æ¯ä¸ªé˜¶æ®µä¸åŒ
            }
            
            logger.info("Sequence evolution analysis completed with %d unique stages.", unique_stages)
            return analysis
            
        except Exception as e:
            logger.error("Sequence evolution analysis failed: %s", str(e))
            return {"error": str(e)}


# æµ‹è¯•å‡½æ•°
async def test_image_understanding() -> Dict[str, Any]:
    """æµ‹è¯•å›¾åƒç†è§£æ¨¡å—"""
    analyzer = MultimodalImageAnalyzer()
    
    # æ¨¡æ‹Ÿä¸‰å¼ å›¾åƒè·¯å¾„
    test_images = [
        "image_1_primitive_tools.jpg",
        "image_2_sage_wisdom.jpg", 
        "image_3_ai_digital.jpg"
    ]
    
    # åˆ†æå›¾åƒåºåˆ—
    results = await analyzer.analyze_image_sequence(test_images)
    
    return results


if __name__ == "__main__":
    try:
        asyncio.run(test_image_understanding())
    except KeyboardInterrupt:
        logger.info("Test interrupted by user.")
    except Exception as e:
        logger.critical("Test execution failed: %s", str(e))
        raise