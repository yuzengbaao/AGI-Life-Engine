import os
import openai
import logging
from dotenv import load_dotenv
from typing import Dict, Any, Optional

# Load environment variables from .env file
load_dotenv()

logger = logging.getLogger("LLMInterface")

class LLMInterface:
    def __init__(self):
        # 尝试从环境变量获取 API Key
        self.api_key = os.getenv("DEEPSEEK_API_KEY")
        self.base_url = "https://api.deepseek.com"
        self.model = "deepseek-chat"
        
        if not self.api_key:
            logger.warning("⚠️ DEEPSEEK_API_KEY environment variable not found. LLM features will be disabled or mocked.")
            self.client = None
        else:
            try:
                self.client = openai.OpenAI(
                    api_key=self.api_key,
                    base_url=self.base_url
                )
                logger.info("✅ DeepSeek API Client initialized.")
            except Exception as e:
                logger.error(f"❌ Failed to initialize DeepSeek Client: {e}")
                self.client = None

    def chat_completion(self, system_prompt: str, user_prompt: str, temperature: float = 0.7) -> str:
        """
        调用 DeepSeek API 进行对话
        """
        if not self.client:
            return "Error: API Key not configured."

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=temperature,
                max_tokens=1024
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"❌ API Call failed: {e}")
            return f"Error during API call: {str(e)}"

    def is_enabled(self) -> bool:
        return self.client is not None
