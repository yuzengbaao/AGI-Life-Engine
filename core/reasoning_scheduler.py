#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨ç†è°ƒåº¦å™¨ï¼ˆReasoning Schedulerï¼‰
==================================

åŠŸèƒ½ï¼šæ™ºèƒ½è°ƒåº¦æ¨ç†å¼•æ“ï¼Œä¼˜å…ˆä½¿ç”¨å› æœæ¨ç†ï¼Œé™çº§åˆ°LLM
ç›®æ ‡ï¼šå®ç°æ¨ç†æ·±åº¦ä»15æ­¥æå‡è‡³1000æ­¥+

ç‰ˆæœ¬: 1.0.0
"""

import time
import hashlib
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
from collections import deque


class ReasoningMode(Enum):
    """æ¨ç†æ¨¡å¼"""
    CAUSAL = "causal"          # å› æœæ¨ç†
    HYBRID = "hybrid"          # æ··åˆæ¨ç†
    LLM_FALLBACK = "llm"       # LLMé™çº§
    PATTERN_MATCH = "pattern"  # æ¨¡å¼åŒ¹é…


@dataclass
class ReasoningStep:
    """æ¨ç†æ­¥éª¤"""
    step_id: str
    mode: ReasoningMode
    timestamp: float
    input_data: Dict[str, Any]
    reasoning_process: str
    output: Any
    confidence: float
    depth: int
    execution_time: float


@dataclass
class ReasoningSession:
    """æ¨ç†ä¼šè¯"""
    session_id: str
    start_time: float
    steps: List[ReasoningStep] = field(default_factory=list)
    current_depth: int = 0
    max_depth: int = 99999  # ğŸ”§ [2026-01-20] è§£é™¤æ¨ç†æ·±åº¦é™åˆ¶
    mode_history: List[ReasoningMode] = field(default_factory=list)

    def add_step(self, step: ReasoningStep):
        """æ·»åŠ æ¨ç†æ­¥éª¤"""
        self.steps.append(step)
        self.current_depth = max(self.current_depth, step.depth)
        self.mode_history.append(step.mode)

    def get_summary(self) -> Dict[str, Any]:
        """è·å–ä¼šè¯æ‘˜è¦"""
        if not self.steps:
            return {
                'session_id': self.session_id,
                'total_steps': 0,
                'max_depth': 0,
                'avg_confidence': 0.0,
                'mode_distribution': {}
            }

        mode_counts = {}
        for mode in self.mode_history:
            mode_counts[mode.value] = mode_counts.get(mode.value, 0) + 1

        return {
            'session_id': self.session_id,
            'total_steps': len(self.steps),
            'max_depth': self.current_depth,
            'avg_confidence': sum(s.confidence for s in self.steps) / len(self.steps),
            'mode_distribution': mode_counts,
            'total_time': self.steps[-1].timestamp - self.start_time if self.steps else 0,
            'avg_step_time': sum(s.execution_time for s in self.steps) / len(self.steps) if self.steps else 0
        }


class ReasoningScheduler:
    """
    æ¨ç†è°ƒåº¦å™¨

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. æ™ºèƒ½é€‰æ‹©æ¨ç†å¼•æ“ï¼ˆå› æœæ¨ç†ä¼˜å…ˆï¼‰
    2. è¿½è¸ªæ¨ç†æ·±åº¦
    3. é™çº§ç­–ç•¥ç®¡ç†
    4. æ¨ç†å†å²è®°å½•
    """

    def __init__(self, causal_engine=None, llm_service=None,
                 confidence_threshold: float = 0.6,
                 max_depth: int = 99999):  # ğŸ”§ [2026-01-20] è§£é™¤æ¨ç†æ·±åº¦é™åˆ¶
        """
        åˆå§‹åŒ–æ¨ç†è°ƒåº¦å™¨

        Args:
            causal_engine: å› æœæ¨ç†å¼•æ“å®ä¾‹
            llm_service: LLMæœåŠ¡å®ä¾‹
            confidence_threshold: å› æœæ¨ç†ç½®ä¿¡åº¦é˜ˆå€¼
            max_depth: æœ€å¤§æ¨ç†æ·±åº¦ï¼ˆå·²è§£é™¤é™åˆ¶ï¼‰
        """
        self.causal_engine = causal_engine
        self.llm_service = llm_service
        self.confidence_threshold = confidence_threshold
        self.max_depth = max_depth

        # æ¨ç†ä¼šè¯ç®¡ç†
        self.current_session: Optional[ReasoningSession] = None
        self.session_history: List[ReasoningSession] = []

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_reasoning_calls': 0,
            'causal_reasoning_used': 0,
            'llm_fallback_used': 0,
            'hybrid_reasoning_used': 0,
            'avg_depth_per_session': 0,
            'max_depth_achieved': 0
        }

        # æ¨ç†é“¾ç¼“å­˜ï¼ˆç”¨äºé¿å…é‡å¤æ¨ç†ï¼‰
        self.reasoning_cache: Dict[str, ReasoningStep] = {}

    def start_session(self, context: Optional[Dict] = None) -> str:
        """
        å¼€å§‹æ–°çš„æ¨ç†ä¼šè¯

        Args:
            context: åˆå§‹ä¸Šä¸‹æ–‡

        Returns:
            session_id: ä¼šè¯ID
        """
        session_id = f"session_{int(time.time() * 1000)}"
        self.current_session = ReasoningSession(
            session_id=session_id,
            start_time=time.time(),
            max_depth=self.max_depth
        )
        return session_id

    def reason(self, query: str, context: Optional[Dict] = None,
               prefer_causal: bool = True) -> Tuple[Any, ReasoningStep]:
        """
        æ‰§è¡Œæ¨ç†

        Args:
            query: æ¨ç†æŸ¥è¯¢
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            prefer_causal: æ˜¯å¦ä¼˜å…ˆä½¿ç”¨å› æœæ¨ç†

        Returns:
            (result, reasoning_step): æ¨ç†ç»“æœå’Œæ¨ç†æ­¥éª¤è®°å½•
        """
        if not self.current_session:
            self.start_session()

        self.stats['total_reasoning_calls'] += 1

        # ç”ŸæˆæŸ¥è¯¢ç¼“å­˜é”®
        cache_key = self._generate_cache_key(query, context)
        if cache_key in self.reasoning_cache:
            cached_step = self.reasoning_cache[cache_key]
            return cached_step.output, cached_step

        start_time = time.time()

        # å†³ç­–ï¼šä½¿ç”¨å“ªç§æ¨ç†å¼•æ“
        mode, result, confidence = self._select_reasoning_engine(
            query, context, prefer_causal
        )

        execution_time = time.time() - start_time

        # åˆ›å»ºæ¨ç†æ­¥éª¤
        step = ReasoningStep(
            step_id=f"step_{len(self.current_session.steps)}",
            mode=mode,
            timestamp=time.time(),
            input_data={'query': query, 'context': context},
            reasoning_process=self._get_reasoning_process_description(mode),
            output=result,
            confidence=confidence,
            depth=len(self.current_session.steps) + 1,
            execution_time=execution_time
        )

        # è®°å½•æ¨ç†æ­¥éª¤
        self.current_session.add_step(step)
        self.reasoning_cache[cache_key] = step

        # æ›´æ–°ç»Ÿè®¡
        if mode == ReasoningMode.CAUSAL:
            self.stats['causal_reasoning_used'] += 1
        elif mode == ReasoningMode.LLM_FALLBACK:
            self.stats['llm_fallback_used'] += 1
        elif mode == ReasoningMode.HYBRID:
            self.stats['hybrid_reasoning_used'] += 1

        return result, step

    def _select_reasoning_engine(self, query: str, context: Optional[Dict],
                                 prefer_causal: bool) -> Tuple[ReasoningMode, Any, float]:
        """
        é€‰æ‹©æ¨ç†å¼•æ“

        å†³ç­–æµç¨‹ï¼š
        1. å¦‚æœæœ‰å› æœæ¨ç†å¼•æ“ä¸”è¢«å¯ç”¨ -> å°è¯•å› æœæ¨ç†
        2. å¦‚æœå› æœæ¨ç†ç½®ä¿¡åº¦è¶³å¤Ÿ -> ä½¿ç”¨å› æœæ¨ç†ç»“æœ
        3. å¦åˆ™ -> é™çº§åˆ°LLM
        """
        # å°è¯•å› æœæ¨ç†
        if prefer_causal and self.causal_engine:
            try:
                # æ£€æŸ¥æ˜¯å¦é€‚åˆå› æœæ¨ç†
                if self._is_suitable_for_causal_reasoning(query, context):
                    # æ‰§è¡Œå› æœæ¨ç†
                    result, confidence = self._perform_causal_reasoning(query, context)

                    if confidence >= self.confidence_threshold:
                        return ReasoningMode.CAUSAL, result, confidence
                    else:
                        # ç½®ä¿¡åº¦ä¸è¶³ï¼Œå°è¯•æ··åˆæ¨ç†
                        if self.llm_service:
                            enhanced_result = self._hybrid_reasoning(result, query, context)
                            return ReasoningMode.HYBRID, enhanced_result, confidence + 0.2

            except Exception as e:
                print(f"  [Scheduler] Causal reasoning failed: {e}, falling back to LLM")

        # é™çº§åˆ°LLM
        if self.llm_service:
            try:
                llm_result = self._perform_llm_reasoning(query, context)
                return ReasoningMode.LLM_FALLBACK, llm_result, 0.5  # LLMåŸºç¡€ç½®ä¿¡åº¦
            except Exception as e:
                print(f"  [Scheduler] LLM reasoning failed: {e}")

        # æœ€åçš„é™çº§ï¼šæ¨¡å¼åŒ¹é…
        return self._perform_pattern_matching(query, context)

    def _is_suitable_for_causal_reasoning(self, query: str, context: Optional[Dict]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦é€‚åˆå› æœæ¨ç†

        é€‚åˆåœºæ™¯ï¼š
        - æŸ¥è¯¢åŒ…å«å› æœå…³é”®è¯ï¼ˆä¸ºä»€ä¹ˆã€å¯¼è‡´ã€å› ä¸ºï¼‰
        - ä¸Šä¸‹æ–‡ä¸­æœ‰äº‹ä»¶åºåˆ—
        - éœ€è¦é¢„æµ‹å¹²é¢„æ•ˆæœ
        """
        causal_keywords = ['ä¸ºä»€ä¹ˆ', 'why', 'å¯¼è‡´', 'cause', 'å› ä¸º', 'because',
                          'å¦‚æœ', 'if', 'é¢„æµ‹', 'predict', 'å½±å“', 'effect']

        query_lower = query.lower()
        has_causal_keyword = any(kw in query_lower for kw in causal_keywords)

        # æ£€æŸ¥ä¸Šä¸‹æ–‡ä¸­æ˜¯å¦æœ‰äº‹ä»¶
        has_events = context and 'events' in context

        return has_causal_keyword or has_events

    def _perform_causal_reasoning(self, query: str, context: Optional[Dict]) -> Tuple[Any, float]:
        """æ‰§è¡Œå› æœæ¨ç†"""
        from core.causal_reasoning import Event

        # ä»ä¸Šä¸‹æ–‡æå–äº‹ä»¶
        events = []
        if context and 'events' in context:
            events = context['events']
        else:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®çš„äº‹ä»¶ï¼Œåˆ›å»ºæ¨¡æ‹Ÿäº‹ä»¶
            events = [
                Event(id=f"E{i}", type="query", timestamp=time.time() + i * 0.1,
                      properties={"content": query})
                for i in range(3)
            ]

        # æ‰§è¡Œå› æœæ¨ç†
        causal_graph = self.causal_engine.infer_causality(events)

        # å°è¯•è§£é‡Š
        explanation = self.causal_engine.explain_reasoning(query)

        # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºå› æœå…³ç³»æ•°é‡ï¼‰
        confidence = min(0.5 + len(causal_graph.edges) * 0.1, 0.95)

        result = {
            'explanation': explanation,
            'causal_relations': len(causal_graph.edges),
            'graph': causal_graph
        }

        return result, confidence

    def _perform_llm_reasoning(self, query: str, context: Optional[Dict]) -> Any:
        """æ‰§è¡ŒLLMæ¨ç†"""
        # æ„å»ºæç¤ºè¯
        prompt = self._build_llm_prompt(query, context)

        # è°ƒç”¨LLMæœåŠ¡
        if hasattr(self.llm_service, 'query'):
            response = self.llm_service.query(prompt)
        elif hasattr(self.llm_service, 'generate'):
            response = self.llm_service.generate(prompt)
        else:
            response = f"LLM response for: {query}"

        return response

    def _hybrid_reasoning(self, causal_result: Any, query: str,
                          context: Optional[Dict]) -> Any:
        """æ··åˆæ¨ç†ï¼šç»“åˆå› æœæ¨ç†å’ŒLLM"""
        # ä½¿ç”¨å› æœæ¨ç†çš„ç»“æœä½œä¸ºä¸Šä¸‹æ–‡ï¼Œè®©LLMç”Ÿæˆæ›´å¥½çš„è§£é‡Š
        enhanced_context = {
            'causal_reasoning': causal_result.get('explanation', ''),
            'original_context': context
        }

        return self._perform_llm_reasoning(query, enhanced_context)

    def _perform_pattern_matching(self, query: str, context: Optional[Dict]) -> Tuple[ReasoningMode, Any, float]:
        """æ¨¡å¼åŒ¹é…ï¼ˆæœ€åçš„é™çº§æ–¹æ¡ˆï¼‰"""
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        response = f"Pattern matching result for query: {query}"

        if context:
            if 'action' in context:
                response = f"Action: {context['action']}"
            elif 'concept' in context:
                response = f"Concept: {context['concept']}"

        return ReasoningMode.PATTERN_MATCH, response, 0.3

    def _build_llm_prompt(self, query: str, context: Optional[Dict]) -> str:
        """æ„å»ºLLMæç¤ºè¯"""
        prompt = f"Query: {query}\n"

        if context:
            prompt += "\nContext:\n"
            for key, value in context.items():
                if key != 'events':  # äº‹ä»¶å¤ªé•¿ï¼Œç®€åŒ–æ˜¾ç¤º
                    prompt += f"  {key}: {value}\n"

        prompt += "\nPlease provide reasoning and conclusion."
        return prompt

    def _get_reasoning_process_description(self, mode: ReasoningMode) -> str:
        """è·å–æ¨ç†è¿‡ç¨‹æè¿°"""
        descriptions = {
            ReasoningMode.CAUSAL: "Causal inference using temporal precedence, covariation, and confounding exclusion",
            ReasoningMode.HYBRID: "Hybrid reasoning combining causal inference with LLM enhancement",
            ReasoningMode.LLM_FALLBACK: "LLM-based reasoning (fallback due to low causal confidence)",
            ReasoningMode.PATTERN_MATCH: "Pattern matching fallback (lowest confidence)"
        }
        return descriptions.get(mode, "Unknown reasoning mode")

    def _generate_cache_key(self, query: str, context: Optional[Dict]) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content = query + str(context) if context else query
        return hashlib.md5(content.encode()).hexdigest()[:16]

    def end_session(self) -> ReasoningSession:
        """ç»“æŸå½“å‰æ¨ç†ä¼šè¯"""
        if self.current_session:
            session = self.current_session
            self.session_history.append(session)

            # æ›´æ–°ç»Ÿè®¡
            self.stats['max_depth_achieved'] = max(
                self.stats['max_depth_achieved'], session.current_depth
            )
            if self.session_history:
                self.stats['avg_depth_per_session'] = sum(
                    s.current_depth for s in self.session_history
                ) / len(self.session_history)

            self.current_session = None
            return session

        return None

    def get_current_session_summary(self) -> Dict[str, Any]:
        """è·å–å½“å‰ä¼šè¯æ‘˜è¦"""
        if self.current_session:
            return self.current_session.get_summary()
        return {}

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–è°ƒåº¦å™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            'current_session_depth': self.current_session.current_depth if self.current_session else 0,
            'total_sessions': len(self.session_history),
            'cache_size': len(self.reasoning_cache),
            'causal_ratio': self.stats['causal_reasoning_used'] / max(self.stats['total_reasoning_calls'], 1)
        }

    def get_reasoning_chain(self, n: int = 10) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘næ­¥æ¨ç†é“¾"""
        if not self.current_session:
            return []

        recent_steps = self.current_session.steps[-n:]
        return [
            {
                'step': s.step_id,
                'mode': s.mode.value,
                'depth': s.depth,
                'confidence': s.confidence,
                'time': s.execution_time
            }
            for s in recent_steps
        ]


# ============ ä½¿ç”¨ç¤ºä¾‹ ============

if __name__ == "__main__":
    print("=" * 60)
    print("æ¨ç†è°ƒåº¦å™¨æµ‹è¯•")
    print("=" * 60)

    # åˆ›å»ºè°ƒåº¦å™¨
    from core.causal_reasoning import CausalReasoningEngine

    causal_engine = CausalReasoningEngine()
    scheduler = ReasoningScheduler(
        causal_engine=causal_engine,
        llm_service=None,  # æ— LLMæ—¶è‡ªåŠ¨é™çº§åˆ°æ¨¡å¼åŒ¹é…
        confidence_threshold=0.6,
        max_depth=99999  # ğŸ”§ [2026-01-20] æ— é™æ¨ç†æ·±åº¦
    )

    # å¼€å§‹ä¼šè¯
    session_id = scheduler.start_session()
    print(f"\n[Session] {session_id}")

    # æ¨¡æ‹Ÿå¤šæ¬¡æ¨ç†
    queries = [
        "ä¸ºä»€ä¹ˆç³»ç»Ÿä¼šé™·å…¥å¾ªç¯ï¼Ÿ",
        "å¦‚ä½•æ‰“ç ´æ€æƒ³å¾ªç¯ï¼Ÿ",
        "é¢„æµ‹æ·»åŠ å·¥ä½œè®°å¿†çš„æ•ˆæœ",
        "åˆ†æå½“å‰ç³»ç»ŸçŠ¶æ€",
        "æ¢ç´¢æ”¹è¿›æ–¹æ¡ˆ"
    ]

    for i, query in enumerate(queries, 1):
        print(f"\n[Step {i}] Query: {query}")
        result, step = scheduler.reason(query, prefer_causal=True)

        print(f"  Mode: {step.mode.value}")
        print(f"  Confidence: {step.confidence:.2f}")
        print(f"  Depth: {step.depth}")
        print(f"  Time: {step.execution_time:.3f}s")

        if isinstance(result, dict) and 'explanation' in result:
            print(f"  Result: {result['explanation'][:100]}...")

    # è·å–ä¼šè¯æ‘˜è¦
    summary = scheduler.end_session()
    print("\n" + "=" * 60)
    print("[ä¼šè¯æ‘˜è¦]")
    print("=" * 60)
    for key, value in summary.get_summary().items():
        print(f"  {key}: {value}")

    # è·å–ç»Ÿè®¡
    stats = scheduler.get_statistics()
    print("\n[è°ƒåº¦å™¨ç»Ÿè®¡]")
    for key, value in stats.items():
        print(f"  {key}: {value}")
