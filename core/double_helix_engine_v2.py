#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŒèºæ—‹å†³ç­–å¼•æ“ v2.0 (Double Helix Decision Engine v2.0)
å¢å¼ºç‰ˆï¼šé›†æˆéçº¿æ€§èåˆã€å…ƒå­¦ä¹ ã€è¾©è®ºå¼å…±è¯†

æ ¸å¿ƒç‰¹æ€§ï¼š
1. éçº¿æ€§äº¤äº’ï¼šå®ç°1+1>2çš„çœŸå®æ¶Œç°
2. å…ƒå­¦ä¹ ä¼˜åŒ–ï¼šè‡ªé€‚åº”è°ƒæ•´èºæ—‹å‚æ•°
3. è¾©è®ºå¼å…±è¯†ï¼šä»"èåˆ"è¿›åŒ–åˆ°"å¯¹è¯"
4. å¤šæ¨¡æ€èåˆï¼šç½®ä¿¡åº¦+ç†µ+å“åº”æ—¶é—´

ä½œè€…ï¼šClaude Code (Sonnet 4.5)
åˆ›å»ºæ—¥æœŸï¼š2026-01-13
ç‰ˆæœ¬ï¼šv2.0ï¼ˆç³»ç»Ÿå‡çº§ç‰ˆï¼‰
"""

import numpy as np
import torch
import logging
import time
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass
from enum import Enum

# å¯¼å…¥ç³»ç»ŸAå’ŒB
try:
    from core.seed import TheSeed
except ImportError:
    TheSeed = None

try:
    from core.fractal_intelligence import create_fractal_intelligence
except ImportError:
    create_fractal_intelligence = None

# å¯¼å…¥æ–°ç»„ä»¶
try:
    from core.nonlinear_fusion import NonlinearFusionEngine, FusionConfig
except ImportError:
    NonlinearFusionEngine = None
    FusionConfig = None

try:
    from core.meta_learner import MetaLearner, MetaLearningConfig
except ImportError:
    MetaLearner = None
    MetaLearningConfig = None

try:
    from core.dialogue_engine import DialogueEngine
except ImportError:
    DialogueEngine = None

try:
    from core.creative_fusion import CreativeFusionEngine, CreativeFusionResult
except ImportError:
    CreativeFusionEngine = None
    CreativeFusionResult = None

try:
    from core.complementary_analyzer import ComplementaryAnalyzer, ComplementaryAnalysis, SystemPreference
except ImportError:
    ComplementaryAnalyzer = None
    ComplementaryAnalysis = None
    SystemPreference = None

try:
    from core.double_helix_engine_v2_fusion_logic import intelligent_fusion
except ImportError:
    intelligent_fusion = None

logger = logging.getLogger(__name__)


@dataclass
class HelixContext:
    """èºæ—‹ä¸Šä¸‹æ–‡"""
    phase: float
    weight_A: float
    weight_B: float
    last_A_output: Optional[np.ndarray]
    last_B_output: Optional[np.ndarray]
    cycle_number: int
    ascent_level: float


@dataclass
class DoubleHelixResult:
    """åŒèºæ—‹å†³ç­–ç»“æœ"""
    action: int
    confidence: float
    weight_A: float
    weight_B: float
    phase: float
    individual_A: Optional[Any]
    individual_B: Optional[Any]
    fusion_method: str
    emergence_score: float
    explanation: str
    response_time_ms: float
    entropy: float = 0.0
    cycle_number: int = 0
    ascent_level: float = 0.0
    # v2æ–°å¢å­—æ®µ
    dialogue_length: int = 0
    consensus_quality: float = 0.0
    nonlinear_breakdown: Optional[Dict[str, Any]] = None
    complementary_preference: str = 'neutral'  # ğŸ†• ç³»ç»Ÿåå¥½ï¼šA/B/neutral/creative
    # ğŸ†• æ¶Œç°è¡Œä¸ºéªŒè¯å­—æ®µï¼ˆç”¨äºæ™ºèƒ½è§‚æµ‹ï¼‰
    is_creative: bool = False  # æ˜¯å¦æ˜¯åˆ›é€ æ€§è¡Œä¸º
    original_space: bool = True  # æ˜¯å¦åœ¨åŸå§‹åŠ¨ä½œç©ºé—´å†…
    emergence_quality: float = 0.0  # æ¶Œç°è´¨é‡æŒ‡æ ‡
    # ğŸ”§ P0ä¿®å¤: æ·»åŠ ç¼ºå¤±çš„å­—æ®µä»¥æ”¯æŒAGI_Life_Engine.pyçš„è®¿é—®
    system_a_confidence: Optional[float] = None  # ç³»ç»ŸAçš„ç½®ä¿¡åº¦
    system_b_confidence: Optional[float] = None  # ç³»ç»ŸBçš„ç½®ä¿¡åº¦
    reasoning: Optional[str] = None  # æ¨ç†è¿‡ç¨‹è¯´æ˜


class FusionMode(Enum):
    """èåˆæ¨¡å¼"""
    LINEAR = "linear"              # çº¿æ€§åŠ æƒï¼ˆåŸç‰ˆï¼‰
    NONLINEAR = "nonlinear"        # éçº¿æ€§èåˆ
    DIALOGUE = "dialogue"          # è¾©è®ºå¼å…±è¯†
    ADAPTIVE = "adaptive"          # è‡ªé€‚åº”é€‰æ‹©


class DoubleHelixEngineV2:
    """
    åŒèºæ—‹å†³ç­–å¼•æ“ v2.0

    å‡çº§ç‰¹æ€§ï¼š
    1. éçº¿æ€§èåˆï¼šäº¤äº’é¡¹+äº’è¡¥é¡¹+å¤šæ ·æ€§
    2. å…ƒå­¦ä¹ ï¼šè‡ªåŠ¨ä¼˜åŒ–èºæ—‹å‚æ•°
    3. è¾©è®ºå¼å…±è¯†ï¼šç³»ç»ŸAå’ŒBè¾©è®ºè¾¾æˆå…±è¯†
    4. è‡ªé€‚åº”æ¨¡å¼ï¼šæ ¹æ®åœºæ™¯é€‰æ‹©æœ€ä½³èåˆæ–¹å¼
    """

    def __init__(
        self,
        state_dim: int = 64,
        action_dim: int = 4,
        device: str = 'cpu',
        # åŸæœ‰å‚æ•°
        spiral_radius: float = 0.3,
        phase_shift: float = np.pi,
        phase_speed: float = 0.1,
        cycle_length: int = 10,
        ascent_rate: float = 0.01,
        # v2æ–°å¢å‚æ•°
        fusion_mode: FusionMode = FusionMode.ADAPTIVE,
        enable_nonlinear: bool = True,
        enable_meta_learning: bool = True,
        enable_dialogue: bool = False,  # å¯¹è¯æ¨¡å¼è¾ƒæ…¢ï¼Œé»˜è®¤å…³é—­
        dialogue_rounds: int = 2,
        adaptive_threshold: float = 0.02,  # æ¶Œç°é˜ˆå€¼ï¼Œä½äºæ­¤å€¼å¯ç”¨å¯¹è¯
        # v3æ–°å¢ï¼šåŠ¨æ€åŠ¨ä½œç©ºé—´
        enable_dynamic_action: bool = True  # å¯ç”¨åŠ¨æ€åŠ¨ä½œç©ºé—´æ‰©å±•
    ):
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.device = device
        self.enable_dynamic_action = enable_dynamic_action

        # æ–°å¢ï¼šåŠ¨æ€åŠ¨ä½œç©ºé—´ç”Ÿæˆå™¨ï¼ˆTask 12ï¼‰
        if enable_dynamic_action:
            from core.dynamic_action_space import get_dynamic_action_space, get_hierarchical_action_space
            self.dynamic_action_space = get_dynamic_action_space()
            self.hierarchical_action_space = get_hierarchical_action_space()
            logger.info("[åŒèºæ—‹v2] åŠ¨æ€åŠ¨ä½œç©ºé—´å·²å¯ç”¨")
        else:
            self.dynamic_action_space = None
            self.hierarchical_action_space = None

        # Task 14: åˆ›é€ æ€§èåˆå¢å¼º
        self.enable_creative_fusion = True
        if self.enable_creative_fusion:
            try:
                from core.creative_fusion_enhanced import get_emergence_detector, get_adaptive_fusion_engine
                self.emergence_detector = get_emergence_detector()
                self.adaptive_fusion_engine = get_adaptive_fusion_engine()
                logger.info("[åŒèºæ—‹v2] åˆ›é€ æ€§èåˆå¢å¼ºå·²å¯ç”¨")
            except ImportError:
                logger.warning("[åŒèºæ—‹v2] æ— æ³•å¯¼å…¥åˆ›é€ æ€§èåˆå¢å¼ºæ¨¡å—")
                self.emergence_detector = None
                self.adaptive_fusion_engine = None
        else:
            self.emergence_detector = None
            self.adaptive_fusion_engine = None

        # èºæ—‹å‚æ•°
        self.spiral_radius = spiral_radius
        self.phase_shift = phase_shift
        self.phase_speed = phase_speed
        self.cycle_length = cycle_length
        self.ascent_rate = ascent_rate

        # v2é…ç½®
        self.fusion_mode = fusion_mode
        self.enable_nonlinear = enable_nonlinear
        self.enable_meta_learning = enable_meta_learning
        self.enable_dialogue = enable_dialogue
        self.dialogue_rounds = dialogue_rounds
        self.adaptive_threshold = adaptive_threshold

        # v2.1 çº åç»„ä»¶
        self.creative_fusion = None
        self.complementary_analyzer = None
        if CreativeFusionEngine is not None:
            self.creative_fusion = CreativeFusionEngine(
                base_action_dim=action_dim,
                enable_expansion=True,
                expansion_dim=action_dim * 2  # æ‰©å±•åˆ°2å€ç©ºé—´
            )
            logger.info("[åŒèºæ—‹v2] âœ¨ åˆ›é€ æ€§èåˆå¼•æ“å·²å¯ç”¨")
        
        if ComplementaryAnalyzer is not None:
            self.complementary_analyzer = ComplementaryAnalyzer(
                state_dim=state_dim,
                window_size=100,
                min_samples=10
            )
            logger.info("[åŒèºæ—‹v2] ğŸ¯ äº’è¡¥åˆ†æå™¨å·²å¯ç”¨")

        # çŠ¶æ€å˜é‡
        self.phase = 0.0
        self.decision_count = 0
        self.cycle_number = 1
        self.ascent_level = 0.0

        # ä¸Šä¸‹æ–‡
        self.context = HelixContext(
            phase=0.0,
            weight_A=0.5,
            weight_B=0.5,
            last_A_output=None,
            last_B_output=None,
            cycle_number=1,
            ascent_level=0.0
        )

        # æ€§èƒ½è¿½è¸ª
        self.confidence_history = []
        self.cycle_peaks = []
        self.emergence_history = []

        # ç»Ÿè®¡
        self.stats = {
            'total_decisions': 0,
            'A_dominant': 0,
            'B_dominant': 0,
            'balanced': 0,
            'avg_emergence': 0.0,
            'avg_confidence': 0.0,
            'cycles_completed': 0,
            # v2æ–°å¢ç»Ÿè®¡
            'fusion_modes_used': {
                'linear': 0,
                'nonlinear': 0,
                'dialogue': 0
            },
            'meta_optimizations': 0,
            'dialogue_emergence_total': 0.0,
            'nonlinear_emergence_total': 0.0
        }

        # åˆå§‹åŒ–ç³»ç»ŸAå’ŒB
        self._init_systems()

        # åˆå§‹åŒ–v2ç»„ä»¶
        self._init_v2_components()

        logger.info(f"[åŒèºæ—‹v2] å¼•æ“åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"[åŒèºæ—‹v2] èåˆæ¨¡å¼={fusion_mode.value}")
        logger.info(f"[åŒèºæ—‹v2] éçº¿æ€§={enable_nonlinear}, å…ƒå­¦ä¹ ={enable_meta_learning}, å¯¹è¯={enable_dialogue}")

    def _init_systems(self):
        """åˆå§‹åŒ–ç³»ç»ŸAå’ŒB"""
        self.seed = None
        if TheSeed:
            try:
                self.seed = TheSeed(
                    state_dim=self.state_dim,
                    action_dim=self.action_dim
                )
                logger.info("[åŒèºæ—‹v2] ç³»ç»ŸAï¼ˆTheSeedï¼‰å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"[åŒèºæ—‹v2] ç³»ç»ŸAåˆå§‹åŒ–å¤±è´¥: {e}")

        self.fractal = None
        if create_fractal_intelligence:
            try:
                self.fractal = create_fractal_intelligence(
                    input_dim=self.state_dim,
                    state_dim=self.state_dim,
                    device=self.device
                )
                logger.info("[åŒèºæ—‹v2] ç³»ç»ŸBï¼ˆåˆ†å½¢æ™ºèƒ½ï¼‰å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"[åŒèºæ—‹v2] ç³»ç»ŸBåˆå§‹åŒ–å¤±è´¥: {e}")

    def _init_v2_components(self):
        """åˆå§‹åŒ–v2æ–°ç»„ä»¶"""

        # 1. éçº¿æ€§èåˆå¼•æ“
        self.nonlinear_fusion = None
        if self.enable_nonlinear and NonlinearFusionEngine:
            try:
                config = FusionConfig(
                    interaction_strength=0.15,
                    complementarity_strength=0.08,
                    diversity_bonus=0.05
                )
                self.nonlinear_fusion = NonlinearFusionEngine(config=config)
                logger.info("[åŒèºæ—‹v2] éçº¿æ€§èåˆå¼•æ“å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"[åŒèºæ—‹v2] éçº¿æ€§èåˆåˆå§‹åŒ–å¤±è´¥: {e}")

        # 2. å…ƒå­¦ä¹ å™¨
        self.meta_learner = None
        if self.enable_meta_learning and MetaLearner:
            try:
                config = MetaLearningConfig(
                    learning_rate=0.01,
                    optimization_interval=20
                )
                self.meta_learner = MetaLearner(config=config, device=self.device)
                logger.info("[åŒèºæ—‹v2] å…ƒå­¦ä¹ å™¨å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"[åŒèºæ—‹v2] å…ƒå­¦ä¹ å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

        # 3. å¯¹è¯å¼•æ“
        self.dialogue_engine = None
        if self.enable_dialogue and DialogueEngine:
            try:
                self.dialogue_engine = DialogueEngine()
                logger.info("[åŒèºæ—‹v2] å¯¹è¯å¼•æ“å·²å¯ç”¨")
            except Exception as e:
                logger.warning(f"[åŒèºæ—‹v2] å¯¹è¯å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")

    def decide(
        self,
        state: np.ndarray,
        context: Optional[Dict[str, Any]] = None,
        last_reward: Optional[float] = None  # ç”¨äºæ›´æ–°äº’è¡¥åˆ†æå™¨
    ) -> DoubleHelixResult:
        """
        åŒèºæ—‹å†³ç­–ï¼ˆv2.1çº åç‰ˆï¼‰

        æ ¸å¿ƒæ”¹è¿›ï¼š
        1. ä¼˜å…ˆè¯†åˆ«äº’è¡¥åŒºåŸŸ - è°æ“…é•¿å°±ç”¨è°
        2. å¼ºçƒˆåˆ†æ­§æ—¶åˆ›é€ æ€§èåˆ - ç”Ÿæˆæ–°åŠ¨ä½œ
        3. æœ€åæ‰æ˜¯æ•°å€¼èåˆ - ä½œä¸ºä¿åº•ç­–ç•¥

        Args:
            state: å½“å‰çŠ¶æ€
            context: é¢å¤–ä¸Šä¸‹æ–‡
            last_reward: ä¸Šä¸€æ­¥çš„å¥–åŠ±ï¼ˆç”¨äºæ›´æ–°è¡¨ç°ï¼‰

        Returns:
            å†³ç­–ç»“æœ
        """
        start_time = time.time()
        context = context or {}
        self.decision_count += 1
        self.stats['total_decisions'] += 1

        # æ­¥éª¤0ï¼šåŠ¨æ€åŠ¨ä½œç©ºé—´æ‰©å±•ï¼ˆTask 38ï¼‰
        if self.enable_dynamic_action and self.dynamic_action_space is not None:
            novelty_required = context.get('novelty_required', 0.0)
            task_complexity = context.get('task_complexity', 0.5)

            # é«˜æ–°é¢–æ€§æˆ–é«˜å¤æ‚åº¦æ—¶æ‰©å±•åŠ¨ä½œç©ºé—´
            if novelty_required > 0.7 or task_complexity > 0.8:
                expanded_actions = self.dynamic_action_space.expand_action_space(
                    context={'novelty_required': novelty_required, 'task_complexity': task_complexity}
                )
                old_dim = self.action_dim
                self.action_dim = expanded_actions.shape[0]
                logger.debug(
                    f"[åŒèºæ—‹v2] åŠ¨ä½œç©ºé—´æ‰©å±•: "
                    f"{old_dim}D â†’ {self.action_dim}D "
                    f"(æ–°é¢–æ€§={novelty_required:.2f}, å¤æ‚åº¦={task_complexity:.2f})"
                )

        # æ­¥éª¤1ï¼šè®¡ç®—ç›¸ä½å’Œæƒé‡
        self._update_phase()

        # æ­¥éª¤2ï¼šç³»ç»ŸAå’ŒBå¹¶è¡Œå†³ç­–
        result_A = self._decide_A(state, context)
        result_B = self._decide_B(state, context)

        # æ­¥éª¤2.5ï¼šäº’è¡¥åŒºåŸŸåˆ†æï¼ˆæ–°å¢ï¼‰
        complementary_analysis = None
        if self.complementary_analyzer is not None:
            complementary_analysis = self.complementary_analyzer.analyze(
                state=state,
                result_A=result_A,
                result_B=result_B
            )

        # æ­¥éª¤2.6ï¼šåŠ¨ä½œå±‚çº§æå‡ï¼ˆTask 38æ–°å¢ï¼‰
        if self.enable_dynamic_action and self.hierarchical_action_space is not None:
            from core.dynamic_action_space import ActionLevel
            novelty = context.get('novelty_required', 0.0)

            # é«˜æ–°é¢–æ€§æ—¶ä½¿ç”¨é«˜å±‚çº§åŠ¨ä½œ
            if novelty > 0.8:
                target_level = ActionLevel.META  # å…ƒåŠ¨ä½œ
            elif novelty > 0.6:
                target_level = ActionLevel.ABSTRACT  # æŠ½è±¡åŠ¨ä½œ
            elif novelty > 0.4:
                target_level = ActionLevel.COMPOSITE  # å¤åˆåŠ¨ä½œ
            else:
                target_level = ActionLevel.PRIMITIVE  # åŸºç¡€åŠ¨ä½œ

            # è·å–é«˜å±‚çº§åŠ¨ä½œç©ºé—´ç»´åº¦
            high_level_dim = self.hierarchical_action_space.get_action_space(target_level)

            if high_level_dim > self.action_dim:
                logger.debug(
                    f"[åŒèºæ—‹v2] åŠ¨ä½œå±‚çº§æå‡: "
                    f"ä»primitive({self.action_dim}D) â†’ {target_level.value}({high_level_dim}D)"
                )
                self.action_dim = high_level_dim

        # æ­¥éª¤3ï¼šæ™ºèƒ½èåˆç­–ç•¥é€‰æ‹©ï¼ˆæ–°æ”¹è¿›ï¼‰
        if intelligent_fusion is not None:
            # ä½¿ç”¨v2.1çš„æ™ºèƒ½èåˆé€»è¾‘
            fused_result = intelligent_fusion(
                engine=self,
                result_A=result_A,
                result_B=result_B,
                state=state,
                complementary_analysis=complementary_analysis
            )
            # ğŸš¨ ä¿®å¤ï¼šintelligent_fusionå·²è¿”å›æœ‰æ•ˆç»“æœï¼Œè·³è¿‡å¤‡ç”¨é€»è¾‘
            selected_mode = None  # æ ‡è®°å·²ä½¿ç”¨æ™ºèƒ½èåˆ
        else:
            # å›é€€åˆ°åŸæœ‰é€»è¾‘
            selected_mode = self._select_fusion_mode(result_A, result_B)
            fused_result = None  # éœ€è¦åç»­èåˆ

        # æ­¥éª¤4ï¼šæ‰§è¡Œèåˆï¼ˆä»…å½“æ™ºèƒ½èåˆæœªå¤„ç†æ—¶ï¼‰
        if selected_mode is not None:  # ğŸš¨ ä»…å½“æœªä½¿ç”¨æ™ºèƒ½èåˆæ—¶æ‰§è¡Œ
            if selected_mode == FusionMode.DIALOGUE and self.dialogue_engine:
                fused_result = self._fuse_with_dialogue(result_A, result_B)
                self.stats['fusion_modes_used']['dialogue'] += 1
                self.stats['dialogue_emergence_total'] += fused_result['emergence']
            elif selected_mode == FusionMode.NONLINEAR and self.nonlinear_fusion:
                fused_result = self._fuse_with_nonlinear(result_A, result_B)
                self.stats['fusion_modes_used']['nonlinear'] += 1
                self.stats['nonlinear_emergence_total'] += fused_result['emergence']
            else:
                fused_result = self._fuse_linear(result_A, result_B)
                self.stats['fusion_modes_used']['linear'] += 1

        # æ­¥éª¤4.5ï¼šæ¶Œç°è¡Œä¸ºæ£€æµ‹ï¼ˆTask 14æ–°å¢ï¼‰
        if self.enable_creative_fusion and self.emergence_detector is not None:
            is_emergent, emergence_score, metrics = self.emergence_detector.detect_emergence(
                fused_output=fused_result,
                individual_A=result_A,
                individual_B=result_B,
                context={'task_complexity': context.get('task_complexity', 0.5)}
            )

            if is_emergent:
                logger.info(
                    f"[åŒèºæ—‹v2] æ£€æµ‹åˆ°æ¶Œç°è¡Œä¸ºï¼"
                    f"æå‡={emergence_score:.2%}, "
                    f"æ–°é¢–æ€§è´¡çŒ®={metrics['novelty_contribution']:.2%}"
                )
                self.stats['emergence_detected'] = self.stats.get('emergence_detected', 0) + 1

        # æ­¥éª¤5ï¼šæ›´æ–°ä¸Šä¸‹æ–‡
        self._update_context(result_A, result_B)

        # æ­¥éª¤6ï¼šæ£€æµ‹å‘¨æœŸå®Œæˆå’Œèºæ—‹ä¸Šå‡
        self._check_cycle_completion(fused_result['confidence'])

        # æ­¥éª¤7ï¼šå…ƒå­¦ä¹ è®°å½•
        if self.meta_learner:
            current_params = {
                'spiral_radius': self.spiral_radius,
                'phase_speed': self.phase_speed,
                'ascent_rate': self.ascent_rate
            }
            self.meta_learner.record_decision(
                state={
                    'phase': self.context.phase,
                    'weight_A': self.context.weight_A,
                    'weight_B': self.context.weight_B
                },
                fusion_params=current_params,
                reward=fused_result['confidence'],
                emergence=fused_result['emergence']
            )

            # å®šæœŸæ›´æ–°å‚æ•°
            if self.decision_count % 50 == 0:
                suggested_params = self.meta_learner.get_suggested_parameters()
                self._update_parameters_from_meta(suggested_params)

        # æ­¥éª¤7ï¼šæ›´æ–°äº’è¡¥åˆ†æå™¨(å¦‚æœæœ‰å¥–åŠ±)
        if last_reward is not None and self.complementary_analyzer is not None:
            # æ›´æ–°ä¸Šä¸€æ¬¡å†³ç­–çš„è¡¨ç°
            if fused_result.get('selected_system') == 'A' and result_A:
                self.complementary_analyzer.update_performance(state, 'A', last_reward)
            elif fused_result.get('selected_system') == 'B' and result_B:
                self.complementary_analyzer.update_performance(state, 'B', last_reward)

        # æ­¥éª¤8ï¼šç»Ÿè®¡
        response_time = (time.time() - start_time) * 1000
        self._update_stats(fused_result)

        # ğŸ†• ä»fused_resultä¸­æå–ç³»ç»Ÿåå¥½
        selected_system = fused_result.get('selected_system', None)
        if selected_system == 'A':
            complementary_pref = 'A'
        elif selected_system == 'B':
            complementary_pref = 'B'
        elif fused_result.get('is_creative', False):
            complementary_pref = 'creative'
        else:
            complementary_pref = 'neutral'

        # ğŸ”§ P0ä¿®å¤: æå–ç³»ç»ŸAå’ŒBçš„ç½®ä¿¡åº¦
        system_a_conf = result_A.get('confidence') if result_A else None
        system_b_conf = result_B.get('confidence') if result_B else None

        return DoubleHelixResult(
            action=fused_result['action'],
            confidence=fused_result['confidence'],
            weight_A=self.context.weight_A,
            weight_B=self.context.weight_B,
            phase=self.context.phase,
            individual_A=result_A,
            individual_B=result_B,
            fusion_method=fused_result['method'],
            emergence_score=fused_result['emergence'],
            explanation=self._generate_explanation_v2(fused_result, selected_mode),
            response_time_ms=response_time,
            entropy=fused_result.get('entropy', 0.0),
            cycle_number=self.context.cycle_number,
            ascent_level=self.context.ascent_level,
            dialogue_length=fused_result.get('dialogue_length', 0),
            consensus_quality=fused_result.get('consensus_quality', 0.0),
            nonlinear_breakdown=fused_result.get('breakdown'),
            complementary_preference=complementary_pref,  # ğŸ†• ç³»ç»Ÿåå¥½
            # ğŸ†• æ¶Œç°è¡Œä¸ºéªŒè¯æ ‡å¿—
            is_creative=fused_result.get('is_creative', False),
            original_space=fused_result.get('original_space', True),
            emergence_quality=fused_result.get('emergence', 0.0),  # ä½¿ç”¨emergenceä½œä¸ºquality
            # ğŸ”§ P0ä¿®å¤: å¡«å……ç¼ºå¤±å­—æ®µ
            system_a_confidence=system_a_conf,  # ç³»ç»ŸAç½®ä¿¡åº¦
            system_b_confidence=system_b_conf,  # ç³»ç»ŸBç½®ä¿¡åº¦
            reasoning=fused_result.get('reasoning', self._generate_explanation_v2(fused_result, selected_mode))  # æ¨ç†è¿‡ç¨‹
        )

    def _select_fusion_mode(
        self,
        result_A: Optional[Dict[str, Any]],
        result_B: Optional[Dict[str, Any]]
    ) -> FusionMode:
        """è‡ªé€‚åº”é€‰æ‹©èåˆæ¨¡å¼"""

        if self.fusion_mode == FusionMode.ADAPTIVE:
            # æ£€æŸ¥æœ€è¿‘æ¶Œç°è¡¨ç°
            if len(self.emergence_history) >= 10:
                recent_avg_emergence = np.mean(self.emergence_history[-10:])
                # å¦‚æœæ¶Œç°æŒç»­å¾ˆä½ï¼Œå¯ç”¨å¯¹è¯æ¨¡å¼
                if recent_avg_emergence < self.adaptive_threshold and self.dialogue_engine:
                    return FusionMode.DIALOGUE
                # å¦åˆ™ä½¿ç”¨éçº¿æ€§èåˆ
                elif self.nonlinear_fusion:
                    return FusionMode.NONLINEAR

            # é»˜è®¤ä½¿ç”¨éçº¿æ€§
            if self.nonlinear_fusion:
                return FusionMode.NONLINEAR
            else:
                return FusionMode.LINEAR
        else:
            return self.fusion_mode

    def _fuse_with_nonlinear(
        self,
        result_A: Optional[Dict[str, Any]],
        result_B: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """éçº¿æ€§èåˆ"""

        if result_A is None or result_B is None:
            return self._fuse_linear(result_A, result_B)

        fusion_result = self.nonlinear_fusion.fuse(
            result_A, result_B,
            self.context.weight_A,
            self.context.weight_B,
            context={'phase': self.context.phase}
        )

        # æ·»åŠ èºæ—‹ä¸Šå‡åŠ æˆ
        final_confidence = min(1.0, fusion_result['confidence'] + self.context.ascent_level)

        return {
            'action': fusion_result['action'],
            'confidence': final_confidence,
            'method': fusion_result['method'],
            'emergence': fusion_result['emergence'],
            'entropy': self._calculate_entropy(result_A, result_B),
            'breakdown': fusion_result['breakdown'],
            # ğŸ†• æ¶Œç°è¡Œä¸ºæ ‡å¿—
            'is_creative': fusion_result['emergence'] > 0.3,  # æ¶Œç°>0.3è§†ä¸ºåˆ›é€ æ€§
            'original_space': True  # éçº¿æ€§èåˆä»åœ¨åŸå§‹ç©ºé—´
        }

    def _fuse_with_dialogue(
        self,
        result_A: Optional[Dict[str, Any]],
        result_B: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """è¾©è®ºå¼å…±è¯†"""

        if result_A is None or result_B is None:
            return self._fuse_linear(result_A, result_B)

        consensus = self.dialogue_engine.engage_dialogue(
            result_A, result_B,
            context={'phase': self.context.phase}
        )

        # æ·»åŠ èºæ—‹ä¸Šå‡åŠ æˆ
        final_confidence = min(1.0, consensus.confidence + self.context.ascent_level)

        return {
            'action': consensus.action,
            'confidence': final_confidence,
            'method': 'dialogue_consensus',
            'emergence': consensus.emergence,
            'entropy': self._calculate_entropy(result_A, result_B),
            'dialogue_length': consensus.dialogue_length,
            'consensus_quality': consensus.consensus_quality,
            'breakdown': consensus.breakdown,
            # ğŸ†• æ¶Œç°è¡Œä¸ºæ ‡å¿—
            'is_creative': consensus.emergence > 0.4,  # å¯¹è¯æ¶Œç°>0.4è§†ä¸ºåˆ›é€ æ€§
            'original_space': True  # å¯¹è¯èåˆä»åœ¨åŸå§‹ç©ºé—´
        }

    def _fuse_linear(
        self,
        result_A: Optional[Dict[str, Any]],
        result_B: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """çº¿æ€§èåˆï¼ˆåŸç‰ˆï¼‰"""

        if result_A is None and result_B is None:
            return self._get_fallback()
        elif result_A is None:
            return {
                'action': result_B['action'],
                'confidence': result_B['confidence'],
                'method': 'B_only',
                'emergence': 0.0,
                'entropy': 0.5,
                # ğŸ†• æ¶Œç°è¡Œä¸ºæ ‡å¿—
                'is_creative': False,
                'original_space': True
            }
        elif result_B is None:
            return {
                'action': result_A['action'],
                'confidence': result_A['confidence'],
                'method': 'A_only',
                'emergence': 0.0,
                'entropy': 0.5,
                # ğŸ†• æ¶Œç°è¡Œä¸ºæ ‡å¿—
                'is_creative': False,
                'original_space': True
            }

        weight_A = self.context.weight_A
        weight_B = self.context.weight_B

        fused_action = int(weight_A * result_A['action'] + weight_B * result_B['action'])
        base_confidence = weight_A * result_A['confidence'] + weight_B * result_B['confidence']
        max_individual_confidence = max(result_A['confidence'], result_B['confidence'])
        real_synergy = base_confidence - max_individual_confidence
        ascent_bonus = self.context.ascent_level
        fused_confidence = min(1.0, base_confidence + ascent_bonus)
        emergence_score = max(0.0, real_synergy)

        if abs(weight_A - weight_B) < 0.1:
            method = 'linear_balanced'
        elif weight_A > weight_B:
            method = 'linear_A_dominant'
        else:
            method = 'linear_B_dominant'

        return {
            'action': fused_action,
            'confidence': fused_confidence,
            'method': method,
            'emergence': emergence_score,
            'entropy': self._calculate_entropy(result_A, result_B),
            # ğŸ†• æ¶Œç°è¡Œä¸ºæ ‡å¿—
            'is_creative': False,  # çº¿æ€§èåˆä¸æ˜¯åˆ›é€ æ€§çš„
            'original_space': True  # çº¿æ€§èåˆåœ¨åŸå§‹ç©ºé—´
        }

    def _update_parameters_from_meta(self, suggested_params: Dict[str, float]):
        """ä»å…ƒå­¦ä¹ å™¨æ›´æ–°å‚æ•°"""

        old_params = {
            'spiral_radius': self.spiral_radius,
            'phase_speed': self.phase_speed,
            'ascent_rate': self.ascent_rate
        }

        self.spiral_radius = suggested_params['spiral_radius']
        self.phase_speed = suggested_params['phase_speed']
        self.ascent_rate = suggested_params['ascent_rate']

        self.stats['meta_optimizations'] += 1

        logger.info(f"[åŒèºæ—‹v2] å…ƒå­¦ä¹ ä¼˜åŒ– #{self.stats['meta_optimizations']}")
        logger.info(f"[åŒèºæ—‹v2] æ—§å‚æ•°: {old_params}")
        logger.info(f"[åŒèºæ—‹v2] æ–°å‚æ•°: {suggested_params}")

    # ç»§æ‰¿åŸæœ‰æ–¹æ³•
    def _update_phase(self):
        """æ›´æ–°ç›¸ä½å’Œæƒé‡"""
        self.context.weight_A = 0.5 + self.spiral_radius * np.cos(self.phase)
        self.context.weight_B = 0.5 + self.spiral_radius * np.cos(self.phase + self.phase_shift)
        self.context.weight_A = max(0.0, self.context.weight_A)
        self.context.weight_B = max(0.0, self.context.weight_B)
        total_weight = self.context.weight_A + self.context.weight_B
        if total_weight > 0:
            self.context.weight_A /= total_weight
            self.context.weight_B /= total_weight
        self.context.phase = self.phase
        self.phase += self.phase_speed

    def _decide_A(self, state: np.ndarray, context: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ç³»ç»ŸAå†³ç­–"""
        if not self.seed:
            return None
        try:
            enhanced_state = self._enhance_state_A(state, context)
            action = self.seed.act(enhanced_state)
            _, uncertainty = self.seed.predict(enhanced_state, action)
            # ğŸ”§ [2026-01-17] å…³é”®ä¿®å¤: seed.predict()è¿”å›çš„æ˜¯uncertainty(ä¸ç¡®å®šæ€§)
            # å¿…é¡»è½¬æ¢ä¸ºconfidence: confidence = 1 - uncertainty
            confidence = float(np.clip(1.0 - uncertainty, 0, 1))
            logger.debug(f"[DEBUG-A] uncertainty={uncertainty:.4f} â†’ confidence={confidence:.4f}")
            return {'action': int(action), 'confidence': confidence, 'system': 'A'}
        except Exception as e:
            logger.warning(f"[åŒèºæ—‹v2] ç³»ç»ŸAå†³ç­–å¤±è´¥: {e}")
            return None

    def _decide_B(self, state: np.ndarray, context: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ç³»ç»ŸBå†³ç­–"""
        if not self.fractal:
            return None
        try:
            enhanced_state = self._enhance_state_B(state, context)
            state_tensor = torch.FloatTensor(enhanced_state).unsqueeze(0).to(self.device)

            # ğŸ”§ P1ä¿®å¤: ä½¿ç”¨decide()æ–¹æ³•è·å–åŠ¨æ€ç½®ä¿¡åº¦ï¼Œè€Œä¸æ˜¯ç›´æ¥è°ƒç”¨forward()
            if hasattr(self.fractal, 'decide'):
                # ğŸ”§ [2026-01-17] ä¿®å¤è°ƒè¯•æ—¥å¿—ï¼Œé¿å…è®¿é—®dictçš„shapeå±æ€§
                logger.debug(f"[DEBUG-B0] _decide_B called")
                logger.debug(f"[DEBUG-B0] enhanced_state shape: {enhanced_state.shape}")
                logger.debug(f"[DEBUG-B0] state_tensor shape: {state_tensor.shape}")

                # ä½¿ç”¨decideæ–¹æ³•ï¼Œå®ƒè¿”å›åŠ¨æ€è®¡ç®—çš„confidence
                output, info = self.fractal.decide(state_tensor)

                # ğŸ”§ [2026-01-17] ç®€åŒ–è°ƒè¯•æ—¥å¿—
                logger.debug(f"[DEBUG-B2] fractal.decide() returned, info keys: {info.keys() if isinstance(info, dict) else 'N/A'}")

                action = output.argmax().item() if output.dim() > 0 else int(output.item())
                confidence_raw = info.get('confidence', 0.5)  # ä»decideè·å–åŠ¨æ€confidence

                logger.debug(f"[DEBUG-B2] action: {action}, confidence: {float(confidence_raw):.4f}")

                confidence = confidence_raw
            else:
                logger.warning(f"[DEBUG-B2] fractal.decide() NOT found, using fallback")
                # å›é€€åˆ°åŸæ–¹æ¡ˆ
                output = self.fractal.core.forward(state_tensor)
                # å°è¯•ä»FractalOutputè·å–metaä¿¡æ¯
                if hasattr(output, 'entropy'):
                    # FractalOutputå¯¹è±¡ï¼Œä½†æ²¡æœ‰actionå­—æ®µï¼Œéœ€è¦ä»output tensorç”Ÿæˆ
                    action_tensor = output.output if hasattr(output, 'output') else output
                    action = action_tensor.argmax().item() if action_tensor.dim() > 0 else int(action_tensor.item())
                    # ä½¿ç”¨self_awarenessä½œä¸ºconfidence
                    if hasattr(output, 'self_awareness'):
                        confidence = output.self_awareness.mean().item()
                    else:
                        confidence = 0.5
                else:
                    # çº¯tensor
                    action = output.argmax().item() if output.dim() > 0 else int(output.item())
                    confidence = 0.5

            logger.info(f"[DEBUG-B3] Returning to double_helix: action={action}, confidence={confidence:.6f}")
            return {'action': int(action), 'confidence': float(confidence), 'system': 'B'}
        except Exception as e:
            logger.error(f"[åŒèºæ—‹v2] ç³»ç»ŸBå†³ç­–å¤±è´¥: {e}", exc_info=True)
            return None

    def _normalize_state(self, state: Any) -> np.ndarray:
        """
        ğŸ†• [2026-01-17] P0ä¿®å¤ï¼šçŠ¶æ€è¾“å…¥æ ‡å‡†åŒ–
        
        å°†å„ç§è¾“å…¥ç±»å‹è½¬æ¢ä¸ºnumpyæ•°ç»„
        """
        if isinstance(state, np.ndarray):
            return state.flatten() if state.ndim > 1 else state
        elif isinstance(state, dict):
            # ä»å­—å…¸æå–æ•°å€¼
            values = []
            for v in state.values():
                if isinstance(v, (int, float)):
                    values.append(float(v))
                elif isinstance(v, (list, tuple)):
                    values.extend([float(x) for x in v if isinstance(x, (int, float))])
            if not values:
                values = [0.0] * self.state_dim
            arr = np.array(values, dtype=np.float32)
            # å¡«å……æˆ–æˆªæ–­åˆ°state_dim
            if len(arr) < self.state_dim:
                arr = np.pad(arr, (0, self.state_dim - len(arr)))
            elif len(arr) > self.state_dim:
                arr = arr[:self.state_dim]
            return arr
        elif isinstance(state, (list, tuple)):
            arr = np.array(state, dtype=np.float32).flatten()
            if len(arr) < self.state_dim:
                arr = np.pad(arr, (0, self.state_dim - len(arr)))
            elif len(arr) > self.state_dim:
                arr = arr[:self.state_dim]
            return arr
        else:
            # å•ä¸ªå€¼ï¼Œå¡«å……ä¸ºstate_dim
            return np.full(self.state_dim, float(state) if isinstance(state, (int, float)) else 0.0, dtype=np.float32)

    def _enhance_state_A(self, state: np.ndarray, context: Dict[str, Any]) -> np.ndarray:
        """å¢å¼ºç³»ç»ŸAçš„çŠ¶æ€"""
        # ğŸ†• [2026-01-17] P0ä¿®å¤ï¼šç¡®ä¿stateæ˜¯æ­£ç¡®æ ¼å¼
        state = self._normalize_state(state)
        
        if self.context.last_B_output is not None:
            alpha = 0.7
            beta = 0.3
            enhanced = alpha * state + beta * self.context.last_B_output
            return enhanced
        return state

    def _enhance_state_B(self, state: np.ndarray, context: Dict[str, Any]) -> np.ndarray:
        """å¢å¼ºç³»ç»ŸBçš„çŠ¶æ€"""
        # ğŸ†• [2026-01-17] P0ä¿®å¤ï¼šç¡®ä¿stateæ˜¯æ­£ç¡®æ ¼å¼
        state = self._normalize_state(state)
        
        if self.context.last_A_output is not None:
            alpha = 0.7
            beta = 0.3
            enhanced = alpha * state + beta * self.context.last_A_output
            return enhanced
        return state

    def _update_context(self, result_A, result_B):
        """æ›´æ–°ä¸Šä¸‹æ–‡"""
        if result_A is not None:
            self.context.last_A_output = np.zeros(self.state_dim)
            self.context.last_A_output[result_A['action']] = result_A['confidence']
        if result_B is not None:
            self.context.last_B_output = np.zeros(self.state_dim)
            self.context.last_B_output[result_B['action']] = result_B['confidence']

    def _check_cycle_completion(self, confidence: float):
        """æ£€æµ‹å‘¨æœŸå®Œæˆå’Œèºæ—‹ä¸Šå‡"""
        self.confidence_history.append(confidence)
        if self.decision_count % self.cycle_length == 0:
            cycle_peak = max(self.confidence_history[-self.cycle_length:])
            self.cycle_peaks.append(cycle_peak)
            if len(self.cycle_peaks) >= 2:
                improvement = self.cycle_peaks[-1] - self.cycle_peaks[-2]
                if improvement > 0:
                    self.ascent_level += self.ascent_rate
                    self.context.ascent_level = self.ascent_level
                    logger.info(f"[åŒèºæ—‹v2] å‘¨æœŸ{self.cycle_number}å®Œæˆï¼Œå³°å€¼æå‡{improvement:.4f}ï¼Œä¸Šå‡è‡³{self.ascent_level:.4f}")
            self.cycle_number += 1
            self.context.cycle_number = self.cycle_number
            self.stats['cycles_completed'] += 1

    def _calculate_entropy(self, result_A, result_B) -> float:
        """è®¡ç®—ç†µ"""
        if result_A is None or result_B is None:
            return 0.0
        action_diff = abs(result_A['action'] - result_B['action'])
        confidence_diff = abs(result_A['confidence'] - result_B['confidence'])
        entropy = (action_diff / self.action_dim) * 0.5 + (confidence_diff * 0.5)
        return entropy

    def _update_stats(self, result: Dict[str, Any]):
        """æ›´æ–°ç»Ÿè®¡"""
        weight_A = self.context.weight_A
        weight_B = self.context.weight_B
        if abs(weight_A - weight_B) < 0.1:
            self.stats['balanced'] += 1
        elif weight_A > weight_B:
            self.stats['A_dominant'] += 1
        else:
            self.stats['B_dominant'] += 1
        emergence = result['emergence']
        if len(self.emergence_history) > 0:
            self.stats['avg_emergence'] = (
                self.stats['avg_emergence'] * len(self.emergence_history) + emergence
            ) / (len(self.emergence_history) + 1)
        else:
            self.stats['avg_emergence'] = emergence
        self.emergence_history.append(emergence)
        if len(self.confidence_history) > 0:
            self.stats['avg_confidence'] = np.mean(self.confidence_history)

    def _generate_explanation_v2(self, result: Dict[str, Any], mode: Optional[FusionMode]) -> str:
        """ç”Ÿæˆè§£é‡Šï¼ˆv2ç‰ˆï¼‰"""
        mode_str = mode.value if mode is not None else result.get('method', 'intelligent_fusion')
        explanation = f"åŒèºæ—‹v2èåˆ | æ¨¡å¼={mode_str} | ç›¸ä½={self.context.phase:.2f}"
        explanation += f" | Aæƒé‡={self.context.weight_A:.2f} Bæƒé‡={self.context.weight_B:.2f}"

        if result['emergence'] > 0.01:
            explanation += f" | æ¶Œç°+{result['emergence']:.4f}"

        if self.context.ascent_level > 0:
            explanation += f" | ä¸Šå‡å±‚çº§={self.context.ascent_level:.4f}"

        if 'dialogue_length' in result and result['dialogue_length'] > 0:
            explanation += f" | å¯¹è¯è½®æ•°={result['dialogue_length']}"

        if 'consensus_quality' in result and result['consensus_quality'] > 0:
            explanation += f" | å…±è¯†è´¨é‡={result['consensus_quality']:.2f}"

        return explanation

    def _get_fallback(self) -> Dict[str, Any]:
        """å…œåº•å†³ç­–"""
        return {
            'action': 0,
            'confidence': 0.5,
            'method': 'fallback',
            'emergence': 0.0,
            'entropy': 1.0,
            # ğŸ†• æ¶Œç°è¡Œä¸ºæ ‡å¿—
            'is_creative': False,
            'original_space': True
        }

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        base_stats = {
            **self.stats,
            'current_phase': self.context.phase,
            'current_weight_A': self.context.weight_A,
            'current_weight_B': self.context.weight_B,
            'cycle_number': self.context.cycle_number,
            'ascent_level': self.context.ascent_level,
            'cycle_peaks': self.cycle_peaks[-5:] if self.cycle_peaks else [],
            'recent_emergence': self.emergence_history[-10:] if self.emergence_history else [],
            'meta_optimizations': self.stats['meta_optimizations']
        }

        # æ·»åŠ v2ç»„ä»¶ç»Ÿè®¡
        if self.nonlinear_fusion:
            base_stats['nonlinear_fusion'] = self.nonlinear_fusion.get_statistics()

        if self.meta_learner:
            base_stats['meta_learning'] = self.meta_learner.get_statistics()

        if self.dialogue_engine:
            base_stats['dialogue'] = self.dialogue_engine.get_statistics()

        return base_stats


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("\n" + "="*70)
    print(" "*15 + "åŒèºæ—‹å†³ç­–å¼•æ“ v2.0 æµ‹è¯•")
    print("="*70)

    engine = DoubleHelixEngineV2(
        state_dim=64,
        action_dim=4,
        fusion_mode=FusionMode.ADAPTIVE,
        enable_nonlinear=True,
        enable_meta_learning=True,
        enable_dialogue=True,
        adaptive_threshold=0.02
    )

    print(f"\n[åˆå§‹åŒ–] åŒèºæ—‹v2å¼•æ“åˆ›å»ºæˆåŠŸ")
    print(f"[é…ç½®] èåˆæ¨¡å¼=adaptive, éçº¿æ€§=True, å…ƒå­¦ä¹ =True, å¯¹è¯=True")

    # æ‰§è¡Œ50æ¬¡å†³ç­–
    print(f"\n[æµ‹è¯•] æ‰§è¡Œ50æ¬¡å†³ç­–...")
    print("="*70)

    for i in range(50):
        state = np.random.randn(64)
        result = engine.decide(state)

        if (i + 1) % 10 == 0:
            print(f"\nå†³ç­– {i+1}/50:")
            print(f"  ç›¸ä½: {result.phase:.2f}")
            print(f"  æƒé‡: A={result.weight_A:.2f} B={result.weight_B:.2f}")
            print(f"  èåˆæ–¹æ³•: {result.fusion_method}")
            print(f"  ç½®ä¿¡åº¦: {result.confidence:.4f}")
            print(f"  æ¶Œç°åˆ†æ•°: {result.emergence_score:.4f}")

            if result.dialogue_length > 0:
                print(f"  å¯¹è¯è½®æ•°: {result.dialogue_length}")
                print(f"  å…±è¯†è´¨é‡: {result.consensus_quality:.2f}")

    # æ˜¾ç¤ºç»Ÿè®¡
    print("\n" + "="*70)
    print(" "*25 + "ç»Ÿè®¡ä¿¡æ¯")
    print("="*70)

    stats = engine.get_statistics()
    print(f"\næ€»å†³ç­–æ•°: {stats['total_decisions']}")
    print(f"Aä¸»å¯¼: {stats['A_dominant']}")
    print(f"Bä¸»å¯¼: {stats['B_dominant']}")
    print(f"å‡è¡¡: {stats['balanced']}")
    print(f"å¹³å‡æ¶Œç°åˆ†æ•°: {stats['avg_emergence']:.4f}")
    print(f"å¹³å‡ç½®ä¿¡åº¦: {stats['avg_confidence']:.4f}")
    print(f"å®Œæˆå‘¨æœŸ: {stats['cycles_completed']}")
    print(f"ä¸Šå‡å±‚çº§: {stats['ascent_level']:.4f}")

    print(f"\nèåˆæ¨¡å¼åˆ†å¸ƒ:")
    for mode, count in stats['fusion_modes_used'].items():
        print(f"  {mode}: {count}æ¬¡")

    print(f"\nå…ƒå­¦ä¹ ä¼˜åŒ–: {stats['meta_optimizations']}æ¬¡")

    if 'nonlinear_fusion' in stats:
        nf_stats = stats['nonlinear_fusion']
        print(f"\néçº¿æ€§èåˆç»Ÿè®¡:")
        print(f"  æ€»èåˆæ¬¡æ•°: {nf_stats['total_fusions']}")
        print(f"  å¹³å‡æ¶Œç°: {nf_stats['avg_emergence']:.4f}")
        print(f"  æ¶Œç°ç‡: {nf_stats['emergence_rate']:.2%}")

    if 'dialogue' in stats:
        d_stats = stats['dialogue']
        print(f"\nå¯¹è¯å¼•æ“ç»Ÿè®¡:")
        print(f"  æ€»å¯¹è¯æ•°: {d_stats['total_dialogues']}")
        print(f"  å¹³å‡å¯¹è¯é•¿åº¦: {d_stats['avg_dialogue_length']:.1f}")
        print(f"  å…±è¯†ç‡: {d_stats['consensus_rate']:.2%}")
        print(f"  å¹³å‡æ¶Œç°: {d_stats['avg_emergence']:.4f}")

    print("\n" + "="*70 + "\n")
