#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†å½¢æ™ºèƒ½æ ¸å¿ƒæ¨¡å— (Fractal Intelligence Core)
åŸºäºç¬¬ä¸€æ€§åŸç†æ¨å¯¼çš„è‡ªæŒ‡æ¶‰åˆ†å½¢æ‹“æ‰‘ç½‘ç»œå®ç°

æ•°å­¦åŸºç¡€ï¼šdocs/FLUID_INTELLIGENCE_MATHEMATICAL_FOUNDATION_20260112.md
å®æ–½è·¯çº¿ï¼šdocs/B_PLAN_IMPLEMENTATION_ROADMAP_20260112.md

æ ¸å¿ƒåˆ›æ–°ï¼š
1. è‡ªæŒ‡æ¶‰æ€§ï¼šç½‘ç»œèƒ½è§‚å¯Ÿå’Œä¿®æ”¹è‡ªèº«
2. åˆ†å½¢æ€§ï¼šä¸åŒå°ºåº¦ä¸Šçš„è‡ªç›¸ä¼¼ç»“æ„
3. ç›®æ ‡å¯å¡‘æ€§ï¼šèƒ½è´¨ç–‘å’Œä¿®æ”¹ä¼˜åŒ–ç›®æ ‡
4. ç†µé©±åŠ¨ï¼šå¥½å¥‡å¿ƒå‹åŠ›é˜€è°ƒèŠ‚æ¢ç´¢

ä½œè€…ï¼šClaude Code (Sonnet 4.5)
åˆ›å»ºæ—¥æœŸï¼š2026-01-12
ç‰ˆæœ¬ï¼šv1.0 (Bç»„)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import logging
from typing import Dict, Any, Optional, Tuple
from dataclasses import dataclass

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# æ³¨æ„ï¼šé€’å½’æ·±åº¦é™åˆ¶å·²ç§»é™¤ç¡¬ç¼–ç ï¼Œæ”¹ç”¨DynamicRecursionLimiter
# åŸMAX_RECURSION_DEPTH = 3å·²åºŸå¼ƒï¼Œä½¿ç”¨åŠ¨æ€é™åˆ¶å™¨æ›¿ä»£


@dataclass
class FractalOutput:
    """åˆ†å½¢ç½‘ç»œè¾“å‡ºæ•°æ®ç±»"""
    output: torch.Tensor
    self_awareness: torch.Tensor
    entropy: torch.Tensor
    goal_score: float
    metaparams: Tuple[float, float, float]  # (alpha, beta, gamma)


class SelfReferentialFractalCore(nn.Module):
    """
    è‡ªæŒ‡æ¶‰åˆ†å½¢æ ¸å¿ƒ

    æ•°å­¦å¯¹åº”ï¼šÎ¦ = f(Î¦, x)

    æ ¸å¿ƒç‰¹æ€§ï¼š
    1. è‡ªæŒ‡æ¶‰ï¼šç½‘ç»œç»´æŠ¤å…³äºè‡ªèº«çš„è¡¨ç¤º
    2. åˆ†å½¢ï¼šå¤šå±‚è‡ªç›¸ä¼¼é€’å½’ç»“æ„
    3. ç›®æ ‡å¯å¡‘ï¼šèƒ½è´¨ç–‘å’Œä¿®æ”¹ä¼˜åŒ–ç›®æ ‡
    4. ç†µé©±åŠ¨ï¼šå¥½å¥‡å¿ƒå‹åŠ›é˜€
    """

    def __init__(
        self,
        input_dim: int = 2,
        state_dim: int = 64,
        fractal_depth: int = 3,
        max_recursion: int = 3,
        device: str = 'cpu',
        entropy_temperature: float = 2.0,  # é»˜è®¤æ¸©åº¦2.0ï¼Œä½¿ç†µå€¼æ›´åˆç†
        enable_dynamic_recursion: bool = True  # æ–°å¢ï¼šå¯ç”¨åŠ¨æ€é€’å½’é™åˆ¶
    ):
        super().__init__()

        self.input_dim = input_dim
        self.state_dim = state_dim
        self.fractal_depth = fractal_depth
        self.max_recursion = max_recursion
        self.device = device
        self.entropy_temperature = entropy_temperature
        self.enable_dynamic_recursion = enable_dynamic_recursion

        # æ–°å¢ï¼šåŠ¨æ€é€’å½’é™åˆ¶å™¨
        if enable_dynamic_recursion:
            from core.dynamic_recursion_limiter import get_recursion_limiter
            self.recursion_limiter = get_recursion_limiter()
            logger.info("[åˆ†å½¢æ™ºèƒ½] åŠ¨æ€é€’å½’é™åˆ¶å™¨å·²å¯ç”¨")
        else:
            self.recursion_limiter = None
            logger.info("[åˆ†å½¢æ™ºèƒ½] ä½¿ç”¨å›ºå®šé€’å½’é™åˆ¶")

        # ========== å…³é”®åˆ›æ–°1ï¼šè‡ªæŒ‡æ¶‰çŠ¶æ€ ==========
        # ç½‘ç»œç»´æŠ¤ä¸€ä¸ª"å…³äºè‡ªèº«çš„è¡¨ç¤º"
        self.self_representation = nn.Parameter(
            torch.randn(state_dim, device=device) * 0.01,
            requires_grad=True  # å¯å­¦ä¹ çš„è‡ªæˆ‘æ¦‚å¿µ
        )

        # ========== å…³é”®åˆ›æ–°2ï¼šåˆ†å½¢é€’å½’å— ==========
        self.fractal_blocks = nn.ModuleList([
            FractalRecursiveBlock(
                state_dim=state_dim,
                depth=d,
                self_reflection=self.self_representation,
                device=device,
                recursion_limiter=self.recursion_limiter if enable_dynamic_recursion else None
            )
            for d in range(fractal_depth)
        ])

        # è¾“å…¥æŠ•å½±
        self.input_projection = nn.Linear(input_dim, state_dim).to(device)

        # è¾“å‡ºæŠ•å½±
        self.output_projection = nn.Linear(state_dim, 1).to(device)

        # ========== å…³é”®åˆ›æ–°3ï¼šç›®æ ‡è´¨ç–‘æ¨¡å—ï¼ˆActiveæ¨¡å¼ï¼‰==========
        self.goal_questioner = GoalQuestionerActive(state_dim, device=device)

        # ========== å…³é”®åˆ›æ–°4ï¼šå¥½å¥‡å¿ƒå‹åŠ›é˜€ ==========
        self.curiosity_valve = CuriosityPressureValve(state_dim, device=device)

        # ç”¨äºè¿½è¸ªå†å²
        self.entropy_history = []
        self.goal_score_history = []

        logger.info(f"SelfReferentialFractalCore initialized: "
                   f"state_dim={state_dim}, fractal_depth={fractal_depth}, "
                   f"device={device}")

    def forward(
        self,
        x: torch.Tensor,
        t: Optional[int] = None,
        return_meta: bool = True
    ) -> Tuple[torch.Tensor, Optional[FractalOutput]]:
        """
        å‰å‘ä¼ æ’­å®ç°è‡ªæŒ‡æ¶‰åˆ†å½¢æ¼”åŒ–

        æ•°å­¦å¯¹åº”ï¼šâˆ‚S/âˆ‚t = Î±Â·âˆ‡â‚›L_meta + Î²Â·âˆ‡á´¼L_goal + Î³Â·N
        """
        if x.dim() == 1:
            x = x.unsqueeze(0)

        x = x.to(self.device)

        # 1. è¾“å…¥æŠ•å½±
        state = self.input_projection(x)

        # 2. è®¡ç®—è‡ªæŒ‡æ¶‰æ„è¯†
        self_awareness = self._compute_self_awareness(state)

        # 3. åˆ†å½¢é€’å½’å¤„ç†
        fractal_outputs = []
        for i, block in enumerate(self.fractal_blocks):
            scale_factor = 0.7 ** i
            scaled_state = state * scale_factor
            output = block(scaled_state, self_awareness, t, recursion_depth=0)
            fractal_outputs.append(output)

        # 4. è‡ªæŒ‡æ¶‰èåˆ
        integrated = self._integrate_self_reference(fractal_outputs, self_awareness)

        # 5. è¾“å‡ºæŠ•å½±
        output = self.output_projection(integrated)

        # 6. è®¡ç®—å…ƒä¿¡æ¯
        entropy = self._compute_entropy(output, temperature=self.entropy_temperature)
        goal_score = self.goal_questioner(integrated.mean(0))

        # è¿½è¸ªå†å²
        self.entropy_history.append(entropy.item())
        self.goal_score_history.append(goal_score)

        # 7. å‹åŠ›é˜€è°ƒèŠ‚
        alpha, beta, gamma = self.curiosity_valve(entropy)

        if return_meta:
            meta = FractalOutput(
                output=output,
                self_awareness=self_awareness,
                entropy=entropy,
                goal_score=goal_score,
                metaparams=(alpha, beta, gamma)
            )
            return output, meta

        return output, None

    def _compute_self_awareness(self, state: torch.Tensor) -> torch.Tensor:
        """
        è®¡ç®—è‡ªæŒ‡æ¶‰æ„è¯†

        ğŸ”§ æ ¹æœ¬ä¿®å¤: ä»[1,1]ç»´åº¦æ”¹ä¸º[1, state_dim]ç»´åº¦

        æ•°å­¦å¯¹åº”ï¼šÎ¦_self = Î· Â· Ïƒ(S Â· Î¦_self_repr)
        """
        # ğŸ”§ ä¿®å¤å‰ï¼ˆé”™è¯¯ï¼‰:
        # interaction = torch.matmul(state, self.self_representation.T)  # [1,64] Ã— [64,1] = [1,1]
        # self_awareness = torch.sigmoid(interaction / (self.state_dim ** 0.5))  # [1,1] â† åªæœ‰1ä¸ªå…ƒç´ ï¼

        # ğŸ”§ ä¿®å¤åï¼ˆæ­£ç¡®ï¼‰:
        # ä½¿ç”¨element-wiseäº¤äº’ï¼Œä¿æŒstateçš„ç»´åº¦
        # state: [batch, state_dim], self_representation: [state_dim]
        interaction = state * self.self_representation  # å¹¿æ’­ä¹˜æ³•: [1,64] * [64] = [1,64]
        self_awareness = torch.sigmoid(interaction)  # [1,64] â† 64ä¸ªå…ƒç´ ï¼

        logger.info(f"[DEBUG-AWARENESS] _compute_self_awareness output shape: {self_awareness.shape}")
        logger.info(f"[DEBUG-AWARENESS] self_awareness min: {self_awareness.min().item():.6f}")
        logger.info(f"[DEBUG-AWARENESS] self_awareness max: {self_awareness.max().item():.6f}")
        logger.info(f"[DEBUG-AWARENESS] self_awareness mean: {self_awareness.mean().item():.6f}")
        logger.info(f"[DEBUG-AWARENESS] self_awareness std: {self_awareness.std().item():.6f}")

        return self_awareness

    def _integrate_self_reference(
        self,
        fractal_outputs: list,
        self_awareness: torch.Tensor
    ) -> torch.Tensor:
        """
        æ•´åˆè‡ªæŒ‡æ¶‰ä¿¡æ¯

        æ•°å­¦å¯¹åº”ï¼šI = âˆ« e^(-Î»s) Â· C(Î¦^s(S)) Â· R(Î¦^s(S)) ds
        """
        # åŠ æƒæ•´åˆä¸åŒåˆ†å½¢å°ºåº¦çš„è¾“å‡º
        weights = torch.softmax(
            torch.tensor(
                [0.7 ** i for i in range(len(fractal_outputs))],
                device=self.device
            ),
            dim=0
        )

        # Stackå’ŒåŠ æƒ
        stacked = torch.stack(fractal_outputs, dim=0)
        weighted = weights.view(-1, 1, 1) * stacked
        integrated = weighted.sum(0)

        # è‡ªæŒ‡æ¶‰è°ƒèŠ‚
        final = integrated * self_awareness + integrated * (1 - self_awareness)

        return final

    def _compute_entropy(self, output: torch.Tensor, temperature: float = 1.0) -> torch.Tensor:
        """
        è®¡ç®—è®¤çŸ¥ç†µï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼Œæ”¯æŒæ¸©åº¦å‚æ•°ï¼‰

        æ•°å­¦å¯¹åº”ï¼šH(S) = -âˆ‘p_i log p_i

        ä¼˜åŒ–ï¼š
        1. æ·»åŠ æ¸©åº¦å‚æ•°æ§åˆ¶åˆ†å¸ƒé”åº¦
        2. æ­£ç¡®å½’ä¸€åŒ–åˆ°[0, 1]èŒƒå›´
        3. æ·»åŠ æ›´å°çš„epsiloné˜²æ­¢æ•°å€¼é—®é¢˜

        Args:
            output: ç½‘ç»œè¾“å‡ºlogits
            temperature: æ¸©åº¦å‚æ•°ï¼ˆ>1ä½¿åˆ†å¸ƒæ›´å‡åŒ€ï¼Œ<1æ›´é”åˆ©ï¼‰

        Returns:
            å½’ä¸€åŒ–çš„ç†µå€¼ [0, 1]
        """
        # åº”ç”¨æ¸©åº¦å‚æ•°çš„softmax
        # temperature > 1: æ›´å‡åŒ€åˆ†å¸ƒ â†’ æ›´é«˜ç†µ
        # temperature < 1: æ›´é”åˆ©åˆ†å¸ƒ â†’ æ›´ä½ç†µ
        probs = F.softmax(output / temperature, dim=-1)

        # æ·»åŠ æå°é‡é˜²æ­¢log(0)
        log_probs = torch.log(probs + 1e-10)

        # è®¡ç®—ç†µï¼ˆé¦™å†œç†µï¼‰
        entropy = -(probs * log_probs).sum(dim=-1).mean()

        # å½’ä¸€åŒ–åˆ°[0, 1]èŒƒå›´
        # æœ€å¤§å¯èƒ½ç†µ = log(ç±»åˆ«æ•°)
        # å¯¹äºå•ä¸ªè¾“å‡ºå€¼ï¼Œæˆ‘ä»¬å°†å…¶è§†ä¸ºäºŒå…ƒåˆ†å¸ƒï¼Œæœ€å¤§ç†µ = log(2)
        max_entropy = np.log(2) if output.shape[-1] == 1 else np.log(output.shape[-1])
        normalized_entropy = entropy / (max_entropy + 1e-10)

        # ç¡®ä¿åœ¨[0, 1]èŒƒå›´å†…
        normalized_entropy = torch.clamp(normalized_entropy, min=0.0, max=1.0)

        return normalized_entropy

    def modify_goal(self, state: torch.Tensor):
        """
        ä¿®æ”¹ç›®æ ‡å‡½æ•°ï¼ˆActiveæ¨¡å¼ï¼‰

        è¿™æ˜¯Bç»„çš„å…³é”®ç‰¹æ€§ï¼šç³»ç»Ÿèƒ½çœŸæ­£è´¨ç–‘å’Œä¿®æ”¹è‡ªå·±çš„ç›®æ ‡
        """
        self.goal_questioner.modify_goal(state)

    def get_self_representation(self) -> torch.Tensor:
        """è·å–å½“å‰çš„è‡ªæŒ‡æ¶‰è¡¨ç¤º"""
        return self.self_representation.detach()

    def get_goal_representation(self) -> torch.Tensor:
        """è·å–å½“å‰çš„ç›®æ ‡è¡¨ç¤º"""
        return self.goal_questioner.goal_representation.detach()


class FractalRecursiveBlock(nn.Module):
    """
    åˆ†å½¢é€’å½’å—ï¼šæ¯ä¸€å±‚éƒ½æ˜¯æ•´ä¸ªç½‘ç»œçš„ç¼©æ”¾ç‰ˆæœ¬

    æ•°å­¦æ€§è´¨ï¼š
    - è‡ªç›¸ä¼¼æ€§ï¼šf(Î»x) ~ Î»f(x)
    - é€’å½’æ€§ï¼šf^((n))(x) = f(f^((n-1))(x))
    """

    def __init__(
        self,
        state_dim: int,
        depth: int,
        self_reflection: nn.Parameter,
        device: str = 'cpu',
        recursion_limiter = None  # æ–°å¢ï¼šé€’å½’é™åˆ¶å™¨å¼•ç”¨
    ):
        super().__init__()
        self.depth = depth
        self.state_dim = state_dim
        self.device = device
        self.recursion_limiter = recursion_limiter  # æ–°å¢ï¼šä¿å­˜é™åˆ¶å™¨å¼•ç”¨

        # ä¸»å¹²è·¯å¾„
        self.main_path = nn.Sequential(
            nn.Linear(state_dim, state_dim),
            nn.LayerNorm(state_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(state_dim, state_dim)
        ).to(device)

        # é€’å½’åˆ†å½¢åˆ†æ”¯ï¼ˆå¦‚æœdepth > 0ï¼‰
        if depth > 0:
            self.fractal_branch = FractalRecursiveBlock(
                state_dim,
                depth - 1,
                self_reflection,
                device
            )
            self.fractal_projection = nn.Linear(state_dim, state_dim).to(device)
        else:
            self.fractal_branch = None
            self.fractal_projection = None

        # é—¨æ§æœºåˆ¶
        self.gate = nn.Parameter(torch.zeros(1, device=device))
        self.self_gate = nn.Linear(state_dim, 1).to(device)

    def forward(
        self,
        x: torch.Tensor,
        self_awareness: torch.Tensor,
        t: Optional[int],
        recursion_depth: int = 0
    ) -> torch.Tensor:
        # åŠ¨æ€é€’å½’æ·±åº¦é™åˆ¶ï¼ˆæ–°å¢ï¼‰
        if self.recursion_limiter is not None:
            max_depth = self.recursion_limiter.get_current_limit()
        else:
            # é»˜è®¤é™åˆ¶ï¼ˆå‘åå…¼å®¹ï¼‰
            max_depth = 3

        if recursion_depth >= max_depth:
            return x

        # ä¸»å¹²å˜æ¢
        main = self.main_path(x)

        # åˆ†å½¢é€’å½’
        if self.fractal_branch is not None:
            scaled = x * 0.5
            fractal = self.fractal_branch(
                scaled,
                self_awareness,
                t,
                recursion_depth + 1
            )
            fractal = self.fractal_projection(fractal)
        else:
            fractal = torch.zeros_like(main)

        # è‡ªæŒ‡æ¶‰é—¨æ§
        self_gate_weight = torch.sigmoid(self.self_gate(x))

        # èåˆ
        gate = torch.sigmoid(self.gate) * self_gate_weight
        output = main + gate * fractal

        return output


class GoalQuestionerActive(nn.Module):
    """
    ç›®æ ‡è´¨ç–‘æ¨¡å— - Activeæ¨¡å¼

    ä¸Aç»„çš„å…³é”®åŒºåˆ«ï¼š
    - Aç»„ï¼šsuggest_onlyï¼ˆåªèƒ½å»ºè®®ï¼‰
    - Bç»„ï¼šactiveï¼ˆèƒ½çœŸæ­£ä¿®æ”¹ç›®æ ‡å‡½æ•°ï¼‰

    æ•°å­¦å¯¹åº”ï¼šL_goal^(t+1) = L_goal^(t) + ÎµÂ·E[âˆ‡â‚— I(S, L_goal)]
    """

    def __init__(self, state_dim: int, device: str = 'cpu'):
        super().__init__()
        self.state_dim = state_dim
        self.device = device
        self.mode = 'active'  # å…³é”®æ”¹åŠ¨

        # ç›®æ ‡è¡¨ç¤º
        self.goal_representation = nn.Parameter(
            torch.randn(state_dim, device=device) * 0.1,
            requires_grad=True
        )

        # è´¨ç–‘ç½‘ç»œ
        self.questioner = nn.Sequential(
            nn.Linear(state_dim * 2, state_dim),
            nn.LayerNorm(state_dim),
            nn.ReLU(),
            nn.Linear(state_dim, 1),
            nn.Sigmoid()
        ).to(device)

    def forward(self, state: torch.Tensor) -> float:
        """è¯„ä¼°å½“å‰ç›®æ ‡æ˜¯å¦åˆç†"""
        if state.dim() == 1:
            state = state.unsqueeze(0)

        goal_rep_2d = self.goal_representation.unsqueeze(0).expand_as(state)
        similarity = F.cosine_similarity(state, goal_rep_2d)

        combined = torch.cat([state, goal_rep_2d], dim=-1)
        question_score = self.questioner(combined)

        return question_score.item()

    def modify_goal(self, state: torch.Tensor):
        """
        ä¿®æ”¹ç›®æ ‡å‡½æ•°ï¼ˆActiveæ¨¡å¼çš„å…³é”®åŠŸèƒ½ï¼‰

        è¿™æ˜¯Bç»„åŒºåˆ«äºAç»„çš„æ ¸å¿ƒç‰¹æ€§
        """
        if state.dim() == 1:
            state = state.unsqueeze(0)

        with torch.enable_grad():
            goal_rep_2d = self.goal_representation.unsqueeze(0).expand_as(state)
            combined = torch.cat([state, goal_rep_2d], dim=-1)

            question_output = self.questioner(combined)
            goal_grad = torch.autograd.grad(
                outputs=question_output,
                inputs=self.goal_representation,
                create_graph=True,
                retain_graph=True
            )[0]

        with torch.no_grad():
            learning_rate = 0.001
            self.goal_representation += learning_rate * goal_grad.squeeze()

        logger.debug(f"Goal modified: grad_norm={torch.norm(goal_grad):.6f}")


class CuriosityPressureValve(nn.Module):
    """
    å¥½å¥‡å¿ƒå‹åŠ›é˜€ï¼šåŠ¨æ€è°ƒèŠ‚ç†µå€¼

    æ•°å­¦å¯¹åº”ï¼šæ ¹æ® H(S) è°ƒèŠ‚ Î±, Î², Î³

    åŠŸèƒ½ï¼š
    - é«˜ç†µ â†’ é™ä½æ¢ç´¢æƒé‡ï¼Œæé«˜åˆ©ç”¨æƒé‡
    - ä½ç†µ â†’ æé«˜æ¢ç´¢æƒé‡ï¼Œé™ä½åˆ©ç”¨æƒé‡
    """

    def __init__(
        self,
        state_dim: int,
        target_entropy: float = 0.9,
        device: str = 'cpu'
    ):
        super().__init__()
        self.target_entropy = target_entropy
        self.device = device

        self.valve_net = nn.Sequential(
            nn.Linear(1, 16),
            nn.ReLU(),
            nn.Linear(16, 3),
            nn.Sigmoid()
        ).to(device)

    def forward(self, current_entropy: torch.Tensor) -> Tuple[float, float, float]:
        """
        æ ¹æ®å½“å‰ç†µè¿”å›å…ƒå‚æ•°

        è¿”å›ï¼š(alphaæ¢ç´¢, betaç›®æ ‡, gammaåˆ›æ–°)
        """
        entropy_error = current_entropy - self.target_entropy

        adjustments = self.valve_net(
            torch.tensor([[entropy_error]], device=self.device)
        )

        alpha, beta, gamma = adjustments[0].unbind(0)

        # å½’ä¸€åŒ–
        total = alpha + beta + gamma + 1e-8
        return (alpha/total).item(), (beta/total).item(), (gamma/total).item()


class FractalIntelligenceAdapter:
    """
    åˆ†å½¢æ™ºèƒ½é€‚é…å™¨

    ç”¨äºå°†SelfReferentialFractalCoreé›†æˆåˆ°ç°æœ‰TRAE AGIç³»ç»Ÿ
    """

    def __init__(
        self,
        input_dim: int = 2,
        state_dim: int = 64,
        device: str = 'cpu'
    ):
        self.core = SelfReferentialFractalCore(
            input_dim=input_dim,
            state_dim=state_dim,
            device=device
        )
        self.device = device

        self.cognitive_bridge = None

        logger.info("FractalIntelligenceAdapter initialized")

    def set_cognitive_bridge(self, cognitive_bridge):
        """
        è®¾ç½®è®¤çŸ¥æ¡¥æ¥å™¨

        è®¤çŸ¥æ¡¥æ¥å™¨ä¸ºåˆ†å½¢æ™ºèƒ½æä¾›æ‹“æ‰‘è®°å¿†æŸ¥è¯¢å’Œå› æœæ¨ç†èƒ½åŠ›

        Args:
            cognitive_bridge: CognitiveBridge å®ä¾‹
        """
        self.cognitive_bridge = cognitive_bridge
        logger.info("CognitiveBridge connected to FractalIntelligence")

    def decide(
        self,
        state: torch.Tensor,
        context: Optional[Dict[str, Any]] = None
    ) -> Tuple[torch.Tensor, Dict[str, Any]]:
        """
        å†³ç­–å‡½æ•°ï¼ˆæ›¿ä»£å¤–éƒ¨LLMçš„ä¸»è¦åŠŸèƒ½ï¼‰

        è¿™æ˜¯é™ä½å¤–éƒ¨ä¾èµ–çš„å…³é”®æ–¹æ³•
        """
        with torch.no_grad():
            output, meta = self.core(state, return_meta=True)

            # ğŸ”§ ç´§æ€¥è¯Šæ–­: è¯¦ç»†è®°å½•self_awarenessçš„è®¡ç®—è¿‡ç¨‹
            logger.info(f"[DEBUG-B1] meta.self_awareness shape: {meta.self_awareness.shape}")
            logger.info(f"[DEBUG-B1] meta.self_awareness dtype: {meta.self_awareness.dtype}")
            logger.info(f"[DEBUG-B1] meta.self_awareness device: {meta.self_awareness.device}")
            logger.info(f"[DEBUG-B1] meta.self_awareness raw values:\n{meta.self_awareness}")
            logger.info(f"[DEBUG-B1] self_awareness min: {meta.self_awareness.min().item():.6f}")
            logger.info(f"[DEBUG-B1] self_awareness max: {meta.self_awareness.max().item():.6f}")
            logger.info(f"[DEBUG-B1] self_awareness std: {meta.self_awareness.std().item():.6f}")
            logger.info(f"[DEBUG-B1] self_awareness.mean() BEFORE final: {meta.self_awareness.mean().item():.6f}")

            # æå–å†³ç­–ä¿¡æ¯
            entropy = meta.entropy.item()
            goal_score = meta.goal_score

            # ğŸ”§ æ ¹æœ¬ä¿®å¤: ä½¿ç”¨goal_scoreä½œä¸ºconfidenceï¼ˆåŠ¨æ€å˜åŒ–ï¼‰
            # åŸå› : self_awarenessåªæœ‰[1,1]ä¸ªå…ƒç´ ï¼Œmean()æ— æ„ä¹‰
            # è€Œgoal_scoreåœ¨0.4-0.6èŒƒå›´åŠ¨æ€å˜åŒ–ï¼Œæ›´æœ‰ä»£è¡¨æ€§
            confidence_old = meta.self_awareness.mean().item()
            confidence = float(goal_score)

            logger.info(f"[DEBUG-B1] confidence_old (self_awareness.mean()): {confidence_old:.6f}")
            logger.info(f"[DEBUG-B1] confidence_NEW (goal_score): {confidence:.6f}")
            logger.info(f"[DEBUG-B1] entropy: {entropy:.6f}")
            logger.info(f"[DEBUG-B1] goal_score: {goal_score}")
            logger.info(f"[DEBUG-B1] FINAL confidence: {confidence:.6f}")

            # å¦‚æœç½®ä¿¡åº¦é«˜ï¼Œç›´æ¥ä½¿ç”¨æœ¬åœ°ç»“æœ
            if confidence > 0.7:
                return output, {
                    'source': 'fractal_core',
                    'confidence': confidence,
                    'entropy': entropy,
                    'goal_score': goal_score,
                    'local_decision': True
                }
            else:
                # ä½ç½®ä¿¡åº¦ï¼šéœ€è¦å¤–éƒ¨LLMéªŒè¯
                return output, {
                    'source': 'fractal_core',
                    'confidence': confidence,
                    'entropy': entropy,
                    'goal_score': goal_score,
                    'local_decision': False,
                    'needs_validation': True
                }

    def learn(
        self,
        experience: Dict[str, Any],
        reward: float
    ):
        """
        ä»ç»éªŒä¸­å­¦ä¹ ï¼ˆæ”¯æŒåœ¨çº¿å­¦ä¹ ï¼‰
        """
        # è¿™é‡Œå¯ä»¥å®ç°ç®€å•çš„åœ¨çº¿å­¦ä¹ 
        # ä¾‹å¦‚ï¼šæ›´æ–°ç›®æ ‡å‡½æ•°
        if 'state' in experience:
            state = experience['state']
            self.core.modify_goal(state)


# ä¾¿æ·å‡½æ•°
def create_fractal_intelligence(
    input_dim: int = 2,
    state_dim: int = 64,
    device: str = 'cpu'
) -> FractalIntelligenceAdapter:
    """
    åˆ›å»ºåˆ†å½¢æ™ºèƒ½ç³»ç»Ÿ

    Args:
        input_dim: è¾“å…¥ç»´åº¦
        state_dim: å†…éƒ¨çŠ¶æ€ç»´åº¦
        device: è®¾å¤‡ï¼ˆ'cpu'æˆ–'cuda'ï¼‰

    Returns:
        åˆ†å½¢æ™ºèƒ½é€‚é…å™¨å®ä¾‹
    """
    return FractalIntelligenceAdapter(
        input_dim=input_dim,
        state_dim=state_dim,
        device=device
    )


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)

    print("="*60)
    print("[æµ‹è¯•] åˆ†å½¢æ™ºèƒ½æ ¸å¿ƒæ¨¡å—")
    print("="*60)

    # åˆ›å»ºåˆ†å½¢æ™ºèƒ½æ ¸å¿ƒ
    adapter = create_fractal_intelligence(
        input_dim=2,
        state_dim=64,
        device='cpu'
    )

    # æµ‹è¯•å‰å‘ä¼ æ’­
    x = torch.randn(10, 2)
    output, meta = adapter.core(x, return_meta=True)

    print(f"\n[ç»“æœ] è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"[ç»“æœ] è‡ªæˆ‘æ„è¯†å¼ºåº¦: {meta.self_awareness.mean():.4f}")
    print(f"[ç»“æœ] è®¤çŸ¥ç†µ: {meta.entropy:.4f}")
    print(f"[ç»“æœ] ç›®æ ‡å¾—åˆ†: {meta.goal_score:.4f}")
    print(f"[ç»“æœ] å…ƒå‚æ•°: Î±={meta.metaparams[0]:.4f}, "
          f"Î²={meta.metaparams[1]:.4f}, Î³={meta.metaparams[2]:.4f}")

    # æµ‹è¯•ç›®æ ‡ä¿®æ”¹
    state = torch.randn(64)
    adapter.core.modify_goal(state)
    print(f"\n[ç»“æœ] ç›®æ ‡å·²ä¿®æ”¹")

    print("\n" + "="*60)
    print("[æˆåŠŸ] åˆ†å½¢æ™ºèƒ½æ ¸å¿ƒæ¨¡å—æµ‹è¯•é€šè¿‡")
    print("="*60)
