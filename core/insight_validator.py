"""
æ´å¯ŸéªŒè¯å™¨ (Insight Validator)
å®ç°è‡ªåŠ¨éªŒè¯ç”Ÿæˆçš„æ´å¯Ÿä»£ç ï¼Œç¡®ä¿åªæœ‰é«˜è´¨é‡çš„æ´å¯Ÿè¢«é›†æˆåˆ°ç³»ç»Ÿä¸­ã€‚

éªŒè¯å±‚çº§ï¼š
1. è¯­æ³•éªŒè¯ - ASTè§£ææ£€æŸ¥Pythonè¯­æ³•
2. å®‰å…¨æ€§æ£€æŸ¥ - æ£€æµ‹å±é™©æ“ä½œï¼ˆæ–‡ä»¶åˆ é™¤ã€ç½‘ç»œè¯·æ±‚ç­‰ï¼‰
3. å•å…ƒæµ‹è¯•ç”Ÿæˆ - è‡ªåŠ¨ä¸ºæ´å¯Ÿç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
4. æ€§èƒ½åŸºå‡†æµ‹è¯• - æµ‹è¯•ä»£ç æ‰§è¡Œæ•ˆç‡
5. è¯­ä¹‰éªŒè¯ - æ£€æŸ¥ä»£ç æ˜¯å¦çœŸæ­£å®ç°å£°ç§°çš„åŠŸèƒ½

ğŸ†• [2026-01-10] å¢å¼ºéªŒè¯å±‚çº§ï¼ˆè§£å†³ä¼ªä»£ç é—®é¢˜ï¼‰:
L1: ä¾èµ–åˆ†æ - æ£€æŸ¥æ‰€æœ‰è°ƒç”¨çš„å‡½æ•°æ˜¯å¦å­˜åœ¨
L2: æ²™ç®±æ‰§è¡Œ - çœŸæ­£è¿è¡Œä»£ç ï¼Œæ•è·è¿è¡Œæ—¶é”™è¯¯
"""

import ast
import time
import traceback
import re
import sys
import io
import builtins
import subprocess
import inspect
from typing import Dict, Any, List, Tuple, Set, Optional
from contextlib import redirect_stdout, redirect_stderr
import importlib.util
import tempfile
import os
import logging

logger = logging.getLogger(__name__)

# ============================================================================
# ğŸ†• ç³»ç»Ÿå‡½æ•°ä¾èµ–æ³¨å†Œè¡¨ï¼ˆç™½åå•ï¼‰
# ============================================================================
SYSTEM_FUNCTION_REGISTRY: Set[str] = {
    # Python å†…ç½®å‡½æ•°
    'abs', 'all', 'any', 'ascii', 'bin', 'bool', 'breakpoint', 'bytearray',
    'bytes', 'callable', 'chr', 'classmethod', 'compile', 'complex',
    'delattr', 'dict', 'dir', 'divmod', 'enumerate', 'eval', 'exec',
    'filter', 'float', 'format', 'frozenset', 'getattr', 'globals',
    'hasattr', 'hash', 'help', 'hex', 'id', 'input', 'int', 'isinstance',
    'issubclass', 'iter', 'len', 'list', 'locals', 'map', 'max',
    'memoryview', 'min', 'next', 'object', 'oct', 'open', 'ord', 'pow',
    'print', 'property', 'range', 'repr', 'reversed', 'round', 'set',
    'setattr', 'slice', 'sorted', 'staticmethod', 'str', 'sum', 'super',
    'tuple', 'type', 'vars', 'zip',
    # å¸¸ç”¨æ ‡å‡†åº“å‡½æ•°ï¼ˆå¯å®‰å…¨ä½¿ç”¨ï¼‰
    'sqrt', 'sin', 'cos', 'tan', 'log', 'exp', 'floor', 'ceil',
    'random', 'randint', 'choice', 'shuffle', 'sample',
    'time', 'sleep',
    'json', 'loads', 'dumps',
    're', 'match', 'search', 'findall', 'sub',
    # ç±»å‹æ³¨è§£
    'Optional', 'List', 'Dict', 'Tuple', 'Set', 'Any', 'Union',
    # ğŸ”§ P1ä¿®å¤: NumPyå¸¸ç”¨å‡½æ•°ï¼ˆç”¨äºç§‘å­¦è®¡ç®—å’ŒInsightç”Ÿæˆï¼‰
    'maximum', 'minimum', 'real', 'imag', 'conj', 'conjugate',
    'fft', 'ifft', 'fftn', 'ifftn', 'fft2', 'ifft2', 'fftshift', 'ifftshift',
    'fftfreq', 'rfft', 'irfft', 'rfftn', 'irfftn',
    'astype', 'copy', 'transpose', 'reshape', 'flatten', 'ravel', 'squeeze',
    'expand_dims', 'squeeze', 'clip', 'abs', 'sqrt', 'square', 'exp', 'log', 'log10',
    'mean', 'median', 'std', 'var', 'sum', 'prod', 'cumsum', 'cumprod',
    'min', 'max', 'argmin', 'argmax', 'argsort', 'sort', 'sort_complex',
    'dot', 'matmul', 'tensordot', 'inner', 'outer', 'kron', 'einsum',
    'concatenate', 'stack', 'vstack', 'hstack', 'dstack', 'column_stack',
    'split', 'array_split', 'hsplit', 'vsplit', 'dsplit',
    'arange', 'linspace', 'logspace', 'geomspace', 'meshgrid', 'mgrid', 'ogrid',
    'zeros', 'ones', 'empty', 'full', 'zeros_like', 'ones_like', 'empty_like', 'full_like',
    'eye', 'identity', 'diag', 'diagflat', 'tri', 'tril', 'triu', 'vander',
    'tile', 'repeat', 'broadcast_to', 'broadcast_arrays',
    'rand', 'randn', 'randint', 'random', 'random_sample', 'ranf', 'sample',
    'choice', 'permutation', 'shuffle', 'seed',
    'load', 'save', 'savez', 'savez_compressed', 'txt', 'fromtxt', 'loadtxt', 'savetxt',
    # ğŸ”§ P1ä¿®å¤: PyTorchå¸¸ç”¨å‡½æ•°ï¼ˆç”¨äºæ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œï¼‰
    'tensor', 'zeros_', 'ones_', 'empty_', 'full_',
    'from_numpy', 'to', 'cpu', 'cuda', 'numpy',
    'sigmoid', 'tanh', 'relu', 'softmax', 'log_softmax', 'softmin',
    'binary_cross_entropy', 'mse_loss', 'l1_loss', 'nll_loss', 'cross_entropy',
    'argmax', 'argmin', 'topk', 'kthvalue', 'unique', 'unique_consecutive',
    'gather', 'scatter', 'index_select', 'index_add', 'index_fill',
    'cat', 'stack', 'hstack', 'vstack', 'dstack', 'chunk', 'split', 'unbind',
    'transpose', 'permute', 'reshape', 'view', 'unsqueeze', 'squeeze', 'flatten',
    'clone', 'detach', 'grad', 'no_grad', 'enable_grad', 'set_grad_enabled',
    'nn', 'optim', 'functional', 'utils',
    # ğŸ”§ P1ä¿®å¤: å…¶ä»–ç§‘å­¦è®¡ç®—å‡½æ•°
    'predict', 'predict_proba', 'fit', 'transform', 'fit_transform',
    'entropy', 'kl_divergence', 'mutual_info', 'cosine_similarity',
    'reconstruct', 'compress', 'decompress',
    'compress_function', 'update_signature', 'update',
    'encode', 'decode', 'embed', 'embedding',
    'normalize', 'scale', 'standardize', 'minmax_scale',
    'cluster', 'classify', 'regress', 'segment',
    # ğŸ”§ P1ä¿®å¤: å¸¸è§ç¬¬ä¸‰æ–¹åº“å‡½æ•°
    'DataFrame', 'Series', 'read_csv', 'to_csv', 'read_json', 'to_json',
    'figure', 'plot', 'show', 'savefig', 'subplot', 'subplots',
    'requests_get', 'requests_post', 'get', 'post',
    # ğŸ”§ [2026-01-15] P0ä¿®å¤: Pythonå†…ç½®æ–¹æ³•å’ŒNumPy/PyTorchå¸¸ç”¨æ–¹æ³•
    'item', 'items', 'keys', 'values', 'get', 'append', 'extend', 'pop',
    'tolist', 'numpy', 'cpu', 'cuda', 'float', 'long', 'int', 'bool',
    'size', 'shape', 'ndim', 'dtype', 'T', 'contiguous', 'detach',
    # ğŸ”§ [2026-01-15] æ–°å¢ï¼šInsightå®ç”¨å‡½æ•°åº“ï¼ˆæå‡å¯æ‰§è¡Œæ€§ï¼‰
    'invert_causal_chain', 'perturb_attention_weights', 'simulate_forward',
    'rest_phase_reorganization', 'noise_guided_rest', 'semantic_perturb',
    'analyze_tone', 'semantic_diode', 'detect_topological_defect',
    'fractal_idle_pulse', 'reverse_abduction_step', 'inject_adversarial_intuition',
    'latent_recombination', 'kl_div', 'CurlLayer',
}

# æ ‡å‡†åº“æ¨¡å—ï¼ˆå¯ä»¥å®‰å…¨å¯¼å…¥çš„ï¼‰
SAFE_MODULES: Set[str] = {
    'math', 'random', 'time', 'datetime', 'json', 're', 'collections',
    'itertools', 'functools', 'operator', 'copy', 'typing', 'dataclasses',
    'enum', 'statistics', 'decimal', 'fractions', 'numbers', 'cmath',
    'array', 'bisect', 'heapq', 'queue', 'struct', 'weakref',
    'string', 'textwrap', 'difflib', 'unicodedata', 'io',
    'abc', 'contextlib', 'warnings', 'logging', 'traceback',
    # ğŸ”§ P1ä¿®å¤: ç§‘å­¦è®¡ç®—æ¨¡å—ï¼ˆç”¨äºInsightç”Ÿæˆï¼‰
    'numpy', 'np',
    'torch', 'torch.nn', 'torch.nn.functional', 'torch.optim',
    'scipy', 'scipy.fft', 'scipy.stats', 'scipy.signal',
    'pandas', 'pd',
    'matplotlib', 'matplotlib.pyplot', 'plt',
    'sklearn', 'sklearn.metrics', 'sklearn.model_selection',
    # ğŸ”§ [2026-01-15] æ–°å¢ï¼šInsightå®ç”¨æ¨¡å—ï¼ˆæå‡å¯æ‰§è¡Œæ€§ï¼‰
    'core.insight_utilities', 'insight_utilities',
}


class InsightValidator:
    """
    æ´å¯ŸéªŒè¯å™¨ - ç¡®ä¿ç”Ÿæˆçš„æ´å¯Ÿä»£ç å¯æ‰§è¡Œä¸”æœ‰ä»·å€¼
    
    ğŸ†• [2026-01-24] æ‹“æ‰‘è¿æ¥å¢å¼º:
    - æ–°å¢ HallucinationAwareLLMEngine è¿æ¥ï¼šå¯¹æ´å¯Ÿå†…å®¹è¿›è¡Œå¹»è§‰æ£€æµ‹ååŒéªŒè¯
    """
    
    # å±é™©æ“ä½œé»‘åå•
    DANGEROUS_MODULES = {'os', 'subprocess', 'shutil', 'socket', 'requests', 'urllib'}
    DANGEROUS_FUNCTIONS = {'exec', 'eval', 'compile', '__import__', 'open'}
    DANGEROUS_ATTRIBUTES = {'__delattr__', '__setattr__', '__delete__'}
    
    def __init__(self, system_dependency_graph: Optional[Dict[str, bool]] = None,
                 hallucination_detector=None):
        """
        åˆå§‹åŒ–æ´å¯ŸéªŒè¯å™¨
        
        Args:
            system_dependency_graph: ç³»ç»Ÿä¾èµ–å›¾
            hallucination_detector: ğŸ†• å¹»è§‰æ£€æµ‹å™¨ï¼ˆç”¨äºéªŒè¯ååŒï¼‰
        """
        self.validation_history = []
        # ğŸ†• ç³»ç»Ÿä¾èµ–å›¾ï¼šè®°å½•ç³»ç»Ÿä¸­å·²å­˜åœ¨çš„å‡½æ•°
        self.system_dependency_graph = system_dependency_graph or {}
        # ğŸ†• éªŒè¯é€€ç«çŠ¶æ€
        self._validation_backoff_until = 0.0
        self._validation_failure_count = 0
        # ğŸ†• [2026-01-24] æ‹“æ‰‘è¿æ¥: å¹»è§‰æ£€æµ‹å™¨
        self.hallucination_detector = hallucination_detector
        
    def validate(self, code: str, insight_metadata: Dict[str, Any]) -> Dict[str, Any]:
        """
        å®Œæ•´éªŒè¯æµç¨‹ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        è¿”å›æ ¼å¼:
        {
            'valid': bool,
            'score': float (0-1),
            'checks': {
                'syntax': bool,
                'safety': bool,
                'dependency': bool,    # ğŸ†• ä¾èµ–æ£€æŸ¥
                'sandbox': bool,       # ğŸ†• æ²™ç®±æ‰§è¡Œ
                'unit_test': bool,
                'performance': bool,
                'semantic': bool
            },
            'errors': List[str],
            'warnings': List[str],
            'missing_deps': List[str],  # ğŸ†• ç¼ºå¤±çš„ä¾èµ–å‡½æ•°
            'execution_time': float,
            'recommendation': str  # 'INTEGRATE', 'ARCHIVE', 'REJECT'
        }
        """
        result = {
            'valid': False,
            'score': 0.0,
            'checks': {},
            'errors': [],
            'warnings': [],
            'missing_deps': [],
            'execution_time': 0.0,
            'recommendation': 'REJECT'
        }
        
        start_time = time.time()
        
        # ğŸ†• æ£€æŸ¥éªŒè¯é€€ç«çŠ¶æ€
        now_ts = time.time()
        if now_ts < self._validation_backoff_until:
            remaining = int(self._validation_backoff_until - now_ts)
            result['errors'].append(f"éªŒè¯é€€ç«ä¸­ï¼ˆå‰©ä½™{remaining}sï¼‰")
            result['execution_time'] = time.time() - start_time
            return result
        
        # 1. è¯­æ³•éªŒè¯
        syntax_valid, syntax_error = self._check_syntax(code)
        result['checks']['syntax'] = syntax_valid
        if not syntax_valid:
            result['errors'].append(f"è¯­æ³•é”™è¯¯: {syntax_error}")
            result['execution_time'] = time.time() - start_time
            return result
        
        # 2. å®‰å…¨æ€§æ£€æŸ¥
        safety_valid, safety_warnings = self._check_safety(code)
        result['checks']['safety'] = safety_valid
        result['warnings'].extend(safety_warnings)
        if not safety_valid:
            result['errors'].append("å®‰å…¨æ£€æŸ¥å¤±è´¥: æ£€æµ‹åˆ°å±é™©æ“ä½œ")
            result['execution_time'] = time.time() - start_time
            return result
        
        # ğŸ†• 3. ä¾èµ–åˆ†æï¼ˆå…³é”®æ–°å¢ï¼‰
        deps_valid, missing_deps = self._check_dependencies(code)
        result['checks']['dependency'] = deps_valid
        result['missing_deps'] = missing_deps
        if not deps_valid:
            result['errors'].append(f"ä¾èµ–æ£€æŸ¥å¤±è´¥: ç¼ºå°‘å‡½æ•° {', '.join(missing_deps[:5])}")
            self._record_validation_failure()
            result['execution_time'] = time.time() - start_time
            return result
        
        # ğŸ†• 4. æ²™ç®±æ‰§è¡Œï¼ˆçœŸæ­£è¿è¡Œä»£ç ï¼‰
        sandbox_valid, sandbox_error = self._run_in_sandbox(code)
        result['checks']['sandbox'] = sandbox_valid
        if not sandbox_valid:
            result['errors'].append(f"æ²™ç®±æ‰§è¡Œå¤±è´¥: {sandbox_error}")
            self._record_validation_failure()
            result['execution_time'] = time.time() - start_time
            return result
        
        # 5. å•å…ƒæµ‹è¯•ç”Ÿæˆä¸æ‰§è¡Œ
        test_valid, test_coverage = self._run_unit_tests(code, insight_metadata)
        result['checks']['unit_test'] = test_valid
        result['test_coverage'] = test_coverage
        if not test_valid:
            result['warnings'].append(f"å•å…ƒæµ‹è¯•è¦†ç›–ç‡ä½: {test_coverage:.1%}")
        
        # 6. æ€§èƒ½åŸºå‡†æµ‹è¯•
        perf_valid, exec_time = self._benchmark_performance(code)
        result['checks']['performance'] = perf_valid
        result['execution_time'] = exec_time
        if not perf_valid:
            result['warnings'].append(f"æ€§èƒ½ä¸è¶³: æ‰§è¡Œæ—¶é—´{exec_time:.3f}sè¶…è¿‡é˜ˆå€¼")
        
        # 7. è¯­ä¹‰éªŒè¯ï¼ˆæ£€æŸ¥ä»£ç æ˜¯å¦å®ç°å£°ç§°çš„åŠŸèƒ½ï¼‰
        semantic_valid, semantic_score = self._validate_semantics(code, insight_metadata)
        result['checks']['semantic'] = semantic_valid
        if not semantic_valid:
            result['warnings'].append("è¯­ä¹‰éªŒè¯å¤±è´¥: ä»£ç ä¸æ´å¯Ÿæè¿°ä¸åŒ¹é…")
        
        # ğŸ†• [2026-01-24] 8. å¹»è§‰ååŒéªŒè¯ï¼ˆä½¿ç”¨HallucinationAwareLLMEngineï¼‰
        hallucination_valid = True
        if self.hallucination_detector and insight_metadata.get('description'):
            try:
                hallucination_result = self.hallucination_detector.detect(
                    llm_output=insight_metadata.get('description', ''),
                    context={'code': code, 'source': 'insight_validator'}
                )
                hallucination_valid = not hallucination_result.is_hallucination
                result['checks']['hallucination'] = hallucination_valid
                if not hallucination_valid:
                    result['warnings'].append(f"å¹»è§‰æ£€æµ‹è­¦å‘Š: {hallucination_result.issues[:2]}")
                    logger.debug(f"[InsightValidator] å¹»è§‰æ£€æµ‹: {hallucination_result.issues}")
            except Exception as hal_err:
                logger.debug(f"[InsightValidator] å¹»è§‰æ£€æµ‹è·³è¿‡: {hal_err}")
                result['checks']['hallucination'] = True  # æ£€æµ‹å¤±è´¥æ—¶ä¸é˜»å¡
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼ˆæ›´æ–°æƒé‡ï¼‰
        result['valid'] = all([
            syntax_valid,
            safety_valid,
            deps_valid,      # ğŸ†• ä¾èµ–å¿…é¡»é€šè¿‡
            sandbox_valid,   # ğŸ†• æ²™ç®±å¿…é¡»é€šè¿‡
            test_valid or test_coverage > 0.5,
            perf_valid or exec_time < 1.0
        ])
        
        # ğŸ†• æ›´æ–°åŠ æƒè¯„åˆ†ï¼ˆå¢åŠ ä¾èµ–å’Œæ²™ç®±æƒé‡ï¼‰
        weights = {
            'syntax': 0.15, 
            'safety': 0.15, 
            'dependency': 0.20,  # ğŸ†• å…³é”®æ£€æŸ¥
            'sandbox': 0.20,     # ğŸ†• å…³é”®æ£€æŸ¥
            'unit_test': 0.15, 
            'performance': 0.08, 
            'semantic': 0.07
        }
        result['score'] = sum(
            weights.get(k, 0.0) * (1.0 if v else 0.0) 
            for k, v in result['checks'].items()
        )
        
        # æ ¹æ®è¯„åˆ†ç»™å‡ºå»ºè®®ï¼ˆä¾èµ–å’Œæ²™ç®±å¤±è´¥ç›´æ¥æ‹’ç»ï¼‰
        if not deps_valid or not sandbox_valid:
            result['recommendation'] = 'REJECT'
        elif result['score'] >= 0.8:
            result['recommendation'] = 'INTEGRATE'
        elif result['score'] >= 0.6:
            result['recommendation'] = 'ARCHIVE'  # å½’æ¡£å¾…æ”¹è¿›
        else:
            result['recommendation'] = 'REJECT'
        
        # ğŸ†• æˆåŠŸéªŒè¯é‡ç½®é€€ç«è®¡æ•°
        if result['valid']:
            self._validation_failure_count = 0
        
        result['execution_time'] = time.time() - start_time
        self.validation_history.append(result)
        
        return result
    
    def _record_validation_failure(self):
        """è®°å½•éªŒè¯å¤±è´¥ï¼Œç”¨äºé€€ç«ç­–ç•¥"""
        self._validation_failure_count += 1
        if self._validation_failure_count >= 3:
            # è¿ç»­3æ¬¡å¤±è´¥ï¼Œè§¦å‘60ç§’é€€ç«
            self._validation_backoff_until = time.time() + 60.0
            logger.warning(f"[InsightValidator] è¿ç»­{self._validation_failure_count}æ¬¡éªŒè¯å¤±è´¥ï¼Œå¯åŠ¨60ç§’é€€ç«")
    
    def _check_syntax(self, code: str) -> Tuple[bool, str]:
        """è¯­æ³•æ£€æŸ¥ - ä½¿ç”¨ASTè§£æ"""
        try:
            ast.parse(code)
            return True, None
        except SyntaxError as e:
            return False, f"Line {e.lineno}: {e.msg}"
        except Exception as e:
            return False, str(e)
    
    def _check_safety(self, code: str) -> Tuple[bool, List[str]]:
        """å®‰å…¨æ€§æ£€æŸ¥ - æ£€æµ‹å±é™©æ“ä½œ"""
        warnings = []
        
        try:
            tree = ast.parse(code)
            
            for node in ast.walk(tree):
                # æ£€æŸ¥å±é™©å¯¼å…¥
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        if alias.name in self.DANGEROUS_MODULES:
                            warnings.append(f"å±é™©å¯¼å…¥: {alias.name}")
                            return False, warnings
                
                elif isinstance(node, ast.ImportFrom):
                    if node.module in self.DANGEROUS_MODULES:
                        warnings.append(f"å±é™©å¯¼å…¥: from {node.module}")
                        return False, warnings
                
                # æ£€æŸ¥å±é™©å‡½æ•°è°ƒç”¨
                elif isinstance(node, ast.Call):
                    if isinstance(node.func, ast.Name):
                        if node.func.id in self.DANGEROUS_FUNCTIONS:
                            warnings.append(f"å±é™©å‡½æ•°: {node.func.id}")
                            return False, warnings
                
                # æ£€æŸ¥æ–‡ä»¶æ“ä½œ
                elif isinstance(node, ast.Call):
                    if isinstance(node.func, ast.Name) and node.func.id == 'open':
                        # åªå…è®¸è¯»å–æ“ä½œ
                        if len(node.args) > 1:
                            mode = node.args[1]
                            if isinstance(mode, ast.Constant) and 'w' in mode.value.lower():
                                warnings.append("ç¦æ­¢å†™å…¥æ–‡ä»¶æ“ä½œ")
                                return False, warnings
            
            return True, warnings
            
        except Exception as e:
            return False, [f"å®‰å…¨æ£€æŸ¥å¼‚å¸¸: {str(e)}"]
    
    # ========================================================================
    # ğŸ†• Layer 1: ä¾èµ–åˆ†æï¼ˆå…³é”®æ–°å¢ - è§£å†³ä¼ªä»£ç é—®é¢˜ï¼‰
    # ========================================================================
    
    def _check_dependencies(self, code: str) -> Tuple[bool, List[str]]:
        """
        ä¾èµ–åˆ†æ - æ£€æŸ¥æ‰€æœ‰è°ƒç”¨çš„å‡½æ•°æ˜¯å¦å­˜åœ¨
        
        è¿™æ˜¯è§£å†³ä¼ªä»£ç é—®é¢˜çš„å…³é”®æ–¹æ³•ï¼š
        - æå–ä»£ç ä¸­æ‰€æœ‰å‡½æ•°è°ƒç”¨
        - æ£€æŸ¥æ¯ä¸ªå‡½æ•°æ˜¯å¦åœ¨å·²çŸ¥èŒƒå›´å†…ï¼ˆæœ¬åœ°å®šä¹‰/ç³»ç»Ÿæ³¨å†Œ/Pythonå†…ç½®/å®‰å…¨æ¨¡å—ï¼‰
        - è¿”å›ç¼ºå¤±çš„ä¾èµ–åˆ—è¡¨
        """
        try:
            tree = ast.parse(code)
            
            # 1. æå–ä»£ç ä¸­å®šä¹‰çš„å‡½æ•°
            local_definitions = set()
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    local_definitions.add(node.name)
                elif isinstance(node, ast.ClassDef):
                    local_definitions.add(node.name)
                elif isinstance(node, ast.Assign):
                    for target in node.targets:
                        if isinstance(target, ast.Name):
                            local_definitions.add(target.id)
            
            # 2. æå–ä»£ç ä¸­å¯¼å…¥çš„æ¨¡å—å’Œå‡½æ•°
            imported_names = set()
            for node in ast.walk(tree):
                if isinstance(node, ast.Import):
                    for alias in node.names:
                        name = alias.asname if alias.asname else alias.name
                        imported_names.add(name)
                        # ä¹Ÿæ·»åŠ æ¨¡å—æœ¬èº«ä»¥æ”¯æŒ module.func è°ƒç”¨
                        imported_names.add(alias.name.split('.')[0])
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imported_names.add(node.module.split('.')[0])
                    for alias in node.names:
                        name = alias.asname if alias.asname else alias.name
                        imported_names.add(name)
            
            # 3. æå–æ‰€æœ‰å‡½æ•°è°ƒç”¨
            called_functions = set()
            for node in ast.walk(tree):
                if isinstance(node, ast.Call):
                    func_name = self._extract_call_name(node)
                    if func_name:
                        called_functions.add(func_name)
            
            # 4. æ£€æŸ¥æ¯ä¸ªè°ƒç”¨æ˜¯å¦æœ‰æ•ˆ
            missing_deps = []
            for func_name in called_functions:
                if not self._is_function_available(
                    func_name, 
                    local_definitions, 
                    imported_names
                ):
                    missing_deps.append(func_name)
            
            if missing_deps:
                logger.warning(f"[InsightValidator] æ£€æµ‹åˆ°ç¼ºå¤±ä¾èµ–: {missing_deps}")
                return False, missing_deps
            
            return True, []
            
        except Exception as e:
            logger.error(f"[InsightValidator] ä¾èµ–æ£€æŸ¥å¼‚å¸¸: {e}")
            return False, [f"ä¾èµ–æ£€æŸ¥å¼‚å¸¸: {str(e)}"]
    
    def _extract_call_name(self, node: ast.Call) -> Optional[str]:
        """ä» AST Call èŠ‚ç‚¹æå–å‡½æ•°å"""
        if isinstance(node.func, ast.Name):
            # ç®€å•è°ƒç”¨: func()
            return node.func.id
        elif isinstance(node.func, ast.Attribute):
            # å±æ€§è°ƒç”¨: obj.method()
            # åªè¿”å›æ–¹æ³•åï¼Œå› ä¸ºå¯¹è±¡å¯èƒ½æ˜¯æœ¬åœ°å˜é‡
            return node.func.attr
        return None
    
    def _is_function_available(
        self, 
        func_name: str, 
        local_defs: Set[str], 
        imported: Set[str]
    ) -> bool:
        """æ£€æŸ¥å‡½æ•°æ˜¯å¦åœ¨å¯ç”¨èŒƒå›´å†…"""
        # 1. æœ¬åœ°å®šä¹‰
        if func_name in local_defs:
            return True
        
        # 2. å¯¼å…¥çš„åç§°
        if func_name in imported:
            return True
        
        # 3. Python å†…ç½®å‡½æ•°
        if hasattr(builtins, func_name):
            return True
        
        # 4. å…¨å±€å‡½æ•°æ³¨å†Œè¡¨
        if func_name in SYSTEM_FUNCTION_REGISTRY:
            return True
        
        # 5. ç³»ç»Ÿä¾èµ–å›¾ï¼ˆAGIç³»ç»Ÿå·²æœ‰å‡½æ•°ï¼‰
        if func_name in self.system_dependency_graph:
            return True
        
        # 6. æ£€æŸ¥å®‰å…¨æ¨¡å—ä¸­æ˜¯å¦å­˜åœ¨
        for module_name in SAFE_MODULES:
            try:
                module = __import__(module_name)
                if hasattr(module, func_name):
                    return True
            except ImportError:
                continue
        
        return False
    
    # ========================================================================
    # ğŸ†• Layer 2: æ²™ç®±æ‰§è¡Œï¼ˆçœŸæ­£è¿è¡Œä»£ç ï¼‰
    # ========================================================================
    
    def _run_in_sandbox(self, code: str, timeout: float = 5.0) -> Tuple[bool, str]:
        """
        æ²™ç®±æ‰§è¡Œ - åœ¨éš”ç¦»ç¯å¢ƒä¸­çœŸæ­£è¿è¡Œä»£ç 
        
        è¿™æ˜¯è§£å†³ä¼ªä»£ç é—®é¢˜çš„ç¬¬äºŒé“é˜²çº¿ï¼š
        - çœŸæ­£æ‰§è¡Œä»£ç ï¼ˆä¸åªæ˜¯å®šä¹‰ï¼‰
        - å°è¯•è°ƒç”¨æ‰€æœ‰å®šä¹‰çš„å‡½æ•°
        - æ•è·ä»»ä½•è¿è¡Œæ—¶é”™è¯¯ï¼ˆåŒ…æ‹¬ NameErrorï¼‰
        """
        temp_path = None
        try:
            # 1. åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(
                mode='w', suffix='.py', delete=False, encoding='utf-8'
            ) as f:
                # åŒ…è£…ä»£ç ä»¥ä¾¿æµ‹è¯•æ‰§è¡Œ
                wrapped_code = self._wrap_code_for_sandbox(code)
                f.write(wrapped_code)
                temp_path = f.name
            
            # 2. åœ¨å­è¿›ç¨‹ä¸­æ‰§è¡Œï¼ˆçœŸæ­£éš”ç¦»ï¼‰
            try:
                result = subprocess.run(
                    [sys.executable, temp_path],
                    capture_output=True,
                    text=True,
                    timeout=timeout,
                    cwd=os.path.dirname(temp_path)
                )
                
                if result.returncode != 0:
                    error_msg = result.stderr.strip() if result.stderr else "Unknown error"
                    # æå–å…³é”®é”™è¯¯ä¿¡æ¯
                    if "NameError" in error_msg:
                        # è¿™æ­£æ˜¯æˆ‘ä»¬è¦æ•è·çš„ä¼ªä»£ç é—®é¢˜ï¼
                        match = re.search(r"NameError: name '(\w+)' is not defined", error_msg)
                        if match:
                            error_msg = f"NameError: å‡½æ•° '{match.group(1)}' ä¸å­˜åœ¨"
                    elif "ImportError" in error_msg:
                        error_msg = f"ImportError: {error_msg.split('ImportError:')[-1].strip()[:100]}"
                    
                    logger.warning(f"[InsightValidator] æ²™ç®±æ‰§è¡Œå¤±è´¥: {error_msg}")
                    return False, error_msg
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ stderr è¾“å‡ºï¼ˆå¯èƒ½æ˜¯è­¦å‘Šï¼‰
                if result.stderr and "Error" in result.stderr:
                    return False, result.stderr.strip()[:200]
                
                return True, ""
                
            except subprocess.TimeoutExpired:
                return False, f"æ‰§è¡Œè¶…æ—¶ (>{timeout}s)"
            except Exception as e:
                return False, f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"
            
        except Exception as e:
            return False, f"æ²™ç®±å‡†å¤‡å¤±è´¥: {str(e)}"
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_path and os.path.exists(temp_path):
                try:
                    os.unlink(temp_path)
                except:
                    pass
    
    def _wrap_code_for_sandbox(self, code: str) -> str:
        """
        åŒ…è£…ä»£ç ä»¥ä¾¿åœ¨æ²™ç®±ä¸­æµ‹è¯•
        - å®šä¹‰æ‰€æœ‰å‡½æ•°
        - å°è¯•è°ƒç”¨æ¯ä¸ªå‡½æ•°ï¼ˆä½¿ç”¨åˆç†çš„æµ‹è¯•å‚æ•°ï¼‰
        """
        try:
            tree = ast.parse(code)
            functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
            
            # æ„å»ºæµ‹è¯•ä»£ç 
            test_calls = []
            for func in functions:
                func_name = func.name
                # åˆ†æå‡½æ•°ç­¾åï¼Œç”Ÿæˆæµ‹è¯•å‚æ•°
                test_args = self._generate_test_arguments(func)
                # ä½¿ç”¨ASCIIå­—ç¬¦é¿å…Windows GBKç¼–ç é—®é¢˜
                test_calls.append(f"""
try:
    result = {func_name}({test_args})
    print("[SANDBOX] OK: {func_name} executed successfully")
except TypeError as e:
    # å‚æ•°ç±»å‹ä¸åŒ¹é…æ˜¯å¯ä»¥æ¥å—çš„
    print("[SANDBOX] WARN: {func_name} type error (acceptable):", str(e))
except Exception as e:
    print("[SANDBOX] FAIL: {func_name} failed:", str(e), file=__import__('sys').stderr)
    raise
""")
            
            # ç»„è£…å®Œæ•´çš„æµ‹è¯•ä»£ç 
            wrapped = f"""# Sandbox test wrapper
{code}

# === Sandbox Test Execution ===
if __name__ == "__main__":
    import sys
    print("[SANDBOX] Starting function tests...")
{"".join(test_calls)}
    print("[SANDBOX] All tests completed.")
"""
            return wrapped
            
        except Exception as e:
            # å¦‚æœæ— æ³•è§£æï¼Œç›´æ¥è¿”å›åŸä»£ç 
            return f"{code}\n\n# Sandbox wrapper failed: {e}"
    
    def _generate_test_arguments(self, func: ast.FunctionDef) -> str:
        """æ ¹æ®å‡½æ•°ç­¾åç”Ÿæˆæµ‹è¯•å‚æ•°"""
        args = func.args
        test_args = []
        
        # å¤„ç†ä½ç½®å‚æ•°
        for arg in args.args:
            arg_name = arg.arg.lower()
            # æ ¹æ®å‚æ•°åæ¨æ–­ç±»å‹
            if 'state' in arg_name:
                test_args.append("{'entropy': 0.5, 'curiosity': 0.5}")
            elif 'entropy' in arg_name:
                test_args.append("0.5")
            elif 'curiosity' in arg_name:
                test_args.append("0.5")
            elif 'threshold' in arg_name:
                test_args.append("0.5")
            elif 'data' in arg_name or 'list' in arg_name or 'items' in arg_name:
                test_args.append("[1, 2, 3]")
            elif 'dict' in arg_name or 'config' in arg_name:
                test_args.append("{}")
            elif 'str' in arg_name or 'text' in arg_name or 'name' in arg_name:
                test_args.append("'test'")
            elif 'num' in arg_name or 'value' in arg_name or 'count' in arg_name:
                test_args.append("1")
            elif arg_name in ('a', 'b', 'c', 'x', 'y', 'z', 'n', 'm', 'i', 'j', 'k'):
                # å•å­—æ¯å‚æ•°é€šå¸¸æ˜¯æ•°å€¼
                test_args.append("1")
            elif 'factor' in arg_name or 'ratio' in arg_name or 'rate' in arg_name:
                test_args.append("0.5")
            elif 'index' in arg_name or 'idx' in arg_name or 'pos' in arg_name:
                test_args.append("0")
            elif 'size' in arg_name or 'length' in arg_name or 'width' in arg_name:
                test_args.append("10")
            elif 'flag' in arg_name or 'enabled' in arg_name or 'active' in arg_name:
                test_args.append("True")
            else:
                # é»˜è®¤ä½¿ç”¨ç©ºå­—ç¬¦ä¸²ï¼ˆæ¯”Noneæ›´ä¸å®¹æ˜“å¼•å‘TypeErrorï¼‰
                test_args.append("'test_value'")
        
        # è·³è¿‡æœ‰é»˜è®¤å€¼çš„å‚æ•°
        num_defaults = len(args.defaults)
        if num_defaults > 0:
            test_args = test_args[:-num_defaults]
        
        return ", ".join(test_args)

    def _run_unit_tests(self, code: str, metadata: Dict) -> Tuple[bool, float]:
        """
        è‡ªåŠ¨ç”Ÿæˆå¹¶è¿è¡Œå•å…ƒæµ‹è¯•
        æµ‹è¯•è¦†ç›–ç‡ = æˆåŠŸæµ‹è¯•æ•° / æ€»æµ‹è¯•æ•°
        """
        # æå–ä»£ç ä¸­çš„å‡½æ•°å®šä¹‰
        try:
            tree = ast.parse(code)
            functions = [node.name for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
            
            if not functions:
                return True, 1.0  # æ— å‡½æ•°å®šä¹‰ï¼Œé»˜è®¤é€šè¿‡
            
            # ä¸ºæ¯ä¸ªå‡½æ•°ç”Ÿæˆç®€å•æµ‹è¯•
            passed_tests = 0
            total_tests = len(functions)
            
            # åˆ›å»ºä¸´æ—¶æ¨¡å—
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(code)
                temp_path = f.name
            
            try:
                spec = importlib.util.spec_from_file_location("temp_insight", temp_path)
                module = importlib.util.module_from_spec(spec)
                sys.modules["temp_insight"] = module
                spec.loader.exec_module(module)
                
                for func_name in functions:
                    try:
                        func = getattr(module, func_name)
                        if callable(func):
                            # å°è¯•ç”¨ä¸åŒå‚æ•°è°ƒç”¨
                            test_inputs = [
                                {},
                                {'x': 0},
                                {'data': []},
                                {'value': 1.0}
                            ]
                            
                            for test_input in test_inputs:
                                try:
                                    func(**test_input)
                                    passed_tests += 0.25  # æ¯ä¸ªæˆåŠŸè°ƒç”¨å¾—0.25åˆ†
                                    break
                                except TypeError:
                                    continue  # å‚æ•°ä¸åŒ¹é…ï¼Œå°è¯•ä¸‹ä¸€ä¸ª
                                except Exception:
                                    break  # æ‰§è¡Œé”™è¯¯ï¼Œè·³è¿‡
                    except:
                        continue
                
                coverage = min(1.0, passed_tests / total_tests)
                return coverage > 0.5, coverage
                
            finally:
                os.unlink(temp_path)
                if "temp_insight" in sys.modules:
                    del sys.modules["temp_insight"]
                    
        except Exception as e:
            return False, 0.0
    
    def _benchmark_performance(self, code: str, timeout: float = 0.5) -> Tuple[bool, float]:
        """
        æ€§èƒ½åŸºå‡†æµ‹è¯•
        è¦æ±‚: æ‰§è¡Œæ—¶é—´ < timeout
        """
        try:
            # åˆ›å»ºéš”ç¦»ç¯å¢ƒæ‰§è¡Œ
            start = time.time()
            
            # ä½¿ç”¨compile + execæ‰§è¡Œ
            compiled = compile(code, '<insight>', 'exec')
            namespace = {}
            
            exec(compiled, namespace)
            
            exec_time = time.time() - start
            
            return exec_time < timeout, exec_time
            
        except Exception as e:
            return False, timeout
    
    def _validate_semantics(self, code: str, metadata: Dict) -> Tuple[bool, float]:
        """
        è¯­ä¹‰éªŒè¯ - æ£€æŸ¥ä»£ç æ˜¯å¦å®ç°äº†å£°ç§°çš„åŠŸèƒ½
        é€šè¿‡å…³é”®è¯åŒ¹é…å’Œä»£ç ç»“æ„åˆ†æ
        """
        try:
            hypothesis = metadata.get('trigger_goal', '').lower()
            content = metadata.get('content', '').lower()
            
            # æå–å…³é”®æ¦‚å¿µ
            keywords = self._extract_keywords(hypothesis + ' ' + content)
            
            # æ£€æŸ¥ä»£ç ä¸­æ˜¯å¦åŒ…å«ç›¸å…³å®ç°
            code_lower = code.lower()
            matches = sum(1 for kw in keywords if kw in code_lower)
            
            # è¯­ä¹‰å¾—åˆ† = åŒ¹é…å…³é”®è¯æ•° / æ€»å…³é”®è¯æ•°
            score = matches / len(keywords) if keywords else 0.5
            
            return score > 0.3, score
            
        except:
            return False, 0.0
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–æ–‡æœ¬ä¸­çš„å…³é”®æŠ€æœ¯è¯æ±‡"""
        # ç®€å•å®ç°ï¼šæå–3å­—ä»¥ä¸Šçš„å•è¯
        words = re.findall(r'\b[a-z]{3,}\b', text.lower())
        # è¿‡æ»¤å¸¸è§åœç”¨è¯
        stopwords = {'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all', 'can', 'her', 'was', 'one', 'our', 'out', 'day', 'get', 'has', 'him', 'his', 'how', 'man', 'new', 'now', 'old', 'see', 'two', 'way', 'who', 'boy', 'did', 'its', 'let', 'put', 'say', 'she', 'too', 'use'}
        return [w for w in words if w not in stopwords][:10]  # æœ€å¤š10ä¸ªå…³é”®è¯
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–éªŒè¯ç»Ÿè®¡ä¿¡æ¯"""
        if not self.validation_history:
            return {'total': 0}
        
        return {
            'total': len(self.validation_history),
            'valid': sum(1 for v in self.validation_history if v['valid']),
            'average_score': sum(v['score'] for v in self.validation_history) / len(self.validation_history),
            'integrate_recommended': sum(1 for v in self.validation_history if v['recommendation'] == 'INTEGRATE'),
            'archive_recommended': sum(1 for v in self.validation_history if v['recommendation'] == 'ARCHIVE'),
            'reject_recommended': sum(1 for v in self.validation_history if v['recommendation'] == 'REJECT')
        }
