#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è·¨åŸŸçŸ¥è¯†è¿ç§»ç³»ç»Ÿ (Cross-Domain Knowledge Transfer System)
==========================================================

åŠŸèƒ½: å®ç°è·¨åŸŸçŸ¥è¯†æ˜ å°„ã€å…ƒå­¦ä¹ è¿ç§»å’Œå°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ›
ç‰ˆæœ¬: 1.0.0 (2026-01-19)

æ ¸å¿ƒç»„ä»¶:
1. CrossDomainMapper - è·¨åŸŸçŸ¥è¯†æ˜ å°„å™¨
2. MetaLearningTransfer - å…ƒå­¦ä¹ è¿ç§»å¼•æ“
3. FewShotLearner - å°‘æ ·æœ¬å­¦ä¹ å™¨
4. SkillExtractor - æŠ€èƒ½æå–å™¨

ç›®æ ‡: æå‡å­¦ä¹ æ™ºèƒ½ 67.5% â†’ 80% (+12.5%)
"""

import logging
import numpy as np
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
from collections import defaultdict, Counter
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

logger = logging.getLogger(__name__)


# ==================== æ•°æ®ç»“æ„ ====================

@dataclass
class DomainKnowledge:
    """é¢†åŸŸçŸ¥è¯†è¡¨ç¤º"""
    domain: str
    concepts: Set[str]  # é¢†åŸŸæ¦‚å¿µé›†åˆ
    relations: Dict[Tuple[str, str], str]  # æ¦‚å¿µå…³ç³»
    patterns: List[Dict[str, Any]]  # æŠ½è±¡æ¨¡å¼
    skills: List[Dict[str, Any]]  # æŠ€èƒ½æ¨¡å¼
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'domain': self.domain,
            'concepts': list(self.concepts),
            'relations': {f"{k[0]}->{k[1]}": v for k, v in self.relations.items()},
            'patterns': self.patterns,
            'skills': self.skills,
            'metadata': self.metadata
        }


@dataclass
class TransferResult:
    """è¿ç§»ç»“æœ"""
    source_domain: str
    target_domain: str
    success: bool
    transferred_knowledge: Optional[DomainKnowledge]
    transfer_score: float  # è¿ç§»ç½®ä¿¡åº¦
    adaptation_effort: float  # é€‚é…æˆæœ¬ (0-1)
    improvements: Dict[str, float]  # æ€§èƒ½æå‡
    errors: List[str] = field(default_factory=list)


@dataclass
class MetaKnowledge:
    """å…ƒçŸ¥è¯†ï¼ˆè·¨ä»»åŠ¡å¯è¿ç§»çš„çŸ¥è¯†ï¼‰"""
    abstract_patterns: List[Dict[str, Any]]  # æŠ½è±¡æ¨¡å¼
    learning_strategies: List[str]  # å­¦ä¹ ç­–ç•¥
    problem_solving_templates: List[Dict[str, Any]]  # é—®é¢˜è§£å†³æ¨¡æ¿
    transferability_score: float  # å¯è¿ç§»æ€§è¯„åˆ†


@dataclass
class FewShotExample:
    """å°‘æ ·æœ¬å­¦ä¹ ç¤ºä¾‹"""
    input_data: Dict[str, Any]
    output_data: Dict[str, Any]
    domain: str
    task_type: str
    metadata: Dict[str, Any] = field(default_factory=dict)


# ==================== 1. è·¨åŸŸçŸ¥è¯†æ˜ å°„å™¨ ====================

class CrossDomainMapper:
    """
    è·¨åŸŸçŸ¥è¯†æ˜ å°„å™¨

    åŠŸèƒ½:
    1. æå–é¢†åŸŸçŸ¥è¯†çš„æŠ½è±¡ç»“æ„
    2. æ˜ å°„åˆ°ç›®æ ‡é¢†åŸŸ
    3. è¯„ä¼°æ˜ å°„è´¨é‡
    """

    def __init__(self, similarity_threshold: float = 0.6):
        """
        åˆå§‹åŒ–è·¨åŸŸæ˜ å°„å™¨

        Args:
            similarity_threshold: æ¦‚å¿µç›¸ä¼¼åº¦é˜ˆå€¼
        """
        self.similarity_threshold = similarity_threshold
        self.mapping_cache = {}  # æ˜ å°„ç¼“å­˜
        self.domain_embeddings = {}  # é¢†åŸŸåµŒå…¥

    def extract_abstract_structure(self, knowledge: DomainKnowledge) -> Dict[str, Any]:
        """
        æå–æŠ½è±¡ç»“æ„ï¼ˆé¢†åŸŸæ— å…³çš„æ¨¡å¼ï¼‰

        ç­–ç•¥:
        1. è¯†åˆ«é«˜é¢‘æ¨¡å¼
        2. æå–å…³ç³»éª¨æ¶
        3. æŠ½è±¡æŠ€èƒ½æ¨¡æ¿

        Args:
            knowledge: æºé¢†åŸŸçŸ¥è¯†

        Returns:
            æŠ½è±¡ç»“æ„è¡¨ç¤º
        """
        abstract_structure = {
            'patterns': [],
            'relations': [],
            'skills': [],
            'statistics': {}
        }

        # 1. æå–é«˜é¢‘æ¨¡å¼
        pattern_counts = defaultdict(int)
        for pattern in knowledge.patterns:
            # ä½¿ç”¨æ¨¡å¼çš„ç»“æ„ç­¾åä½œä¸ºé”®
            signature = self._get_pattern_signature(pattern)
            pattern_counts[signature] += 1

        # é€‰æ‹©é«˜é¢‘æ¨¡å¼
        frequent_patterns = [
            sig for sig, count in pattern_counts.items()
            if count >= 2  # è‡³å°‘å‡ºç°2æ¬¡
        ]

        abstract_structure['patterns'] = frequent_patterns
        abstract_structure['statistics']['pattern_count'] = len(frequent_patterns)

        # 2. æå–å…³ç³»éª¨æ¶ï¼ˆå…³é”®å…³ç³»ç±»å‹ï¼‰
        relation_counts = Counter()
        for (_, _), rel_type in knowledge.relations.items():
            relation_counts[rel_type] += 1

        # é€‰æ‹©å…³é”®å…³ç³»ï¼ˆé«˜é¢‘å…³ç³»ï¼‰
        key_relations = [
            rel_type for rel_type, count in relation_counts.most_common(5)
        ]

        abstract_structure['relations'] = key_relations
        abstract_structure['statistics']['relation_count'] = len(key_relations)

        # 3. æŠ½è±¡æŠ€èƒ½æ¨¡æ¿
        for skill in knowledge.skills:
            abstract_skill = self._abstract_skill(skill)
            abstract_structure['skills'].append(abstract_skill)

        abstract_structure['statistics']['skill_count'] = len(abstract_structure['skills'])

        logger.info(f"[CrossDomainMapper] æå–æŠ½è±¡ç»“æ„: "
                   f"{len(frequent_patterns)} æ¨¡å¼, {len(key_relations)} å…³ç³», "
                   f"{len(abstract_structure['skills'])} æŠ€èƒ½")

        return abstract_structure

    def map_to_target_domain(self,
                            abstract_structure: Dict[str, Any],
                            target_knowledge: DomainKnowledge) -> DomainKnowledge:
        """
        å°†æŠ½è±¡ç»“æ„æ˜ å°„åˆ°ç›®æ ‡é¢†åŸŸ

        ç­–ç•¥:
        1. å¯¹é½æ¦‚å¿µ
        2. åŒ¹é…å…³ç³»
        3. é€‚é…æŠ€èƒ½

        Args:
            abstract_structure: æŠ½è±¡ç»“æ„
            target_knowledge: ç›®æ ‡é¢†åŸŸçŸ¥è¯†

        Returns:
            æ˜ å°„åçš„é¢†åŸŸçŸ¥è¯†
        """
        mapped_knowledge = DomainKnowledge(
            domain=target_knowledge.domain,
            concepts=set(),
            relations={},
            patterns=[],
            skills=[]
        )

        # 1. æ˜ å°„æ¦‚å¿µï¼ˆåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰
        concept_mapping = self._align_concepts(
            abstract_structure.get('patterns', []),
            target_knowledge
        )
        mapped_knowledge.concepts = set(concept_mapping.values())

        # 2. æ˜ å°„å…³ç³»
        for relation in abstract_structure.get('relations', []):
            # åœ¨ç›®æ ‡åŸŸä¸­å¯»æ‰¾ç±»ä¼¼å…³ç³»
            mapped_relations = self._find_similar_relations(
                relation, target_knowledge
            )
            mapped_knowledge.relations.update(mapped_relations)

        # 3. é€‚é…æŠ€èƒ½
        for skill_template in abstract_structure.get('skills', []):
            adapted_skill = self._adapt_skill_to_domain(
                skill_template, target_knowledge
            )
            if adapted_skill:
                mapped_knowledge.skills.append(adapted_skill)

        # 4. æ˜ å°„æ¨¡å¼
        for pattern in abstract_structure.get('patterns', []):
            mapped_pattern = self._adapt_pattern_to_domain(
                pattern, target_knowledge
            )
            if mapped_pattern:
                mapped_knowledge.patterns.append(mapped_pattern)

        logger.info(f"[CrossDomainMapper] æ˜ å°„åˆ°ç›®æ ‡åŸŸ: "
                   f"{len(mapped_knowledge.concepts)} æ¦‚å¿µ, "
                   f"{len(mapped_knowledge.relations)} å…³ç³», "
                   f"{len(mapped_knowledge.skills)} æŠ€èƒ½")

        return mapped_knowledge

    def evaluate_mapping_quality(self,
                                mapped_knowledge: DomainKnowledge,
                                target_knowledge: DomainKnowledge) -> float:
        """
        è¯„ä¼°æ˜ å°„è´¨é‡

        æŒ‡æ ‡:
        1. æ¦‚å¿µè¦†ç›–ç‡
        2. å…³ç³»ä¸€è‡´æ€§
        3. æŠ€èƒ½é€‚é…åº¦

        Args:
            mapped_knowledge: æ˜ å°„çš„çŸ¥è¯†
            target_knowledge: ç›®æ ‡é¢†åŸŸçŸ¥è¯†

        Returns:
            æ˜ å°„è´¨é‡è¯„åˆ† (0-1)
        """
        # 1. æ¦‚å¿µè¦†ç›–ç‡
        if len(target_knowledge.concepts) > 0:
            concept_coverage = len(mapped_knowledge.concepts & target_knowledge.concepts) / len(target_knowledge.concepts)
        else:
            concept_coverage = 0.0

        # 2. å…³ç³»ä¸€è‡´æ€§
        if len(target_knowledge.relations) > 0:
            relation_overlap = set(mapped_knowledge.relations.values()) & set(target_knowledge.relations.values())
            relation_consistency = len(relation_overlap) / len(target_knowledge.relations)
        else:
            relation_consistency = 0.0

        # 3. æŠ€èƒ½é€‚é…åº¦ï¼ˆæŠ€èƒ½ä¸é¢†åŸŸçš„åŒ¹é…åº¦ï¼‰
        skill_adaptation = 0.0
        if mapped_knowledge.skills:
            # è¯„ä¼°æŠ€èƒ½æ˜¯å¦é€‚åˆç›®æ ‡åŸŸ
            adapted_count = sum(
                1 for skill in mapped_knowledge.skills
                if self._is_skill_compatible(skill, target_knowledge)
            )
            skill_adaptation = adapted_count / len(mapped_knowledge.skills)

        # åŠ æƒç»„åˆ
        quality_score = (
            0.4 * concept_coverage +
            0.3 * relation_consistency +
            0.3 * skill_adaptation
        )

        logger.info(f"[CrossDomainMapper] æ˜ å°„è´¨é‡: {quality_score:.3f} "
                   f"(æ¦‚å¿µ={concept_coverage:.2f}, å…³ç³»={relation_consistency:.2f}, æŠ€èƒ½={skill_adaptation:.2f})")

        return quality_score

    # ==================== è¾…åŠ©æ–¹æ³• ====================

    def _get_pattern_signature(self, pattern: Dict[str, Any]) -> str:
        """è·å–æ¨¡å¼çš„ç»“æ„ç­¾å"""
        # ç®€åŒ–ï¼šä½¿ç”¨é”®çš„é›†åˆä½œä¸ºç­¾å
        return json.dumps(sorted(pattern.keys()), sort_keys=True)

    def _abstract_skill(self, skill: Dict[str, Any]) -> Dict[str, Any]:
        """æŠ½è±¡æŠ€èƒ½ï¼ˆå»é™¤é¢†åŸŸç‰¹å®šç»†èŠ‚ï¼‰"""
        return {
            'type': skill.get('type', 'unknown'),
            'operations': skill.get('operations', []),
            'parameters': skill.get('parameters', {}),
            'abstract_signature': self._get_pattern_signature(skill)
        }

    def _align_concepts(self, patterns: List[str], target_knowledge: DomainKnowledge) -> Dict[str, str]:
        """å¯¹é½æ¦‚å¿µï¼ˆç®€åŒ–ç‰ˆï¼šä½¿ç”¨å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼‰"""
        mapping = {}
        for pattern in patterns:
            # åœ¨ç›®æ ‡åŸŸä¸­å¯»æ‰¾æœ€ç›¸ä¼¼çš„æ¦‚å¿µ
            best_match = None
            best_score = 0.0

            for concept in target_knowledge.concepts:
                # ç®€å•çš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
                similarity = self._string_similarity(pattern, concept)
                if similarity > best_score and similarity >= self.similarity_threshold:
                    best_score = similarity
                    best_match = concept

            if best_match:
                mapping[pattern] = best_match

        return mapping

    def _find_similar_relations(self, relation_type: str, target_knowledge: DomainKnowledge) -> Dict[Tuple[str, str], str]:
        """åœ¨ç›®æ ‡åŸŸä¸­å¯»æ‰¾ç›¸ä¼¼å…³ç³»"""
        similar_relations = {}

        for (source, target), rel in target_knowledge.relations.items():
            if self._string_similarity(relation_type, rel) >= self.similarity_threshold:
                similar_relations[(source, target)] = rel

        return similar_relations

    def _adapt_skill_to_domain(self, skill_template: Dict[str, Any], target_knowledge: DomainKnowledge) -> Optional[Dict[str, Any]]:
        """é€‚é…æŠ€èƒ½åˆ°ç›®æ ‡åŸŸ"""
        # ç®€åŒ–ï¼šæ£€æŸ¥æŠ€èƒ½æ˜¯å¦ä¸ç›®æ ‡åŸŸå…¼å®¹
        if self._is_skill_compatible(skill_template, target_knowledge):
            return {
                **skill_template,
                'domain': target_knowledge.domain,
                'adapted': True
            }
        return None

    def _adapt_pattern_to_domain(self, pattern: str, target_knowledge: DomainKnowledge) -> Optional[str]:
        """é€‚é…æ¨¡å¼åˆ°ç›®æ ‡åŸŸ"""
        # ç®€åŒ–ï¼šç›´æ¥ä½¿ç”¨æ¨¡å¼ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦æ›´å¤æ‚çš„é€‚é…ï¼‰
        if any(self._string_similarity(pattern, str(concept)) >= self.similarity_threshold
               for concept in target_knowledge.concepts):
            return pattern
        return None

    def _is_skill_compatible(self, skill: Dict[str, Any], domain: DomainKnowledge) -> bool:
        """æ£€æŸ¥æŠ€èƒ½æ˜¯å¦ä¸é¢†åŸŸå…¼å®¹"""
        # ç®€åŒ–ï¼šæ£€æŸ¥æŠ€èƒ½æ‰€éœ€çš„æ¦‚å¿µæ˜¯å¦å­˜åœ¨äºé¢†åŸŸ
        required_concepts = skill.get('required_concepts', [])
        return all(concept in domain.concepts for concept in required_concepts)

    def _string_similarity(self, s1: str, s2: str) -> float:
        """è®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆJaccardï¼‰"""
        set1 = set(s1.lower())
        set2 = set(s2.lower())
        intersection = len(set1 & set2)
        union = len(set1 | set2)
        return intersection / union if union > 0 else 0.0


# ==================== 2. å…ƒå­¦ä¹ è¿ç§»å¼•æ“ ====================

class MetaLearningTransfer:
    """
    å…ƒå­¦ä¹ è¿ç§»å¼•æ“

    åŠŸèƒ½:
    1. ä»æºä»»åŠ¡æå–å…ƒçŸ¥è¯†
    2. é€‚é…å…ƒçŸ¥è¯†åˆ°ç›®æ ‡ä»»åŠ¡
    3. è¯„ä¼°è¿ç§»æ•ˆæœ
    """

    def __init__(self):
        """åˆå§‹åŒ–å…ƒå­¦ä¹ å¼•æ“"""
        self.meta_knowledge_cache = {}  # å…ƒçŸ¥è¯†ç¼“å­˜
        self.transfer_history = []  # è¿ç§»å†å²

    def extract_meta_knowledge(self,
                              source_tasks: List[Dict[str, Any]],
                              domain: str) -> MetaKnowledge:
        """
        ä»æºä»»åŠ¡æå–å…ƒçŸ¥è¯†

        ç­–ç•¥:
        1. è¯†åˆ«è·¨ä»»åŠ¡çš„å…±åŒæ¨¡å¼
        2. æå–å­¦ä¹ ç­–ç•¥
        3. æŠ½è±¡é—®é¢˜è§£å†³æ¨¡æ¿

        Args:
            source_tasks: æºä»»åŠ¡åˆ—è¡¨
            domain: é¢†åŸŸåç§°

        Returns:
            å…ƒçŸ¥è¯†
        """
        abstract_patterns = []
        learning_strategies = []
        problem_solving_templates = []

        # 1. æå–è·¨ä»»åŠ¡å…±åŒæ¨¡å¼
        pattern_counts = defaultdict(int)
        for task in source_tasks:
            patterns = task.get('patterns', [])
            for pattern in patterns:
                signature = json.dumps(pattern, sort_keys=True)
                pattern_counts[signature] += 1

        # é€‰æ‹©è·¨ä»»åŠ¡æ¨¡å¼ï¼ˆè‡³å°‘åœ¨2ä¸ªä»»åŠ¡ä¸­å‡ºç°ï¼‰
        for signature, count in pattern_counts.items():
            if count >= 2:
                pattern = json.loads(signature)
                abstract_patterns.append(pattern)

        # 2. æå–å­¦ä¹ ç­–ç•¥
        strategy_counts = defaultdict(int)
        for task in source_tasks:
            strategies = task.get('learning_strategies', ['default'])
            for strategy in strategies:
                strategy_counts[strategy] += 1

        # é€‰æ‹©é«˜é¢‘ç­–ç•¥
        for strategy, count in strategy_counts.items():
            if count >= len(source_tasks) * 0.5:  # è‡³å°‘åœ¨50%çš„ä»»åŠ¡ä¸­å‡ºç°
                learning_strategies.append(strategy)

        # 3. æŠ½è±¡é—®é¢˜è§£å†³æ¨¡æ¿
        for task in source_tasks:
            template = {
                'task_type': task.get('type', 'unknown'),
                'steps': task.get('solution_steps', []),
                'success_rate': task.get('success_rate', 0.5)
            }
            problem_solving_templates.append(template)

        # è®¡ç®—å¯è¿ç§»æ€§è¯„åˆ†
        transferability_score = self._compute_transferability(
            abstract_patterns, learning_strategies, problem_solving_templates
        )

        meta_knowledge = MetaKnowledge(
            abstract_patterns=abstract_patterns,
            learning_strategies=learning_strategies,
            problem_solving_templates=problem_solving_templates,
            transferability_score=transferability_score
        )

        self.meta_knowledge_cache[domain] = meta_knowledge

        logger.info(f"[MetaLearningTransfer] æå–å…ƒçŸ¥è¯†: "
                   f"{len(abstract_patterns)} æ¨¡å¼, {len(learning_strategies)} ç­–ç•¥, "
                   f"{len(problem_solving_templates)} æ¨¡æ¿, "
                   f"å¯è¿ç§»æ€§={transferability_score:.2f}")

        return meta_knowledge

    def adapt_to_target(self,
                       meta_knowledge: MetaKnowledge,
                       target_task: Dict[str, Any],
                       target_domain: str) -> TransferResult:
        """
        é€‚é…å…ƒçŸ¥è¯†åˆ°ç›®æ ‡ä»»åŠ¡

        ç­–ç•¥:
        1. é€‰æ‹©æœ€ç›¸å…³çš„æ¨¡å¼å’Œæ¨¡æ¿
        2. æ ¹æ®ç›®æ ‡ä»»åŠ¡è°ƒæ•´
        3. è¯„ä¼°é€‚é…æ•ˆæœ

        Args:
            meta_knowledge: å…ƒçŸ¥è¯†
            target_task: ç›®æ ‡ä»»åŠ¡
            target_domain: ç›®æ ‡é¢†åŸŸ

        Returns:
            è¿ç§»ç»“æœ
        """
        try:
            # 1. é€‰æ‹©ç›¸å…³æ¨¡å¼
            relevant_patterns = self._select_relevant_patterns(
                meta_knowledge.abstract_patterns,
                target_task
            )

            # 2. é€‰æ‹©ç›¸å…³æ¨¡æ¿
            relevant_templates = self._select_relevant_templates(
                meta_knowledge.problem_solving_templates,
                target_task
            )

            # 3. é€‚é…å­¦ä¹ ç­–ç•¥
            adapted_strategies = self._adapt_strategies(
                meta_knowledge.learning_strategies,
                target_task
            )

            # æ„å»ºè¿ç§»çš„çŸ¥è¯†
            transferred_knowledge = DomainKnowledge(
                domain=target_domain,
                concepts=set(),  # ä»ç›®æ ‡ä»»åŠ¡æå–
                relations={},
                patterns=relevant_patterns,
                skills=[{'strategies': adapted_strategies}]
            )

            # è®¡ç®—è¿ç§»è¯„åˆ†
            transfer_score = self._compute_transfer_score(
                meta_knowledge, target_task
            )

            # è®¡ç®—é€‚é…æˆæœ¬
            adaptation_effort = self._compute_adaptation_effort(
                meta_knowledge, target_task
            )

            # ä¼°ç®—æ€§èƒ½æå‡
            improvements = self._estimate_improvements(
                transfer_score, adaptation_effort
            )

            result = TransferResult(
                source_domain=meta_knowledge.__class__.__name__,
                target_domain=target_domain,
                success=True,
                transferred_knowledge=transferred_knowledge,
                transfer_score=transfer_score,
                adaptation_effort=adaptation_effort,
                improvements=improvements
            )

            self.transfer_history.append(result)

            logger.info(f"[MetaLearningTransfer] è¿ç§»æˆåŠŸ: "
                       f"è¯„åˆ†={transfer_score:.2f}, "
                       f"é€‚é…æˆæœ¬={adaptation_effort:.2f}, "
                       f"é¢„æœŸæå‡={improvements}")

            return result

        except Exception as e:
            logger.error(f"[MetaLearningTransfer] è¿ç§»å¤±è´¥: {e}")
            return TransferResult(
                source_domain=meta_knowledge.__class__.__name__,
                target_domain=target_domain,
                success=False,
                transferred_knowledge=None,
                transfer_score=0.0,
                adaptation_effort=1.0,
                improvements={},
                errors=[str(e)]
            )

    def _compute_transferability(self,
                                 patterns: List,
                                 strategies: List,
                                 templates: List) -> float:
        """è®¡ç®—å¯è¿ç§»æ€§è¯„åˆ†"""
        # åŸºäºæ¨¡å¼ã€ç­–ç•¥ã€æ¨¡æ¿çš„æ•°é‡å’Œè´¨é‡
        pattern_score = min(len(patterns) / 10, 1.0)  # æœ€å¤š10ä¸ªæ¨¡å¼
        strategy_score = min(len(strategies) / 5, 1.0)  # æœ€å¤š5ä¸ªç­–ç•¥
        template_score = min(len(templates) / 10, 1.0)  # æœ€å¤š10ä¸ªæ¨¡æ¿

        return (pattern_score + strategy_score + template_score) / 3

    def _select_relevant_patterns(self,
                                  patterns: List[Dict[str, Any]],
                                  target_task: Dict[str, Any]) -> List[Dict[str, Any]]:
        """é€‰æ‹©ä¸ç›®æ ‡ä»»åŠ¡ç›¸å…³çš„æ¨¡å¼"""
        # ç®€åŒ–ï¼šè¿”å›æ‰€æœ‰æ¨¡å¼ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦ç›¸ä¼¼åº¦åŒ¹é…ï¼‰
        return patterns[:5]  # é™åˆ¶æ•°é‡

    def _select_relevant_templates(self,
                                   templates: List[Dict[str, Any]],
                                   target_task: Dict[str, Any]) -> List[Dict[str, Any]]:
        """é€‰æ‹©ä¸ç›®æ ‡ä»»åŠ¡ç›¸å…³çš„æ¨¡æ¿"""
        target_type = target_task.get('type', 'unknown')
        # é€‰æ‹©åŒç±»å‹çš„é«˜æˆåŠŸç‡æ¨¡æ¿
        relevant = [
            t for t in templates
            if t.get('task_type') == target_type and t.get('success_rate', 0) > 0.7
        ]
        return relevant[:3]  # é™åˆ¶æ•°é‡

    def _adapt_strategies(self,
                         strategies: List[str],
                         target_task: Dict[str, Any]) -> List[str]:
        """é€‚é…å­¦ä¹ ç­–ç•¥"""
        # ç®€åŒ–ï¼šç›´æ¥è¿”å›ç­–ç•¥
        return strategies

    def _compute_transfer_score(self,
                                meta_knowledge: MetaKnowledge,
                                target_task: Dict[str, Any]) -> float:
        """è®¡ç®—è¿ç§»è¯„åˆ†"""
        # åŸºäºå…ƒçŸ¥è¯†çš„å¯è¿ç§»æ€§
        base_score = meta_knowledge.transferability_score

        # æ ¹æ®ç›®æ ‡ä»»åŠ¡è°ƒæ•´
        task_complexity = target_task.get('complexity', 0.5)
        adjusted_score = base_score * (1 + task_complexity)

        return min(adjusted_score, 1.0)

    def _compute_adaptation_effort(self,
                                   meta_knowledge: MetaKnowledge,
                                   target_task: Dict[str, Any]) -> float:
        """è®¡ç®—é€‚é…æˆæœ¬ï¼ˆ0-1ï¼Œè¶Šä½è¶Šå¥½ï¼‰"""
        # ç®€åŒ–ï¼šåŸºäºå…ƒçŸ¥è¯†æ•°é‡
        knowledge_size = (
            len(meta_knowledge.abstract_patterns) +
            len(meta_knowledge.learning_strategies) +
            len(meta_knowledge.problem_solving_templates)
        )

        # çŸ¥è¯†è¶Šå¤šï¼Œé€‚é…æˆæœ¬è¶Šé«˜
        effort = min(knowledge_size / 50, 1.0)
        return effort

    def _estimate_improvements(self,
                              transfer_score: float,
                              adaptation_effort: float) -> Dict[str, float]:
        """ä¼°ç®—æ€§èƒ½æå‡"""
        # å‡€æ”¶ç›Š = è¿ç§»è¯„åˆ† - é€‚é…æˆæœ¬
        net_benefit = transfer_score - adaptation_effort * 0.3

        return {
            'learning_speed': net_benefit * 0.5,  # å­¦ä¹ é€Ÿåº¦æå‡
            'accuracy': net_benefit * 0.3,  # å‡†ç¡®ç‡æå‡
            'efficiency': net_benefit * 0.2  # æ•ˆç‡æå‡
        }


# ==================== 3. å°‘æ ·æœ¬å­¦ä¹ å™¨ ====================

class FewShotLearner:
    """
    å°‘æ ·æœ¬å­¦ä¹ å™¨

    åŠŸèƒ½:
    1. ä»å°‘é‡æ ·æœ¬å¿«é€Ÿå­¦ä¹ 
    2. å…ƒåˆå§‹åŒ–
    3. å¿«é€Ÿé€‚åº”
    """

    def __init__(self, num_shots: int = 5):
        """
        åˆå§‹åŒ–å°‘æ ·æœ¬å­¦ä¹ å™¨

        Args:
            num_shots: ä½¿ç”¨çš„æ ·æœ¬æ•°é‡ï¼ˆé»˜è®¤5ä¸ªï¼‰
        """
        self.num_shots = num_shots
        self.learned_models = {}  # å·²å­¦ä¹ çš„æ¨¡å‹
        self.meta_initialization = None  # å…ƒåˆå§‹åŒ–å‚æ•°

    def meta_initialize(self, meta_knowledge: Optional[MetaKnowledge] = None):
        """
        å…ƒåˆå§‹åŒ–ï¼ˆå­¦ä¹ å¦‚ä½•å­¦ä¹ ï¼‰

        Args:
            meta_knowledge: å¯é€‰çš„å…ƒçŸ¥è¯†
        """
        # ç®€åŒ–ï¼šä½¿ç”¨é»˜è®¤åˆå§‹åŒ–
        self.meta_initialization = {
            'learning_rate': 0.01,
            'adaptation_steps': 10,
            'initialization_strategy': 'meta_learned'
        }

        if meta_knowledge:
            # ä½¿ç”¨å…ƒçŸ¥è¯†è°ƒæ•´åˆå§‹åŒ–
            self.meta_initialization['transferability'] = meta_knowledge.transferability_score
            self.meta_initialization['patterns'] = len(meta_knowledge.abstract_patterns)

        logger.info(f"[FewShotLearner] å…ƒåˆå§‹åŒ–å®Œæˆ: {self.meta_initialization}")

    def learn_from_few_shots(self,
                            examples: List[FewShotExample],
                            task_type: str) -> Dict[str, Any]:
        """
        ä»å°‘é‡æ ·æœ¬å­¦ä¹ 

        Args:
            examples: è®­ç»ƒç¤ºä¾‹ï¼ˆå°‘é‡ï¼‰
            task_type: ä»»åŠ¡ç±»å‹

        Returns:
            å­¦ä¹ åˆ°çš„æ¨¡å‹
        """
        if len(examples) > self.num_shots:
            logger.warning(f"[FewShotLearner] æ ·æœ¬æ•°({len(examples)})è¶…è¿‡è®¾å®šå€¼({self.num_shots})ï¼Œ"
                          f"å°†åªä½¿ç”¨å‰{self.num_shots}ä¸ª")
            examples = examples[:self.num_shots]

        logger.info(f"[FewShotLearner] ä»{len(examples)}ä¸ªæ ·æœ¬å­¦ä¹  (ä»»åŠ¡ç±»å‹: {task_type})")

        # 1. å…ƒåˆå§‹åŒ–
        if not self.meta_initialization:
            self.meta_initialize()

        # 2. ä»ç¤ºä¾‹ä¸­æå–æ¨¡å¼
        patterns = self._extract_patterns_from_examples(examples)

        # 3. æ„å»ºå¿«é€Ÿé€‚åº”æ¨¡å‹
        model = self._build_adaptive_model(patterns, task_type)

        # 4. ä¿å­˜æ¨¡å‹
        self.learned_models[task_type] = model

        logger.info(f"[FewShotLearner] å­¦ä¹ å®Œæˆ: {len(patterns)} ä¸ªæ¨¡å¼")

        return model

    def adapt_to_new_task(self,
                         examples: List[FewShotExample],
                         task_type: str,
                         base_model: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        é€‚åº”æ–°ä»»åŠ¡ï¼ˆä½¿ç”¨å·²å­¦ä¹ çš„æ¨¡å‹ä½œä¸ºèµ·ç‚¹ï¼‰

        Args:
            examples: æ–°ä»»åŠ¡çš„ç¤ºä¾‹
            task_type: ä»»åŠ¡ç±»å‹
            base_model: åŸºç¡€æ¨¡å‹ï¼ˆå¯é€‰ï¼‰

        Returns:
            é€‚åº”åçš„æ¨¡å‹
        """
        # ä½¿ç”¨å·²æœ‰æ¨¡å‹æˆ–åˆ›å»ºæ–°æ¨¡å‹
        if base_model is None and task_type in self.learned_models:
            base_model = self.learned_models[task_type]

        if base_model:
            logger.info(f"[FewShotLearner] åŸºäºå·²æœ‰æ¨¡å‹é€‚åº”æ–°ä»»åŠ¡")
            # åŸºäºå·²æœ‰æ¨¡å‹å¿«é€Ÿé€‚åº”
            adapted_model = self._rapid_adaptation(base_model, examples)
        else:
            logger.info(f"[FewShotLearner] ä»é›¶å­¦ä¹ æ–°ä»»åŠ¡")
            # ä»é›¶å¼€å§‹å­¦ä¹ 
            adapted_model = self.learn_from_few_shots(examples, task_type)

        return adapted_model

    def predict(self,
               model: Dict[str, Any],
               input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä½¿ç”¨å­¦ä¹ åˆ°çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹

        Args:
            model: å­¦ä¹ åˆ°çš„æ¨¡å‹
            input_data: è¾“å…¥æ•°æ®

        Returns:
            é¢„æµ‹ç»“æœ
        """
        # ç®€åŒ–ï¼šåŸºäºæ¨¡å¼åŒ¹é…
        patterns = model.get('patterns', [])

        # å¯»æ‰¾æœ€åŒ¹é…çš„æ¨¡å¼
        best_match = None
        best_score = 0.0

        for pattern in patterns:
            score = self._match_pattern(pattern, input_data)
            if score > best_score:
                best_score = score
                best_match = pattern

        if best_match:
            return {
                'prediction': best_match.get('output', {}),
                'confidence': best_score,
                'matched_pattern': best_match.get('signature', 'unknown')
            }
        else:
            return {
                'prediction': {},
                'confidence': 0.0,
                'error': 'No matching pattern found'
            }

    def _extract_patterns_from_examples(self, examples: List[FewShotExample]) -> List[Dict[str, Any]]:
        """ä»ç¤ºä¾‹ä¸­æå–æ¨¡å¼"""
        patterns = []

        for example in examples:
            pattern = {
                'input_signature': self._get_signature(example.input_data),
                'output': example.output_data,
                'domain': example.domain,
                'task_type': example.task_type,
                'signature': f"{example.domain}_{example.task_type}_{len(patterns)}"
            }
            patterns.append(pattern)

        return patterns

    def _build_adaptive_model(self, patterns: List[Dict[str, Any]], task_type: str) -> Dict[str, Any]:
        """æ„å»ºå¿«é€Ÿé€‚åº”æ¨¡å‹"""
        return {
            'task_type': task_type,
            'patterns': patterns,
            'learning_strategy': self.meta_initialization.get('initialization_strategy', 'default'),
            'adaptation_rate': self.meta_initialization.get('learning_rate', 0.01)
        }

    def _rapid_adaptation(self, base_model: Dict[str, Any], examples: List[FewShotExample]) -> Dict[str, Any]:
        """å¿«é€Ÿé€‚åº”ï¼ˆåŸºäºå·²æœ‰æ¨¡å‹ï¼‰"""
        # åˆå¹¶åŸºç¡€æ¨¡å‹çš„æ¨¡å¼å’Œæ–°ç¤ºä¾‹çš„æ¨¡å¼
        existing_patterns = base_model.get('patterns', [])
        new_patterns = self._extract_patterns_from_examples(examples)

        # åˆå¹¶å¹¶å»é‡
        all_patterns = existing_patterns + new_patterns
        unique_patterns = []
        seen_signatures = set()

        for pattern in all_patterns:
            sig = pattern.get('signature')
            if sig not in seen_signatures:
                unique_patterns.append(pattern)
                seen_signatures.add(sig)

        # åˆ›å»ºé€‚åº”åçš„æ¨¡å‹
        adapted_model = {
            **base_model,
            'patterns': unique_patterns,
            'adapted': True,
            'adaptation_count': len(new_patterns)
        }

        return adapted_model

    def _match_pattern(self, pattern: Dict[str, Any], input_data: Dict[str, Any]) -> float:
        """åŒ¹é…æ¨¡å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        # ç®€åŒ–ï¼šä½¿ç”¨é”®çš„åŒ¹é…åº¦
        pattern_keys = set(pattern.get('input_signature', {}).keys())
        input_keys = set(input_data.keys())

        if not pattern_keys:
            return 0.0

        intersection = len(pattern_keys & input_keys)
        return intersection / len(pattern_keys)

    def _get_signature(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–æ•°æ®ç­¾åï¼ˆç®€åŒ–çš„ç»“æ„è¡¨ç¤ºï¼‰"""
        return {key: type(value).__name__ for key, value in data.items()}


# ==================== 4. æŠ€èƒ½æå–å™¨ ====================

class SkillExtractor:
    """
    æŠ€èƒ½æå–å™¨

    åŠŸèƒ½:
    1. ä»ç»éªŒä¸­æå–å¯å¤ç”¨çš„æŠ€èƒ½
    2. æŠ½è±¡æŠ€èƒ½æ¨¡å¼
    3. æŠ€èƒ½åˆ†ç±»ä¸ç´¢å¼•
    """

    def __init__(self):
        """åˆå§‹åŒ–æŠ€èƒ½æå–å™¨"""
        self.skill_library = {}  # æŠ€èƒ½åº“
        self.skill_categories = defaultdict(list)  # æŠ€èƒ½åˆ†ç±»

    def extract_skills(self, experiences: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ä»ç»éªŒä¸­æå–æŠ€èƒ½

        Args:
            experiences: ç»éªŒåˆ—è¡¨

        Returns:
            æå–çš„æŠ€èƒ½åˆ—è¡¨
        """
        extracted_skills = []

        for exp in experiences:
            # 1. è¯†åˆ«æŠ€èƒ½ç±»å‹
            skill_type = self._identify_skill_type(exp)

            # 2. æå–æŠ€èƒ½å‚æ•°
            skill_params = self._extract_skill_parameters(exp)

            # 3. è¯„ä¼°æŠ€èƒ½è´¨é‡
            skill_quality = self._evaluate_skill_quality(exp)

            # 4. æ„å»ºæŠ€èƒ½
            skill = {
                'type': skill_type,
                'parameters': skill_params,
                'quality': skill_quality,
                'source': exp.get('source', 'unknown'),
                'success_rate': exp.get('success_rate', 0.5),
                'usage_count': 0
            }

            # 5. åˆ†ç±»æŠ€èƒ½
            self._categorize_skill(skill)

            extracted_skills.append(skill)

        logger.info(f"[SkillExtractor] æå–{len(extracted_skills)}ä¸ªæŠ€èƒ½")

        return extracted_skills

    def _identify_skill_type(self, experience: Dict[str, Any]) -> str:
        """è¯†åˆ«æŠ€èƒ½ç±»å‹"""
        # ç®€åŒ–ï¼šåŸºäºç»éªŒçš„æ“ä½œç±»å‹
        operations = experience.get('operations', [])
        if not operations:
            return 'generic'

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ“ä½œä½œä¸ºç±»å‹
        return operations[0] if isinstance(operations[0], str) else 'complex'

    def _extract_skill_parameters(self, experience: Dict[str, Any]) -> Dict[str, Any]:
        """æå–æŠ€èƒ½å‚æ•°"""
        # ç®€åŒ–ï¼šæå–å…³é”®å‚æ•°
        return {
            'complexity': experience.get('complexity', 0.5),
            'duration': experience.get('duration', 0),
            'resources': experience.get('resources', {}),
            'preconditions': experience.get('preconditions', [])
        }

    def _evaluate_skill_quality(self, experience: Dict[str, Any]) -> float:
        """è¯„ä¼°æŠ€èƒ½è´¨é‡"""
        # åŸºäºæˆåŠŸç‡å’Œæ•ˆç‡
        success_rate = experience.get('success_rate', 0.5)
        efficiency = experience.get('efficiency', 0.5)

        return (success_rate + efficiency) / 2

    def _categorize_skill(self, skill: Dict[str, Any]):
        """åˆ†ç±»æŠ€èƒ½"""
        skill_type = skill['type']
        self.skill_categories[skill_type].append(skill)

        # æ·»åŠ åˆ°æŠ€èƒ½åº“
        skill_id = f"{skill_type}_{len(self.skill_library)}"
        self.skill_library[skill_id] = skill

    def find_similar_skills(self, target_skill: Dict[str, Any], top_k: int = 5) -> List[Tuple[str, Dict[str, Any]]]:
        """æŸ¥æ‰¾ç›¸ä¼¼æŠ€èƒ½"""
        similarities = []

        for skill_id, skill in self.skill_library.items():
            similarity = self._compute_skill_similarity(target_skill, skill)
            similarities.append((skill_id, skill, similarity))

        # æ’åºå¹¶è¿”å›top_k
        similarities.sort(key=lambda x: x[2], reverse=True)
        return [(sid, skill) for sid, skill, _ in similarities[:top_k]]

    def _compute_skill_similarity(self, skill1: Dict[str, Any], skill2: Dict[str, Any]) -> float:
        """è®¡ç®—æŠ€èƒ½ç›¸ä¼¼åº¦"""
        # ç®€åŒ–ï¼šåŸºäºç±»å‹å’Œå‚æ•°
        if skill1['type'] != skill2['type']:
            return 0.0

        # å‚æ•°ç›¸ä¼¼åº¦
        params1 = skill1.get('parameters', {})
        params2 = skill2.get('parameters', {})

        common_keys = set(params1.keys()) & set(params2.keys())
        if not common_keys:
            return 0.0

        similarity_sum = 0.0
        for key in common_keys:
            val1 = params1[key]
            val2 = params2[key]
            if isinstance(val1, (int, float)) and isinstance(val2, (int, float)):
                # æ•°å€¼ç›¸ä¼¼åº¦
                diff = abs(val1 - val2)
                max_val = max(abs(val1), abs(val2), 1.0)
                similarity_sum += 1 - (diff / max_val)
            elif val1 == val2:
                similarity_sum += 1.0

        return similarity_sum / len(common_keys)


# ==================== 5. è·¨åŸŸè¿ç§»ç³»ç»Ÿé›†æˆ ====================

class CrossDomainTransferSystem:
    """
    è·¨åŸŸè¿ç§»ç³»ç»Ÿé›†æˆ

    æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œæä¾›ç»Ÿä¸€çš„è·¨åŸŸè¿ç§»æ¥å£
    
    ğŸ†• [2026-01-24] æ‹“æ‰‘è¿æ¥å¢å¼º:
    - æ–°å¢ RecursiveSelfMemory è¿æ¥ï¼šè®°å½•è·¨åŸŸå­¦ä¹ ç»éªŒï¼Œå¢å¼ºå…ƒå­¦ä¹ èƒ½åŠ›
    """

    def __init__(self, recursive_self_memory=None):
        """
        åˆå§‹åŒ–è·¨åŸŸè¿ç§»ç³»ç»Ÿ
        
        Args:
            recursive_self_memory: ğŸ†• é€’å½’è‡ªå¼•ç”¨è®°å¿†ï¼ˆç”¨äºè®°å½•è·¨åŸŸå­¦ä¹ ç»éªŒï¼‰
        """
        self.mapper = CrossDomainMapper()
        self.meta_learning = MetaLearningTransfer()
        self.few_shot_learner = FewShotLearner()
        self.skill_extractor = SkillExtractor()

        self.transfer_history = []  # è¿ç§»å†å²
        self.performance_metrics = defaultdict(list)  # æ€§èƒ½æŒ‡æ ‡
        
        # ğŸ†• [2026-01-24] æ‹“æ‰‘è¿æ¥: RecursiveSelfMemory
        self.recursive_self_memory = recursive_self_memory

    def transfer_knowledge(self,
                          source_domain: str,
                          target_domain: str,
                          source_knowledge: DomainKnowledge,
                          target_knowledge: DomainKnowledge) -> TransferResult:
        """
        æ‰§è¡Œå®Œæ•´çš„è·¨åŸŸçŸ¥è¯†è¿ç§»æµç¨‹

        æµç¨‹:
        1. æå–æŠ½è±¡ç»“æ„
        2. æ˜ å°„åˆ°ç›®æ ‡åŸŸ
        3. è¯„ä¼°æ˜ å°„è´¨é‡
        4. è¿”å›è¿ç§»ç»“æœ

        Args:
            source_domain: æºé¢†åŸŸåç§°
            target_domain: ç›®æ ‡é¢†åŸŸåç§°
            source_knowledge: æºé¢†åŸŸçŸ¥è¯†
            target_knowledge: ç›®æ ‡é¢†åŸŸçŸ¥è¯†

        Returns:
            è¿ç§»ç»“æœ
        """
        logger.info(f"[CrossDomainTransfer] å¼€å§‹è¿ç§»: {source_domain} â†’ {target_domain}")

        try:
            # 1. æå–æŠ½è±¡ç»“æ„
            abstract_structure = self.mapper.extract_abstract_structure(source_knowledge)

            # 2. æ˜ å°„åˆ°ç›®æ ‡åŸŸ
            mapped_knowledge = self.mapper.map_to_target_domain(
                abstract_structure, target_knowledge
            )

            # 3. è¯„ä¼°æ˜ å°„è´¨é‡
            quality_score = self.mapper.evaluate_mapping_quality(
                mapped_knowledge, target_knowledge
            )

            # 4. æ„å»ºè¿ç§»ç»“æœ
            result = TransferResult(
                source_domain=source_domain,
                target_domain=target_domain,
                success=quality_score >= 0.5,  # è´¨é‡é˜ˆå€¼0.5
                transferred_knowledge=mapped_knowledge,
                transfer_score=quality_score,
                adaptation_effort=1.0 - quality_score,  # è´¨é‡è¶Šé«˜ï¼Œæˆæœ¬è¶Šä½
                improvements={
                    'knowledge_transfer': quality_score,
                    'expected_performance_gain': quality_score * 0.3
                }
            )

            self.transfer_history.append(result)
            
            # ğŸ†• [2026-01-24] æ‹“æ‰‘è¿æ¥: è®°å½•æˆåŠŸçš„è¿ç§»ç»éªŒåˆ°é€’å½’è‡ªå¼•ç”¨è®°å¿†
            if self.recursive_self_memory and result.success:
                try:
                    self.recursive_self_memory.store_experience(
                        experience={
                            'type': 'cross_domain_transfer',
                            'source_domain': source_domain,
                            'target_domain': target_domain,
                            'transfer_score': quality_score,
                            'patterns_transferred': len(abstract_structure.get('patterns', [])),
                            'skills_transferred': len(abstract_structure.get('skills', []))
                        },
                        why_remembered=f"æˆåŠŸçš„è·¨åŸŸè¿ç§»: {source_domain}â†’{target_domain}",
                        importance='high' if quality_score >= 0.7 else 'medium'
                    )
                    logger.debug(f"[CrossDomainTransfer] è¿ç§»ç»éªŒå·²è®°å½•åˆ°RecursiveSelfMemory")
                except Exception as mem_err:
                    logger.debug(f"[CrossDomainTransfer] è®°å¿†è®°å½•å¤±è´¥: {mem_err}")

            logger.info(f"[CrossDomainTransfer] è¿ç§»å®Œæˆ: æˆåŠŸ={result.success}, "
                       f"è¯„åˆ†={quality_score:.3f}")

            return result

        except Exception as e:
            logger.error(f"[CrossDomainTransfer] è¿ç§»å¤±è´¥: {e}")
            return TransferResult(
                source_domain=source_domain,
                target_domain=target_domain,
                success=False,
                transferred_knowledge=None,
                transfer_score=0.0,
                adaptation_effort=1.0,
                improvements={},
                errors=[str(e)]
            )

    def meta_learning_transfer(self,
                               source_tasks: List[Dict[str, Any]],
                               target_task: Dict[str, Any],
                               target_domain: str) -> TransferResult:
        """
        ä½¿ç”¨å…ƒå­¦ä¹ è¿›è¡Œè¿ç§»

        Args:
            source_tasks: æºä»»åŠ¡åˆ—è¡¨
            target_task: ç›®æ ‡ä»»åŠ¡
            target_domain: ç›®æ ‡é¢†åŸŸ

        Returns:
            è¿ç§»ç»“æœ
        """
        logger.info(f"[CrossDomainTransfer] å…ƒå­¦ä¹ è¿ç§»: {len(source_tasks)}ä¸ªä»»åŠ¡ â†’ {target_domain}")

        # 1. æå–å…ƒçŸ¥è¯†
        meta_knowledge = self.meta_learning.extract_meta_knowledge(
            source_tasks, target_domain
        )

        # 2. é€‚é…åˆ°ç›®æ ‡ä»»åŠ¡
        result = self.meta_learning.adapt_to_target(
            meta_knowledge, target_task, target_domain
        )

        return result

    def few_shot_learning(self,
                         examples: List[FewShotExample],
                         task_type: str,
                         adapt: bool = False) -> Dict[str, Any]:
        """
        æ‰§è¡Œå°‘æ ·æœ¬å­¦ä¹ 

        Args:
            examples: è®­ç»ƒç¤ºä¾‹
            task_type: ä»»åŠ¡ç±»å‹
            adapt: æ˜¯å¦åŸºäºå·²æœ‰æ¨¡å‹é€‚åº”

        Returns:
            å­¦ä¹ åˆ°çš„æ¨¡å‹
        """
        logger.info(f"[CrossDomainTransfer] å°‘æ ·æœ¬å­¦ä¹ : {len(examples)}ä¸ªç¤ºä¾‹, ä»»åŠ¡={task_type}")

        if adapt:
            # åŸºäºå·²æœ‰æ¨¡å‹é€‚åº”
            model = self.few_shot_learner.adapt_to_new_task(examples, task_type)
        else:
            # ä»é›¶å­¦ä¹ 
            model = self.few_shot_learner.learn_from_few_shots(examples, task_type)

        return model

    def extract_and_index_skills(self, experiences: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        æå–å¹¶ç´¢å¼•æŠ€èƒ½

        Args:
            experiences: ç»éªŒåˆ—è¡¨

        Returns:
            æå–çš„æŠ€èƒ½åˆ—è¡¨
        """
        logger.info(f"[CrossDomainTransfer] æå–æŠ€èƒ½: {len(experiences)}ä¸ªç»éªŒ")

        skills = self.skill_extractor.extract_skills(experiences)
        return skills

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
        return {
            'total_transfers': len(self.transfer_history),
            'successful_transfers': sum(1 for t in self.transfer_history if t.success),
            'average_transfer_score': np.mean([t.transfer_score for t in self.transfer_history]) if self.transfer_history else 0.0,
            'skill_library_size': len(self.skill_extractor.skill_library),
            'skill_categories': {
                category: len(skills)
                for category, skills in self.skill_extractor.skill_categories.items()
            },
            'few_shot_models': len(self.few_shot_learner.learned_models)
        }


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

if __name__ == "__main__":
    import sys
    import io
    if sys.platform == 'win32':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

    print("=" * 70)
    print("è·¨åŸŸçŸ¥è¯†è¿ç§»ç³»ç»Ÿæµ‹è¯•")
    print("=" * 70)

    # åˆ›å»ºç³»ç»Ÿ
    system = CrossDomainTransferSystem()

    # ==================== æµ‹è¯•1: è·¨åŸŸçŸ¥è¯†æ˜ å°„ ====================
    print("\næµ‹è¯•1: è·¨åŸŸçŸ¥è¯†æ˜ å°„")
    print("-" * 70)

    # åˆ›å»ºæºé¢†åŸŸçŸ¥è¯†ï¼ˆæ•°å­¦åŸŸï¼‰
    math_knowledge = DomainKnowledge(
        domain='mathematics',
        concepts={'equation', 'variable', 'solution', 'function'},
        relations={
            ('equation', 'variable'): 'contains',
            ('equation', 'solution'): 'has',
            ('function', 'variable'): 'depends_on'
        },
        patterns=[
            {'type': 'linear', 'form': 'ax + b = 0'},
            {'type': 'quadratic', 'form': 'ax^2 + bx + c = 0'},
            {'type': 'equation', 'operation': 'solve_for_x'}
        ],
        skills=[
            {'type': 'solve_equation', 'method': 'algebraic', 'operations': ['isolate', 'substitute']},
            {'type': 'graph_function', 'method': 'plotting', 'operations': ['calculate_points', 'draw']}
        ]
    )

    # åˆ›å»ºç›®æ ‡é¢†åŸŸçŸ¥è¯†ï¼ˆç‰©ç†åŸŸï¼‰
    physics_knowledge = DomainKnowledge(
        domain='physics',
        concepts={'force', 'mass', 'acceleration', 'equation'},
        relations={
            ('force', 'mass'): 'proportional',
            ('force', 'acceleration'): 'related',
            ('equation', 'force'): 'describes'
        },
        patterns=[
            {'type': 'newton', 'form': 'F = ma'},
            {'type': 'kinematic', 'form': 'v = v0 + at'}
        ],
        skills=[
            {'type': 'apply_formula', 'method': 'substitution', 'operations': ['identify_vars', 'calculate']}
        ]
    )

    # æ‰§è¡Œè·¨åŸŸè¿ç§»
    result = system.transfer_knowledge(
        source_domain='mathematics',
        target_domain='physics',
        source_knowledge=math_knowledge,
        target_knowledge=physics_knowledge
    )

    print(f"è¿ç§»ç»“æœ: {'âœ… æˆåŠŸ' if result.success else 'âŒ å¤±è´¥'}")
    print(f"è¿ç§»è¯„åˆ†: {result.transfer_score:.3f}")
    print(f"é€‚é…æˆæœ¬: {result.adaptation_effort:.3f}")
    print(f"é¢„æœŸæå‡: {result.improvements}")
    if result.transferred_knowledge:
        print(f"è¿ç§»çš„æ¦‚å¿µ: {len(result.transferred_knowledge.concepts)} ä¸ª")
        print(f"è¿ç§»çš„æŠ€èƒ½: {len(result.transferred_knowledge.skills)} ä¸ª")

    # ==================== æµ‹è¯•2: å…ƒå­¦ä¹ è¿ç§» ====================
    print("\næµ‹è¯•2: å…ƒå­¦ä¹ è¿ç§»")
    print("-" * 70)

    # åˆ›å»ºæºä»»åŠ¡
    source_tasks = [
        {
            'type': 'optimization',
            'patterns': [{'method': 'gradient_descent', 'learning_rate': 0.01}],
            'learning_strategies': ['iterative', 'gradient_based'],
            'solution_steps': ['initialize', 'compute_gradient', 'update', 'repeat'],
            'success_rate': 0.85
        },
        {
            'type': 'optimization',
            'patterns': [{'method': 'adam', 'learning_rate': 0.001}],
            'learning_strategies': ['iterative', 'momentum_based'],
            'solution_steps': ['initialize', 'compute_gradient', 'update_momentum', 'update', 'repeat'],
            'success_rate': 0.90
        }
    ]

    # åˆ›å»ºç›®æ ‡ä»»åŠ¡
    target_task = {
        'type': 'optimization',
        'complexity': 0.7,
        'description': 'Hyperparameter tuning'
    }

    # æ‰§è¡Œå…ƒå­¦ä¹ è¿ç§»
    meta_result = system.meta_learning_transfer(
        source_tasks=source_tasks,
        target_task=target_task,
        target_domain='machine_learning'
    )

    print(f"å…ƒå­¦ä¹ è¿ç§»: {'âœ… æˆåŠŸ' if meta_result.success else 'âŒ å¤±è´¥'}")
    print(f"è¿ç§»è¯„åˆ†: {meta_result.transfer_score:.3f}")
    print(f"é€‚é…æˆæœ¬: {meta_result.adaptation_effort:.3f}")
    print(f"æ€§èƒ½æå‡: {meta_result.improvements}")

    # ==================== æµ‹è¯•3: å°‘æ ·æœ¬å­¦ä¹  ====================
    print("\næµ‹è¯•3: å°‘æ ·æœ¬å­¦ä¹ ")
    print("-" * 70)

    # åˆ›å»ºè®­ç»ƒç¤ºä¾‹
    examples = [
        FewShotExample(
            input_data={'x': 1, 'y': 2},
            output_data={'sum': 3, 'product': 2},
            domain='arithmetic',
            task_type='basic_ops'
        ),
        FewShotExample(
            input_data={'x': 5, 'y': 3},
            output_data={'sum': 8, 'product': 15},
            domain='arithmetic',
            task_type='basic_ops'
        ),
        FewShotExample(
            input_data={'x': 10, 'y': 7},
            output_data={'sum': 17, 'product': 70},
            domain='arithmetic',
            task_type='basic_ops'
        )
    ]

    # æ‰§è¡Œå°‘æ ·æœ¬å­¦ä¹ 
    model = system.few_shot_learning(
        examples=examples,
        task_type='basic_ops'
    )

    print(f"å­¦ä¹ åˆ°çš„æ¨¡å‹: {model['task_type']}")
    print(f"æ¨¡å¼æ•°é‡: {len(model['patterns'])}")
    print(f"å­¦ä¹ ç­–ç•¥: {model['learning_strategy']}")

    # æµ‹è¯•é¢„æµ‹
    test_input = {'x': 4, 'y': 6}
    prediction = system.few_shot_learner.predict(model, test_input)

    print(f"\né¢„æµ‹æµ‹è¯•:")
    print(f"  è¾“å…¥: {test_input}")
    print(f"  é¢„æµ‹: {prediction['prediction']}")
    print(f"  ç½®ä¿¡åº¦: {prediction['confidence']:.3f}")

    # ==================== æµ‹è¯•4: æŠ€èƒ½æå– ====================
    print("\næµ‹è¯•4: æŠ€èƒ½æå–")
    print("-" * 70)

    # åˆ›å»ºç»éªŒæ•°æ®
    experiences = [
        {
            'operations': ['plan', 'execute', 'evaluate'],
            'success_rate': 0.8,
            'efficiency': 0.7,
            'complexity': 0.6,
            'source': 'task_1'
        },
        {
            'operations': ['analyze', 'design', 'implement'],
            'success_rate': 0.9,
            'efficiency': 0.85,
            'complexity': 0.8,
            'source': 'task_2'
        }
    ]

    # æå–æŠ€èƒ½
    skills = system.extract_and_index_skills(experiences)

    print(f"æå–çš„æŠ€èƒ½: {len(skills)} ä¸ª")
    for skill in skills:
        print(f"  - ç±»å‹: {skill['type']}, è´¨é‡: {skill['quality']:.2f}, "
              f"æˆåŠŸç‡: {skill['success_rate']:.2f}")

    # ==================== ç³»ç»Ÿç»Ÿè®¡ ====================
    print("\n" + "=" * 70)
    print("ç³»ç»Ÿç»Ÿè®¡")
    print("=" * 70)

    stats = system.get_statistics()
    print(f"æ€»è¿ç§»æ•°: {stats['total_transfers']}")
    print(f"æˆåŠŸè¿ç§»: {stats['successful_transfers']}")
    print(f"å¹³å‡è¯„åˆ†: {stats['average_transfer_score']:.3f}")
    print(f"æŠ€èƒ½åº“å¤§å°: {stats['skill_library_size']}")
    print(f"æŠ€èƒ½åˆ†ç±»: {stats['skill_categories']}")
    print(f"å°‘æ ·æœ¬æ¨¡å‹æ•°: {stats['few_shot_models']}")

    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
    print("=" * 70)
