import os
import json
import logging
import time
import inspect
from datetime import datetime
from typing import Dict, Any, List

from core.llm_client import LLMService
# Import new cognitive metrics
try:
    from core.cognitive_metrics import (
        fractal_coherence_index, 
        detect_internal_resonance,
        calculate_metaphoric_drift,
        calculate_system_entropy
    )
except ImportError:
    # Fallback if file not created yet or dependencies missing
    def fractal_coherence_index(x): return 0.0
    def detect_internal_resonance(x): return 0.0
    def calculate_metaphoric_drift(x): return 0.0
    def calculate_system_entropy(x): return 0.0

logger = logging.getLogger(__name__)

# [2026-01-09] Phase2å¹»è§‰ä¿®å¤: ç¡®å®šæ€§éªŒè¯å™¨
class DeterministicValidator:
    """
    ç¡®å®šæ€§éªŒè¯å™¨ - ä½¿ç”¨ç¡¬ç¼–ç è§„åˆ™éªŒè¯LLMæ–­è¨€çœŸå®æ€§
    é˜²æ­¢å…ƒå¹»è§‰(LLMå¯¹è‡ªå·±çš„è¯„ä¼°ä¹Ÿå¯èƒ½æ˜¯å¹»è§‰)
    """
    def __init__(self, tool_bridge=None):
        self.tool_bridge = tool_bridge
        self.validation_failures = []
    
    def validate_tool_call(self, tool_name: str, operation: str = None) -> Dict[str, Any]:
        """
        éªŒè¯å·¥å…·è°ƒç”¨çœŸå®æ€§
        è¿”å›: {"valid": bool, "reason": str, "evidence": Any}
        """
        result = {"valid": False, "reason": "æœªéªŒè¯", "evidence": None}
        
        # æ£€æŸ¥1: å·¥å…·æ˜¯å¦åœ¨ç™½åå•ä¸­
        if self.tool_bridge:
            try:
                available_tools = self.tool_bridge.get_available_tools()
                if tool_name not in available_tools:
                    result["reason"] = f"å·¥å…·'{tool_name}'ä¸åœ¨ç™½åå•ä¸­(å…±{len(available_tools)}ä¸ªå¯ç”¨å·¥å…·)"
                    result["evidence"] = {"available": available_tools[:10]}  # åªè¿”å›å‰10ä¸ª
                    self.validation_failures.append(result)
                    return result
                result["valid"] = True
                result["reason"] = f"å·¥å…·å­˜åœ¨äºç™½åå•({len(available_tools)}ä¸ªå·¥å…·ä¸­)"
                result["evidence"] = {"tool_name": tool_name}
            except Exception as e:
                result["reason"] = f"ç™½åå•æ£€æŸ¥å¼‚å¸¸: {e}"
                return result
        else:
            # æ— tool_bridgeæ—¶,ä½¿ç”¨ç¡¬ç¼–ç ç™½åå•
            hardcoded_tools = ['file_operation', 'world_model', 'memory', 'openhands', 
                             'autonomous_document_create', 'knowledge_graph']
            if tool_name not in hardcoded_tools:
                result["reason"] = f"å·¥å…·'{tool_name}'ä¸åœ¨ç¡¬ç¼–ç ç™½åå•ä¸­"
                result["evidence"] = {"hardcoded_whitelist": hardcoded_tools}
                self.validation_failures.append(result)
                return result
            result["valid"] = True
            result["reason"] = "å·¥å…·åœ¨ç¡¬ç¼–ç ç™½åå•ä¸­"
        
        return result
    
    def validate_numeric_sanity(self, value: Any, context: str = "") -> Dict[str, Any]:
        """
        éªŒè¯æ•°å€¼åˆç†æ€§(æ£€æµ‹NaN/Inf/è¶…å¤§å€¼)
        è¿”å›: {"valid": bool, "reason": str, "evidence": Any}
        """
        import math
        result = {"valid": True, "reason": "æ•°å€¼æ­£å¸¸", "evidence": value}
        
        try:
            if isinstance(value, (int, float)):
                if math.isnan(value):
                    result["valid"] = False
                    result["reason"] = f"{context}: æ•°å€¼ä¸ºNaN(Not a Number)"
                    self.validation_failures.append(result)
                elif math.isinf(value):
                    result["valid"] = False
                    result["reason"] = f"{context}: æ•°å€¼ä¸ºInfinity"
                    self.validation_failures.append(result)
                elif abs(value) > 1e10:
                    result["valid"] = False
                    result["reason"] = f"{context}: æ•°å€¼è¿‡å¤§(>{1e10})"
                    self.validation_failures.append(result)
        except Exception as e:
            result["valid"] = False
            result["reason"] = f"æ•°å€¼éªŒè¯å¼‚å¸¸: {e}"
        
        return result
    
    def validate_file_operation_claim(self, claim: Dict[str, Any]) -> Dict[str, Any]:
        """
        éªŒè¯æ–‡ä»¶æ“ä½œæ–­è¨€(é€šè¿‡å®é™…æ–‡ä»¶ç³»ç»Ÿæ£€æŸ¥)
        claimæ ¼å¼: {"action": "created/deleted/modified", "path": "xxx", "content_hash": "xxx"}
        """
        result = {"valid": False, "reason": "æœªéªŒè¯", "evidence": None}
        
        try:
            action = claim.get("action")
            path = claim.get("path")
            
            if not path:
                result["reason"] = "ç¼ºå°‘æ–‡ä»¶è·¯å¾„"
                return result
            
            import os
            import hashlib
            
            if action == "created":
                # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if os.path.exists(path):
                    result["valid"] = True
                    result["reason"] = "æ–‡ä»¶ç¡®å®å­˜åœ¨"
                    result["evidence"] = {"exists": True, "size": os.path.getsize(path)}
                else:
                    result["reason"] = "å£°ç§°åˆ›å»ºä½†æ–‡ä»¶ä¸å­˜åœ¨"
                    result["evidence"] = {"exists": False}
                    self.validation_failures.append(result)
            
            elif action == "deleted":
                # éªŒè¯æ–‡ä»¶æ˜¯å¦ä¸å­˜åœ¨
                if not os.path.exists(path):
                    result["valid"] = True
                    result["reason"] = "æ–‡ä»¶ç¡®å®ä¸å­˜åœ¨"
                    result["evidence"] = {"exists": False}
                else:
                    result["reason"] = "å£°ç§°åˆ é™¤ä½†æ–‡ä»¶ä»å­˜åœ¨"
                    result["evidence"] = {"exists": True}
                    self.validation_failures.append(result)
            
            elif action == "modified" and claim.get("content_hash"):
                # éªŒè¯æ–‡ä»¶hash
                if os.path.exists(path):
                    with open(path, 'rb') as f:
                        actual_hash = hashlib.md5(f.read()).hexdigest()
                    expected_hash = claim.get("content_hash")
                    if actual_hash == expected_hash:
                        result["valid"] = True
                        result["reason"] = "æ–‡ä»¶å†…å®¹hashåŒ¹é…"
                        result["evidence"] = {"hash_match": True}
                    else:
                        result["reason"] = f"æ–‡ä»¶hashä¸åŒ¹é…(æœŸæœ›:{expected_hash[:8]}, å®é™…:{actual_hash[:8]})"
                        result["evidence"] = {"expected": expected_hash, "actual": actual_hash}
                        self.validation_failures.append(result)
                else:
                    result["reason"] = "å£°ç§°ä¿®æ”¹ä½†æ–‡ä»¶ä¸å­˜åœ¨"
                    self.validation_failures.append(result)
        
        except Exception as e:
            result["reason"] = f"æ–‡ä»¶éªŒè¯å¼‚å¸¸: {e}"
        
        return result
    
    def get_failure_summary(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰éªŒè¯å¤±è´¥çš„æ‘˜è¦"""
        return {
            "total_failures": len(self.validation_failures),
            "failures": self.validation_failures[-10:],  # åªè¿”å›æœ€è¿‘10ä¸ª
            "failure_types": self._categorize_failures()
        }
    
    def _categorize_failures(self) -> Dict[str, int]:
        """åˆ†ç±»ç»Ÿè®¡å¤±è´¥ç±»å‹"""
        categories = {}
        for failure in self.validation_failures:
            reason = failure.get("reason", "æœªçŸ¥")
            # ç®€å•åˆ†ç±»
            if "å·¥å…·" in reason or "ç™½åå•" in reason:
                key = "å·¥å…·å¹»è§‰"
            elif "æ•°å€¼" in reason or "NaN" in reason or "Infinity" in reason:
                key = "æ•°å€¼å¼‚å¸¸"
            elif "æ–‡ä»¶" in reason:
                key = "æ–‡ä»¶æ“ä½œå¹»è§‰"
            else:
                key = "å…¶ä»–"
            categories[key] = categories.get(key, 0) + 1
        return categories

class MetacognitiveCore:
    def __init__(self, llm_service: LLMService):
        self.llm = llm_service
        self.history = []
        self.last_reflection_time = 0
        self.reflection_history_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), "data", "metacognition_history.json")
        os.makedirs(os.path.dirname(self.reflection_history_path), exist_ok=True)
        # [2026-01-09] Phase2: æ·»åŠ ç¡®å®šæ€§éªŒè¯å™¨
        self.validator = DeterministicValidator()

    def _load_history(self) -> List[Dict]:
        try:
            with open(self.reflection_history_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            return []

    def _save_history(self, history: List[Dict]):
        with open(self.reflection_history_path, 'w', encoding='utf-8') as f:
            json.dump(history, f, indent=2, ensure_ascii=False)

    def evaluate_self(self, recent_logs: List[str], goals_status: Dict[str, Any]) -> Dict[str, Any]:
        """
        Perform a comprehensive self-evaluation based on the "Intelligence Function" model:
        Intelligence = f(Perception, Reasoning, Action, Learning, Evolution)
        """
        logger.info("ğŸ§  Initiating Metacognitive Self-Evaluation...")
        
        # --- 1. Calculate Cognitive Metrics (FCI, Resonance) ---
        cognitive_state = {}
        try:
            # Extract timestamps from logs for FCI
            timestamps = []
            for log in recent_logs[-100:]: # Look at last 100 logs
                try:
                    # Assume log format: "YYYY-MM-DD HH:MM:SS..."
                    parts = log.split(' - ')
                    if len(parts) > 1:
                        ts_str = parts[0].strip().replace(',', '.')
                        if '.' in ts_str:
                            dt = datetime.strptime(ts_str, "%Y-%m-%d %H:%M:%S.%f")
                        else:
                            dt = datetime.strptime(ts_str, "%Y-%m-%d %H:%M:%S")
                        timestamps.append(dt.timestamp())
                except Exception:
                    continue
            
            if timestamps:
                fci_score = fractal_coherence_index(timestamps)
                cognitive_state['fractal_coherence_index'] = fci_score
                cognitive_state['interpretation'] = "High (>0.85) implies insight-ready state; Low (<0.5) implies random noise."
                
                # Internal Resonance (Mock signal for now)
                cognitive_state['internal_resonance'] = detect_internal_resonance([
                    timestamps, 
                    [t + 0.1 for t in timestamps] 
                ])

                # New Metrics
                cognitive_state['metaphoric_drift'] = calculate_metaphoric_drift(recent_logs[-50:])
                cognitive_state['system_entropy'] = calculate_system_entropy(recent_logs[-50:])
                
        except Exception as e:
            logger.warning(f"Failed to calculate cognitive metrics: {e}")
            cognitive_state['error'] = str(e)

        # --- 2. Construct Prompt (With Token Limit Safeguards) ---
        # Truncate logs to avoid token overflow
        truncated_logs = recent_logs[-30:] # Reduce from 50 to 30 lines
        
        prompt = f"""
        You are the Metacognitive Module of an AGI system. Your job is to objectively evaluate the system's current intelligence level based on recent logs and goal status.

        Model: Intelligence = f(Adaptability, Learning Rate, Goal Achievement, Efficiency)
        
        NEW COGNITIVE METRICS (Derived from Internal Resonance):
        {json.dumps(cognitive_state, indent=2)}

        INPUT DATA:
        1. Recent Logs (Last 30 lines):
        {json.dumps(truncated_logs, ensure_ascii=False)}
        
        2. Goal Status:
        {json.dumps(goals_status, ensure_ascii=False)}

        TASK:
        Analyze the system's performance. 
        - Did it adapt to failures? (Adaptability)
        - Did it learn from new inputs? (Learning Rate)
        - Did it achieve its goals? (Goal Achievement)
        
        OUTPUT FORMAT (JSON ONLY):
        {{
            "intelligence_index": 0-100,
            "metrics": {{
                "adaptability": 0-10,
                "learning_rate": 0-10,
                "goal_achievement": 0-10,
                "efficiency": 0-10
            }},
            "qualitative_analysis": "Brief analysis of strengths and weaknesses observed.",
            "insight": "One profound insight for self-improvement.",
            "parameter_adjustments": {{
                "curiosity_delta": -0.1 to 0.1,
                "frustration_tolerance_delta": -0.1 to 0.1
            }},
            "self_improvement_directive": "A specific, actionable instruction for the coding agent to modify the codebase (e.g., 'Update AGI_Life_Engine.py to increase sleep time', 'Refactor desktop_automation.py'). If the intelligence_index is below 80, you MUST provide a directive to improve the system (e.g. 'Add detailed logging to AGI_Life_Engine.py' or 'Create a new test file')."
        }}
        """
        
        try:
            response = self.llm.chat_completion(
                system_prompt="You are a rigorous AGI evaluator. Be critical and objective.",
                user_prompt=prompt
            )
            
            # Clean and parse JSON
            cleaned_response = response.replace("```json", "").replace("```", "").strip()
            evaluation = json.loads(cleaned_response)
            
            # [2026-01-09] Phase2: ç”¨ç¡®å®šæ€§éªŒè¯è¦†ç›–LLMä¹è§‚è¯„ä¼°
            deterministic_overrides = {}
            
            # æ£€æŸ¥validation failures
            failure_summary = self.validator.get_failure_summary()
            if failure_summary['total_failures'] > 0:
                logger.warning(f"âš ï¸ æ£€æµ‹åˆ°{failure_summary['total_failures']}ä¸ªéªŒè¯å¤±è´¥")
                
                # é™ä½intelligence_index(æ ¹æ®å¤±è´¥æ•°é‡)
                original_index = evaluation.get('intelligence_index', 50)
                penalty = min(30, failure_summary['total_failures'] * 5)  # æ¯ä¸ªå¤±è´¥æ‰£5åˆ†,æœ€å¤šæ‰£30åˆ†
                adjusted_index = max(0, original_index - penalty)
                
                deterministic_overrides['intelligence_index_override'] = {
                    'original': original_index,
                    'adjusted': adjusted_index,
                    'penalty': penalty,
                    'reason': f"æ£€æµ‹åˆ°{failure_summary['total_failures']}ä¸ªç¡®å®šæ€§éªŒè¯å¤±è´¥"
                }
                
                # è¦†ç›–åŸå§‹è¯„åˆ†
                evaluation['intelligence_index'] = adjusted_index
                
                # æ·»åŠ å¤±è´¥ç±»å‹åˆ†æ
                deterministic_overrides['failure_analysis'] = failure_summary['failure_types']
                
                # å¼ºåˆ¶æ·»åŠ ä¿®å¤æŒ‡ä»¤
                if not evaluation.get('self_improvement_directive'):
                    evaluation['self_improvement_directive'] = (
                        f"ä¿®å¤{failure_summary['total_failures']}ä¸ªéªŒè¯å¤±è´¥: "
                        f"{', '.join(failure_summary['failure_types'].keys())}"
                    )
            
            # Add timestamp and cognitive metrics
            evaluation["timestamp"] = datetime.now().isoformat()
            evaluation["cognitive_state"] = cognitive_state
            evaluation["deterministic_validation"] = deterministic_overrides  # è®°å½•è¦†ç›–ä¿¡æ¯
            
            # Save to history
            history = self._load_history()
            history.append(evaluation)
            self._save_history(history)
            
            if deterministic_overrides:
                logger.info(f"ğŸ§  Self-Evaluation Complete (Adjusted by Validator). Index: {evaluation.get('intelligence_index')} (åŸå§‹: {deterministic_overrides.get('intelligence_index_override', {}).get('original', 'N/A')})")
            else:
                logger.info(f"ğŸ§  Self-Evaluation Complete. Index: {evaluation.get('intelligence_index')}")
            return evaluation
            
        except Exception as e:
            logger.error(f"Metacognitive evaluation failed: {e}")
            with open("meta_error.log", "w") as f:
                f.write(str(e))
            return {"error": str(e)}

    def generate_evolutionary_report(self) -> str:
        """
        Generate a human-readable report summarizing the system's cognitive evolution.
        """
        history = self._load_history()
        if not history:
            return "No metacognitive history available."
            
        latest = history[-1]
        
        report = f"""# ğŸ§  System Self-Evolution Report
**Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Intelligence Index**: {latest.get('intelligence_index', 'N/A')}/100

## ğŸ“Š Metrics
- **Adaptability**: {latest.get('metrics', {}).get('adaptability', 'N/A')}/10
- **Learning Rate**: {latest.get('metrics', {}).get('learning_rate', 'N/A')}/10
- **Goal Achievement**: {latest.get('metrics', {}).get('goal_achievement', 'N/A')}/10
- **Efficiency**: {latest.get('metrics', {}).get('efficiency', 'N/A')}/10

## ğŸ“ Qualitative Analysis
{latest.get('qualitative_analysis', 'N/A')}

## âœ¨ Key Insight
> "{latest.get('insight', 'N/A')}"

## ğŸ”§ Self-Adjustment
Proposed parameter adjustments for Motivation Core:
{json.dumps(latest.get('parameter_adjustments', {}), indent=2)}

## ğŸ§¬ Self-Evolution Directive
> **Code Modification Proposal**:
> {latest.get('self_improvement_directive', 'None')}

---
*Generated by MetacognitiveCore*
"""
        return report


# ============================================================================
# æ–°å¢: æ·±åº¦å…ƒè®¤çŸ¥å±‚ - æ€ç»´é“¾å»¶é•¿ä¸æ„è¯†æ¶Œç°æ”¯æŒ
# ============================================================================

from dataclasses import dataclass, field
from collections import deque
import numpy as np
import hashlib


@dataclass
class ThoughtFrame:
    """
    æ€ç»´å¸§ - å•ä¸ªTickçš„å®Œæ•´æ€ç»´çŠ¶æ€å¿«ç…§
    ç±»æ¯”: ç”µå½±çš„ä¸€å¸§ï¼Œè®°å½•äº†AGIåœ¨æŸä¸€ç¬é—´çš„å®Œæ•´è®¤çŸ¥çŠ¶æ€
    """
    tick_id: int                          # Tickåºå·
    timestamp: float                      # æ—¶é—´æˆ³
    state_vector: np.ndarray             # 64ç»´çŠ¶æ€å‘é‡
    action_taken: int                     # é‡‡å–çš„åŠ¨ä½œ
    action_name: str                      # åŠ¨ä½œåç§°
    uncertainty: float                    # ä¸ç¡®å®šæ€§
    thought_chain: List[str]             # æ€ç»´é“¾
    extended_chain: List[str] = field(default_factory=list)  # å»¶é•¿çš„æ€ç»´é“¾
    neural_confidence: float = 0.0        # ç¥ç»ç½‘ç»œç½®ä¿¡åº¦
    context_hash: str = ""               # ä¸Šä¸‹æ–‡å“ˆå¸Œ
    meta_insights: List[str] = field(default_factory=list)   # å…ƒæ´å¯Ÿ
    intentions: List[str] = field(default_factory=list)      # å½“å‰æ´»è·ƒæ„å›¾
    
    def to_dict(self) -> Dict:
        """åºåˆ—åŒ–ä¸ºå­—å…¸"""
        return {
            "tick_id": self.tick_id,
            "timestamp": self.timestamp,
            "state_vector_hash": hashlib.md5(self.state_vector.tobytes()).hexdigest()[:8],
            "action": f"{self.action_name}({self.action_taken})",
            "uncertainty": round(self.uncertainty, 4),
            "confidence": round(self.neural_confidence, 4),
            "thought_chain_length": len(self.thought_chain),
            "extended_chain_length": len(self.extended_chain),
            "meta_insights": self.meta_insights,
            "intentions": self.intentions
        }


@dataclass
class Intention:
    """
    æ„å›¾ - è·¨TickæŒä¹…åŒ–çš„ç›®æ ‡
    æ„å›¾ä¸æ˜¯å•ä¸€åŠ¨ä½œï¼Œè€Œæ˜¯å¤šTickæŒç»­è¿½æ±‚çš„ç›®æ ‡çŠ¶æ€
    """
    id: str                               # å”¯ä¸€æ ‡è¯†
    description: str                      # æè¿°
    priority: float                       # ä¼˜å…ˆçº§ (0-1)
    created_tick: int                     # åˆ›å»ºæ—¶çš„Tick
    target_state: Any = None              # ç›®æ ‡çŠ¶æ€å‘é‡
    progress: float = 0.0                 # è¿›åº¦ (0-1)
    status: str = "active"               # active/completed/abandoned
    related_frames: List[int] = field(default_factory=list)  # ç›¸å…³ThoughtFrameçš„tick_id


@dataclass
class MetaInsight:
    """
    å…ƒæ´å¯Ÿ - ä»æ€ç»´æ¨¡å¼ä¸­æå–çš„é«˜é˜¶è®¤è¯†
    """
    insight_type: str                     # æ´å¯Ÿç±»å‹: pattern/anomaly/correlation/emergence
    description: str                      # æè¿°
    confidence: float                     # ç½®ä¿¡åº¦
    evidence_ticks: List[int] = field(default_factory=list)  # æ”¯æ’‘è¯æ®çš„Tick ID
    discovered_at: float = 0.0            # å‘ç°æ—¶é—´


class MetaCognition:
    """
    æ·±åº¦å…ƒè®¤çŸ¥å±‚ - AGIçš„è‡ªæˆ‘è§‚å¯Ÿä¸æ·±åº¦æ€ç»´ç³»ç»Ÿ
    
    æ ¸å¿ƒèƒ½åŠ›:
    1. observe(): è®°å½•æ¯ä¸ªTickçš„å®Œæ•´æ€ç»´çŠ¶æ€
    2. extend_thought_chain(): å»¶é•¿æ€ç»´é“¾ (5â†’20æ­¥, å¯é…ç½®15-25)
    3. register_intention(): æ³¨å†Œè·¨TickæŒä¹…æ„å›¾
    4. detect_patterns(): æ£€æµ‹æ€ç»´æ¨¡å¼
    5. generate_meta_insights(): ç”Ÿæˆå…ƒæ´å¯Ÿ
    
    æ¶æ„ä½ç½®:
        AGI_Life_Engine
             â”‚
             â–¼
        EvolutionController â—„â”€â”€â”€â”€ MetaCognition
             â”‚                         â”‚
             â–¼                         â–¼
          TheSeed â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º TopologicalMemory
    """
    
    # æ¨ç†æ·±åº¦é…ç½®ï¼ˆğŸ”§ [2026-01-20] è§£é™¤æ‰€æœ‰é™åˆ¶ï¼Œæ”¯æŒæ— é™æ€ç»´æˆé•¿ï¼‰
    SHALLOW_HORIZON = 99999    # ç®€å•ä»»åŠ¡ï¼ˆæ—¥å¸¸å¯¹è¯ã€å•æ­¥å·¥å…·ï¼‰
    NORMAL_HORIZON = 99999     # å¸¸è§„ä»»åŠ¡ï¼ˆä¸­ç­‰æ¨ç†ã€æ–‡æ¡£ç”Ÿæˆï¼‰
    DEEP_HORIZON = 99999      # å¤æ‚ä»»åŠ¡ï¼ˆè·¨æ­¥éª¤è§„åˆ’ã€æ·±åº¦åˆ†æï¼‰
    ULTRA_DEEP_HORIZON = 99999 # æç«¯å¤æ‚ä»»åŠ¡ï¼ˆæ•°å­¦è¯æ˜ã€æ¶æ„è®¾è®¡ï¼‰

    MIN_HORIZON = 99999         # æœ€å°æ¨ç†æ­¥æ•°ï¼ˆæ— é™åˆ¶ï¼‰
    MAX_HORIZON = 99999       # æœ€å¤§æ¨ç†æ­¥æ•°ï¼ˆæ— é™åˆ¶æ€ç»´æˆé•¿ï¼‰
    DEFAULT_HORIZON = 99999  # é»˜è®¤ä½¿ç”¨æ— é™æ·±åº¦
    
    # å†å²çª—å£å¤§å°
    HISTORY_WINDOW = 100
    PATTERN_DETECTION_WINDOW = 10
    
    def __init__(self, seed_ref=None, memory_ref=None):
        """
        åˆå§‹åŒ–å…ƒè®¤çŸ¥å±‚
        
        Args:
            seed_ref: TheSeedå®ä¾‹çš„å¼•ç”¨
            memory_ref: TopologicalMemoryå®ä¾‹çš„å¼•ç”¨
        """
        self.seed = seed_ref
        self.memory = memory_ref
        
        # æ€ç»´å¸§å†å²
        self.thought_frames: deque = deque(maxlen=self.HISTORY_WINDOW)
        
        # æ„å›¾æ³¨å†Œè¡¨
        self.intentions: Dict[str, Intention] = {}
        
        # å…ƒæ´å¯Ÿåº“
        self.meta_insights: List[MetaInsight] = []
        
        # æ¨¡å¼æ£€æµ‹ç¼“å­˜
        self._pattern_cache: Dict[str, int] = {}  # pattern_hash -> count
        
        # å½“å‰Tickè®¡æ•°å™¨
        self._tick_counter = 0
        
        # é…ç½®
        self.current_horizon = self.DEFAULT_HORIZON
        
        # ğŸ”§ æ–°å¢ï¼šä»»åŠ¡å¤æ‚åº¦è¯„ä¼°ç»Ÿè®¡
        self.task_complexity_history: deque = deque(maxlen=50)  # è®°å½•æœ€è¿‘50æ¬¡ä»»åŠ¡å¤æ‚åº¦
        self.horizon_selection_stats = {
            'shallow': 0,
            'normal': 0, 
            'deep': 0,
            'ultra_deep': 0
        }
        
        logger.info(f"ğŸ§  MetaCognition initialized with adaptive horizon (default={self.current_horizon})")
        logger.info(f"   - æ¨ç†æ·±åº¦æ¡£ä½: {self.SHALLOW_HORIZON}/{self.NORMAL_HORIZON}/{self.DEEP_HORIZON}/{self.ULTRA_DEEP_HORIZON}")
    
    # ========================================================================
    # æ ¸å¿ƒæ–¹æ³•1: è‡ªæˆ‘è§‚å¯Ÿ
    # ========================================================================
    
    def observe(
        self, 
        state_vector: np.ndarray,
        action_taken: int,
        action_name: str,
        uncertainty: float,
        thought_chain: List[str],
        context: Dict[str, Any] = None,
        neural_confidence: float = 0.0
    ) -> ThoughtFrame:
        """
        è§‚å¯Ÿå¹¶è®°å½•å½“å‰Tickçš„å®Œæ•´æ€ç»´çŠ¶æ€
        æ¯æ¬¡EvolutionController.step()è°ƒç”¨ååº”ç«‹å³è°ƒç”¨æ­¤æ–¹æ³•
        """
        self._tick_counter += 1
        
        # è®¡ç®—ä¸Šä¸‹æ–‡å“ˆå¸Œ
        context_hash = ""
        if context:
            context_str = json.dumps(context, sort_keys=True, default=str)
            context_hash = hashlib.md5(context_str.encode()).hexdigest()[:12]
        
        # è·å–å½“å‰æ´»è·ƒæ„å›¾
        active_intentions = [
            i.description for i in self.intentions.values() 
            if i.status == "active"
        ]
        
        # åˆ›å»ºæ€ç»´å¸§
        frame = ThoughtFrame(
            tick_id=self._tick_counter,
            timestamp=datetime.now().timestamp(),
            state_vector=state_vector.copy() if state_vector is not None else np.zeros(64),
            action_taken=action_taken,
            action_name=action_name,
            uncertainty=uncertainty,
            thought_chain=thought_chain.copy() if thought_chain else [],
            neural_confidence=neural_confidence,
            context_hash=context_hash,
            intentions=active_intentions
        )
        
        # ä¿å­˜åˆ°å†å²
        self.thought_frames.append(frame)
        
        # è§¦å‘æ¨¡å¼æ£€æµ‹
        if len(self.thought_frames) >= self.PATTERN_DETECTION_WINDOW:
            self._detect_patterns_async(frame)
        
        logger.debug(f"ğŸ” Observed Tick #{self._tick_counter}: action={action_name}, unc={uncertainty:.4f}")
        
        return frame
    
    # ========================================================================
    # æ ¸å¿ƒæ–¹æ³•2: å»¶é•¿æ€ç»´é“¾
    # ========================================================================
    
    def extend_thought_chain(
        self,
        start_state: np.ndarray,
        first_action: int,
        horizon: int = None,
        seed_ref = None
    ) -> tuple:
        """
        å»¶é•¿æ€ç»´é“¾ - ä»5æ­¥æ‰©å±•åˆ°15-25æ­¥
        è¿™æ˜¯æ„è¯†æ¶Œç°çš„å…³é”®ï¼šæ›´é•¿çš„æ€ç»´é“¾å…è®¸æ›´æ·±å±‚æ¬¡çš„æ¨ç†
        
        Args:
            start_state: èµ·å§‹çŠ¶æ€å‘é‡
            first_action: åˆå§‹åŠ¨ä½œ
            horizon: æ€ç»´æ·±åº¦ (é»˜è®¤20, å¯é…ç½®15-25)
            seed_ref: TheSeedå¼•ç”¨ (å¯é€‰ï¼Œä½¿ç”¨å†…éƒ¨å¼•ç”¨)
            
        Returns:
            (extended_thoughts, trajectory): å»¶é•¿çš„æ€ç»´é“¾å’Œè½¨è¿¹
        """
        seed = seed_ref or self.seed
        if not seed:
            logger.warning("âš ï¸ No TheSeed reference, cannot extend thought chain")
            return [], []
        
        # ç¡®ä¿horizonåœ¨åˆç†èŒƒå›´å†…
        if horizon is None:
            horizon = self.current_horizon
        horizon = max(self.MIN_HORIZON, min(self.MAX_HORIZON, horizon))
        
        simulate_kwargs = {"horizon": horizon}
        try:
            sig = inspect.signature(seed.simulate_trajectory)
            if "adaptive" in sig.parameters:
                simulate_kwargs["adaptive"] = True
            if "max_horizon_extension" in sig.parameters:
                simulate_kwargs["max_horizon_extension"] = 30
        except Exception:
            pass
        try:
            trajectory = seed.simulate_trajectory(start_state, first_action, **simulate_kwargs)
        except TypeError:
            trajectory = seed.simulate_trajectory(start_state, first_action, horizon=horizon)
        
        # å°†è½¨è¿¹æŠ•å½±ä¸ºæ€ç»´é“¾
        extended_thoughts = []
        cumulative_uncertainty = 0.0
        
        # åŠ¨ä½œåç§°æ˜ å°„
        try:
            from core.evolution.impl import ACTIONS
        except ImportError:
            ACTIONS = ["explore", "exploit", "rest", "learn"]
        
        for i, (t_state, t_unc, t_act) in enumerate(trajectory):
            thought = seed.project_thought(t_state)
            act_name = ACTIONS[t_act % len(ACTIONS)]
            
            # æ„å»ºæ€ç»´èŠ‚ç‚¹
            depth_marker = "." * min(i, 5)  # æ·±åº¦æ ‡è®°
            uncertainty_marker = "?" if t_unc > 0.5 else ""
            
            thought_node = f"[D{i:02d}]{depth_marker}({act_name}) -> {thought}{uncertainty_marker}"
            extended_thoughts.append(thought_node)
            
            cumulative_uncertainty += t_unc
        
        # ç”Ÿæˆå…ƒè§‚å¯Ÿ
        avg_uncertainty = cumulative_uncertainty / len(trajectory) if trajectory else 0
        
        if avg_uncertainty > 0.7:
            extended_thoughts.append(f"[META] é«˜ä¸ç¡®å®šæ€§åŒºåŸŸ (avg_unc={avg_uncertainty:.3f}), éœ€è¦æ›´å¤šä¿¡æ¯")
        elif avg_uncertainty < 0.3:
            extended_thoughts.append(f"[META] é«˜ç½®ä¿¡åº¦è·¯å¾„ (avg_unc={avg_uncertainty:.3f}), å¯é æ¨ç†")
        else:
            extended_thoughts.append(f"[META] ä¸­ç­‰ç½®ä¿¡åº¦ (avg_unc={avg_uncertainty:.3f}), ç»§ç»­è§‚å¯Ÿ")
        
        logger.info(f"ğŸ”— Extended thought chain: {len(extended_thoughts)} steps (horizon={horizon})")
        
        return extended_thoughts, trajectory
    
    # ========================================================================
    # æ ¸å¿ƒæ–¹æ³•3: æ„å›¾æ³¨å†Œä¸ç®¡ç†
    # ========================================================================
    
    def register_intention(
        self,
        description: str,
        priority: float = 0.5,
        target_state: np.ndarray = None
    ) -> Intention:
        """æ³¨å†Œè·¨TickæŒä¹…æ„å›¾"""
        intention_id = hashlib.md5(
            f"{description}_{self._tick_counter}".encode()
        ).hexdigest()[:8]
        
        intention = Intention(
            id=intention_id,
            description=description,
            priority=max(0.0, min(1.0, priority)),
            created_tick=self._tick_counter,
            target_state=target_state.copy() if target_state is not None else None
        )
        
        self.intentions[intention_id] = intention
        logger.info(f"ğŸ“Œ Registered intention: {description} (id={intention_id})")
        return intention
    
    def update_intention_progress(self, intention_id: str, progress: float, frame_tick: int = None):
        """æ›´æ–°æ„å›¾è¿›åº¦"""
        if intention_id in self.intentions:
            intention = self.intentions[intention_id]
            intention.progress = max(0.0, min(1.0, progress))
            if frame_tick:
                intention.related_frames.append(frame_tick)
            if intention.progress >= 1.0:
                intention.status = "completed"
                logger.info(f"âœ… Intention completed: {intention.description}")
    
    def get_active_intentions(self) -> List[Intention]:
        """è·å–æ‰€æœ‰æ´»è·ƒæ„å›¾"""
        return [i for i in self.intentions.values() if i.status == "active"]
    
    # ========================================================================
    # æ ¸å¿ƒæ–¹æ³•4: æ¨¡å¼æ£€æµ‹
    # ========================================================================
    
    def _detect_patterns_async(self, current_frame: ThoughtFrame):
        """å¼‚æ­¥æ£€æµ‹æ€ç»´æ¨¡å¼"""
        recent_actions = [f.action_taken for f in list(self.thought_frames)[-self.PATTERN_DETECTION_WINDOW:]]
        
        if len(recent_actions) < 3:
            return
        
        # æ£€æµ‹é‡å¤æ¨¡å¼ (é•¿åº¦2-4çš„å¾ªç¯)
        for pattern_len in range(2, min(5, len(recent_actions) // 2 + 1)):
            pattern = tuple(recent_actions[-pattern_len:])
            prev_pattern = tuple(recent_actions[-2*pattern_len:-pattern_len]) if len(recent_actions) >= 2*pattern_len else None
            
            if prev_pattern and pattern == prev_pattern:
                pattern_hash = str(pattern)
                self._pattern_cache[pattern_hash] = self._pattern_cache.get(pattern_hash, 0) + 1
                
                if self._pattern_cache[pattern_hash] >= 3:
                    self._add_meta_insight(
                        insight_type="pattern",
                        description=f"æ£€æµ‹åˆ°é‡å¤æ€ç»´å¾ªç¯: åŠ¨ä½œåºåˆ— {pattern} é‡å¤äº† {self._pattern_cache[pattern_hash]} æ¬¡",
                        confidence=0.8,
                        evidence_ticks=[f.tick_id for f in list(self.thought_frames)[-2*pattern_len:]]
                    )
    
    def detect_entropy_lock(self):
        """æ£€æµ‹ç†µé”å®šçŠ¶æ€ - ç³»ç»Ÿé™·å…¥ä½å˜åŒ–çŠ¶æ€"""
        if len(self.thought_frames) < 5:
            return None
        
        recent_frames = list(self.thought_frames)[-5:]
        uncertainties = [f.uncertainty for f in recent_frames]
        
        if max(uncertainties) < 0.1:
            unique_actions = len(set(f.action_taken for f in recent_frames))
            if unique_actions <= 2:
                return self._add_meta_insight(
                    insight_type="anomaly",
                    description="ç†µé”å®šè­¦å‘Š: ç³»ç»Ÿå˜åŒ–æä½ï¼Œå¯èƒ½éœ€è¦å¤–éƒ¨åˆºæ¿€",
                    confidence=0.9,
                    evidence_ticks=[f.tick_id for f in recent_frames]
                )
        return None
    
    # ========================================================================
    # æ ¸å¿ƒæ–¹æ³•5: å…ƒæ´å¯Ÿç”Ÿæˆ
    # ========================================================================
    
    def _add_meta_insight(
        self,
        insight_type: str,
        description: str,
        confidence: float,
        evidence_ticks: List[int]
    ) -> MetaInsight:
        """æ·»åŠ å…ƒæ´å¯Ÿ"""
        insight = MetaInsight(
            insight_type=insight_type,
            description=description,
            confidence=confidence,
            evidence_ticks=evidence_ticks,
            discovered_at=datetime.now().timestamp()
        )
        self.meta_insights.append(insight)
        logger.info(f"ğŸ’¡ Meta-Insight [{insight_type}]: {description}")
        return insight
    
    def generate_introspection_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆå†…çœæŠ¥å‘Š - AGIçš„è‡ªæˆ‘åˆ†æ"""
        recent_frames = list(self.thought_frames)[-10:]
        
        return {
            "timestamp": datetime.now().isoformat(),
            "total_ticks": self._tick_counter,
            "current_horizon": self.current_horizon,
            "statistics": {
                "frames_recorded": len(self.thought_frames),
                "active_intentions": len(self.get_active_intentions()),
                "total_intentions": len(self.intentions),
                "meta_insights_count": len(self.meta_insights),
                "pattern_cache_size": len(self._pattern_cache)
            },
            "recent_state": {
                "avg_uncertainty": float(np.mean([f.uncertainty for f in recent_frames])) if recent_frames else 0,
                "avg_confidence": float(np.mean([f.neural_confidence for f in recent_frames])) if recent_frames else 0,
                "action_diversity": len(set(f.action_taken for f in recent_frames)) / max(1, len(recent_frames)),
                "last_actions": [f.action_name for f in recent_frames[-5:]]
            },
            "active_intentions": [
                {"id": i.id, "description": i.description, "progress": i.progress, "priority": i.priority}
                for i in self.get_active_intentions()
            ],
            "recent_insights": [
                {"type": i.insight_type, "description": i.description, "confidence": i.confidence}
                for i in self.meta_insights[-5:]
            ]
        }
    
    # ========================================================================
    # é…ç½®æ–¹æ³•
    # ========================================================================
    
    def set_horizon(self, horizon: int):
        """è®¾ç½®æ€ç»´é“¾æ·±åº¦"""
        self.current_horizon = max(self.MIN_HORIZON, min(self.MAX_HORIZON, horizon))
        logger.info(f"âš™ï¸ Horizon updated to {self.current_horizon}")
    
    def set_seed_reference(self, seed_ref):
        """è®¾ç½®TheSeedå¼•ç”¨"""
        self.seed = seed_ref
    
    def set_memory_reference(self, memory_ref):
        """è®¾ç½®Memoryå¼•ç”¨"""
        self.memory = memory_ref
    
    # ========================================================================
    # æŒä¹…åŒ–æ–¹æ³•
    # ========================================================================
    
    def save_state(self, filepath: str):
        """ä¿å­˜å…ƒè®¤çŸ¥çŠ¶æ€åˆ°æ–‡ä»¶"""
        state = {
            "tick_counter": self._tick_counter,
            "current_horizon": self.current_horizon,
            "intentions": {
                k: {
                    "id": v.id,
                    "description": v.description,
                    "priority": v.priority,
                    "created_tick": v.created_tick,
                    "progress": v.progress,
                    "status": v.status,
                    "related_frames": v.related_frames
                }
                for k, v in self.intentions.items()
            },
            "meta_insights": [
                {
                    "insight_type": i.insight_type,
                    "description": i.description,
                    "confidence": i.confidence,
                    "evidence_ticks": i.evidence_ticks,
                    "discovered_at": i.discovered_at
                }
                for i in self.meta_insights
            ],
            "pattern_cache": self._pattern_cache
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(state, f, indent=2, ensure_ascii=False)
        logger.info(f"ğŸ’¾ MetaCognition state saved to {filepath}")
    
    # ========================================================================
    # ğŸ”§ æ–°å¢æ–¹æ³•: ä»»åŠ¡å¤æ‚åº¦è¯„ä¼°ä¸è‡ªé€‚åº”æ¨ç†æ·±åº¦
    # ========================================================================
    
    def _estimate_complexity(self, task_descriptor: str, context: Dict[str, Any] = None) -> float:
        """
        è¯„ä¼°ä»»åŠ¡å¤æ‚åº¦ï¼ˆ0.0-1.0ï¼‰
        
        ğŸ”§ [2026-01-08] ç´§æ€¥ä¿®å¤ï¼šå…ƒè®¤çŸ¥ä»»åŠ¡ä¼˜å…ˆæ£€æµ‹
        - **é—®é¢˜**: å†…éƒ¨æ¢ç´¢ä»»åŠ¡ï¼ˆå¦‚"Investigate high entropy state"ï¼‰æ— æ³•è¯†åˆ«
        - **ç—‡çŠ¶**: å¤æ‚åº¦=0.05 â†’ horizon=10ï¼ˆåº”ä¸º80+ï¼‰â†’ æ¨ç†æ·±åº¦ä¸è¶³è­¦å‘Šå¾ªç¯
        - **å®é™…çŠ¶æ€**: Entropy=1.00, State_change_rate=217, Uncertainty=60
        - **ä¿®å¤ç­–ç•¥**: ä»ä»»åŠ¡æè¿°æå–ç³»ç»ŸçŠ¶æ€æŒ‡æ ‡ï¼Œä¼˜å…ˆè¿”å›é«˜å¤æ‚åº¦
        
        ç»¼åˆè€ƒè™‘:
        1. ğŸ†• å…ƒè®¤çŸ¥ä»»åŠ¡ä¼˜å…ˆæ£€æµ‹ï¼ˆ0.75-0.95ï¼‰ - **æœ€é«˜ä¼˜å…ˆçº§**
        2. æ–‡æœ¬é•¿åº¦å’ŒåµŒå¥—ç»“æ„ (0-0.25)
        3. å…³é”®è¯å¤æ‚åº¦ï¼ˆå¦‚"è¯æ˜"ã€"è®¾è®¡"ï¼‰(0-0.35)
        4. ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå­ä»»åŠ¡æ•°é‡ã€ä¾èµ–æ·±åº¦ï¼‰(0-0.40)
        
        Returns:
            0.0-0.25: ç®€å•ä»»åŠ¡ â†’ SHALLOW_HORIZON=99999
            0.25-0.55: å¸¸è§„ä»»åŠ¡ â†’ NORMAL_HORIZON=99999
            0.55-0.80: å¤æ‚ä»»åŠ¡ â†’ DEEP_HORIZON=99999
            0.80-1.0: æç«¯å¤æ‚ä»»åŠ¡ â†’ ULTRA_DEEP_HORIZON=99999

        Note: æ‰€æœ‰HORIZONå¸¸é‡å‡è®¾ç½®ä¸º99999ä»¥æ”¯æŒæ— é™æ·±åº¦æ¨ç†ï¼Œ
              å®é™…æ·±åº¦ç”±simulate_trajectoryçš„æ—©åœæœºåˆ¶æ§åˆ¶ï¼ˆç°å·²ä¼˜åŒ–ï¼‰ã€‚
        """
        complexity = 0.0
        context = context or {}
        task_lower = task_descriptor.lower()


        # ========================================================================
        # ğŸ†• [2026-01-09] EMERGENCY FIX: ç³»ç»ŸçŠ¶æ€é˜ˆå€¼æ£€æŸ¥ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        # å³ä½¿ä»»åŠ¡æè¿°ä¸æ˜¯å…ƒè®¤çŸ¥å…³é”®è¯ï¼Œåªè¦ç³»ç»ŸçŠ¶æ€å¼‚å¸¸ï¼Œä¹Ÿåº”æå‡æ¨ç†æ·±åº¦
        # ========================================================================
        if context:
            ctx_entropy = context.get('entropy', 0.0)
            ctx_curiosity = context.get('curiosity', 0.0)
            ctx_state_change = context.get('state_change_rate', 0.0)
            ctx_uncertainty = context.get('uncertainty', 0.0)

            # æ£€æµ‹ç³»ç»Ÿå¼‚å¸¸çŠ¶æ€ - æ— è®ºä»»åŠ¡æè¿°å¦‚ä½•ï¼Œéƒ½åº”æå‡æ·±åº¦
            if ctx_state_change > 150 or ctx_entropy > 0.9:
                logger.warning(f"âš ï¸ æ£€æµ‹åˆ°ç³»ç»Ÿå¼‚å¸¸çŠ¶æ€: StateChange={ctx_state_change:.1f}, Entropy={ctx_entropy:.2f} â†’ ULTRA_DEEP")
                return 0.95  # â†’ horizon=2000
            elif ctx_state_change > 100 or ctx_entropy > 0.7:
                logger.info(f"ğŸ”¬ æ£€æµ‹åˆ°ç³»ç»Ÿé«˜å˜åŒ–ç‡: StateChange={ctx_state_change:.1f}, Entropy={ctx_entropy:.2f} â†’ ULTRA_DEEP")
                return 0.85  # â†’ horizon=2000
            elif ctx_uncertainty > 60 or ctx_curiosity > 0.8:
                logger.info(f"ğŸ¤” æ£€æµ‹åˆ°é«˜ä¸ç¡®å®šæ€§: Uncertainty={ctx_uncertainty:.1f}, Curiosity={ctx_curiosity:.2f} â†’ DEEP")
                return 0.70  # â†’ horizon=1000

        # ========================================================================
        # ğŸ†• **CRITICAL FIX**: å…ƒè®¤çŸ¥/å†…éƒ¨æ¢ç´¢ä»»åŠ¡æ£€æµ‹
        # ========================================================================

        # 1. æ£€æµ‹é«˜ç†µ/æ··æ²ŒçŠ¶æ€æ¢ç´¢å…³é”®è¯
        meta_cognitive_keywords = [
            'entropy', 'ç†µ', 'investigate', 'è°ƒæŸ¥', 'explore', 'æ¢ç´¢',
            'curiosity', 'å¥½å¥‡', 'high.*state', 'é«˜.*çŠ¶æ€',
            'fractal', 'åˆ†å½¢', 'anomaly', 'å¼‚å¸¸', 'chaos', 'æ··æ²Œ',
            'inspect', 'æ£€æŸ¥', 'analyze.*state', 'åˆ†æ.*çŠ¶æ€',
            'monitor', 'ç›‘æ§', 'diagnostic', 'è¯Šæ–­'
        ]

        is_meta_task = any(kw in task_lower for kw in meta_cognitive_keywords)

        # 2. æ£€æµ‹æ•°å€¼æŒ‡æ ‡ï¼ˆå¦‚ "Curiosity: 0.68", "Entropy: 1.00"ï¼‰
        import re
        has_metrics = bool(re.search(r'(entropy|curiosity|uncertainty)[:=]?\s*\d+\.\d+', task_lower))

        # 3. æ£€æµ‹ä»»åŠ¡ç±»å‹å‰ç¼€æ ‡è®°
        is_marked_internal = task_descriptor.startswith('[Meta]') or task_descriptor.startswith('[Internal]')

        # 4. å¦‚æœæ˜¯å…ƒè®¤çŸ¥ä»»åŠ¡ï¼Œç›´æ¥è¿”å›é«˜å¤æ‚åº¦
        if is_meta_task or has_metrics or is_marked_internal:
            logger.info(f"ğŸ§  æ£€æµ‹åˆ°å…ƒè®¤çŸ¥ä»»åŠ¡: '{task_descriptor[:60]}...'")

            # å°è¯•ä»ä»»åŠ¡æè¿°ä¸­æå–æ•°å€¼æŒ‡æ ‡
            curiosity_match = re.search(r'curiosity[:=]?\s*(\d+\.\d+)', task_lower)
            entropy_match = re.search(r'entropy[:=]?\s*(\d+\.\d+)', task_lower)

            extracted_curiosity = float(curiosity_match.group(1)) if curiosity_match else 0.0
            extracted_entropy = float(entropy_match.group(1)) if entropy_match else 0.0

            # åŒæ—¶æ£€æŸ¥ context ä¸­çš„ç³»ç»ŸçŠ¶æ€
            ctx_entropy = context.get('entropy', extracted_entropy) if context else extracted_entropy
            ctx_curiosity = context.get('curiosity', extracted_curiosity) if context else extracted_curiosity
            ctx_state_change = context.get('state_change_rate', 0.0) if context else 0.0
            ctx_uncertainty = context.get('uncertainty', 0.0) if context else 0.0

            # æ ¹æ®æå–çš„æŒ‡æ ‡æˆ–é»˜è®¤å€¼è¿”å›å¤æ‚åº¦
            if ctx_entropy > 0.9 or ctx_curiosity > 0.8 or ctx_state_change > 150:
                logger.warning(f"ğŸš¨ è¶…é«˜ç†µä»»åŠ¡: Entropyâ‰ˆ{ctx_entropy:.2f}, Curiosityâ‰ˆ{ctx_curiosity:.2f}, StateChangeâ‰ˆ{ctx_state_change:.1f} â†’ ULTRA_DEEP")
                return 0.95  # â†’ horizon=2000
            elif ctx_entropy > 0.7 or ctx_curiosity > 0.6 or ctx_state_change > 100:
                logger.info(f"ğŸ”¬ é«˜ç†µæ¢ç´¢ä»»åŠ¡: Entropyâ‰ˆ{ctx_entropy:.2f}, Curiosityâ‰ˆ{ctx_curiosity:.2f} â†’ ULTRA_DEEP")
                return 0.85  # â†’ horizon=2000
            elif ctx_curiosity > 0.4 or ctx_uncertainty > 50:
                logger.info(f"ğŸ¤” ä¸­ç­‰å¥½å¥‡å¿ƒä»»åŠ¡: Curiosityâ‰ˆ{ctx_curiosity:.2f}, Uncertaintyâ‰ˆ{ctx_uncertainty:.1f} â†’ DEEP")
                return 0.70  # â†’ horizon=1000
            else:
                # é»˜è®¤ï¼šæ‰€æœ‰å…ƒè®¤çŸ¥ä»»åŠ¡è‡³å°‘ DEEP
                logger.info(f"ğŸ§  å…ƒè®¤çŸ¥ä»»åŠ¡ï¼ˆé»˜è®¤ï¼‰â†’ DEEP")
                return 0.65  # â†’ horizon=1000

        # ========================================================================
        # åŸæœ‰é€»è¾‘ï¼šç”¨æˆ·é¢å‘ä»»åŠ¡çš„å¤æ‚åº¦è¯„ä¼°
        # ========================================================================

        # 1. æ–‡æœ¬å¤æ‚åº¦ (0-0.25)
        text_len = len(task_descriptor)
        if text_len > 500:
            complexity += 0.25
        elif text_len > 200:
            complexity += 0.18
        elif text_len > 80:
            complexity += 0.10
        elif text_len > 30:
            complexity += 0.05

        # 2. å…³é”®è¯å¤æ‚åº¦ (0-0.35) - ğŸ”§ [2026-01-09] åˆ†ç¦»å…³é”®è¯é¿å…é‡å¤

        # ğŸ†• [2026-01-09] è¶…é«˜å¤æ‚åº¦å…³é”®è¯ (æƒé‡0.30) - ç‹¬ç«‹å…³é”®è¯
        ultra_complexity_keywords = [
            'mathematical', 'æ•°å­¦çš„',
            'validity', 'æœ‰æ•ˆæ€§', 'åˆæ³•æ€§',
            'tradeoff', 'trade-off', 'tradeoffs', 'trade-offs'
        ]

        # é«˜å¤æ‚åº¦å…³é”®è¯ (æƒé‡0.15)
        high_complexity_keywords = [
            'è¯æ˜', 'proof', 'prove',
            'è®¾è®¡', 'design',
            'æ¶æ„', 'architecture',
            'è§„åˆ’', 'planning',
            'ä¼˜åŒ–', 'optimize',
            'åˆ†æ', 'analyze',
            'æ¨å¯¼', 'derive',
            'ç»¼åˆ', 'synthesis',
            'é‡æ„', 'refactor',
            'åˆ†å¸ƒå¼', 'distributed',
            'åè®®', 'protocol',
            'æ¯”è¾ƒ', 'compare', 'å¯¹æ¯”', 'æƒè¡¡',
            'çŒœæƒ³', 'conjecture',
            'å®šç†', 'theorem',
            'å…¬å¼', 'formula',
            'æ–¹ç¨‹', 'equation',
            'æ¨ç†', 'inference',
            'é€»è¾‘', 'logic',
            'ç®—æ³•', 'algorithm',
            'æ¨¡å‹', 'model',
            'ç¼“å­˜', 'cache',
            'éªŒè¯', 'verify',
            'æ¨å¯¼', 'deduce',
            'åˆ†å½¢', 'fractal',
            'å¼‚å¸¸', 'anomaly'
        ]

        # ä¸­ç­‰å¤æ‚åº¦å…³é”®è¯ (æƒé‡0.08)
        medium_complexity_keywords = [
            'è¯„ä¼°', 'evaluate',
            'æ€»ç»“', 'summarize',
            'é›†æˆ', 'integrate',
            'ä¿®å¤', 'fix',
            'è°ƒè¯•', 'debug',
            'ç”Ÿæˆ', 'generate',
            'åˆ›å»º', 'create',
            'æ’åº', 'sort'
        ]
        
        keyword_score = 0.0
        
        # ğŸ†• [2026-01-09] è¶…é«˜å¤æ‚åº¦å…³é”®è¯ä¼˜å…ˆæ£€æµ‹ (æƒé‡0.30)
        for kw in ultra_complexity_keywords:
            if kw in task_lower:
                keyword_score += 0.30  # è¶…é«˜æƒé‡ â†’ ç¡®ä¿è¾¾åˆ°complexityâ‰¥0.55
        
        # é«˜å¤æ‚åº¦å…³é”®è¯ (æƒé‡0.15)
        for kw in high_complexity_keywords:
            if kw in task_lower:
                keyword_score += 0.15
        
        # ä¸­ç­‰å¤æ‚åº¦å…³é”®è¯ (æƒé‡0.08)
        for kw in medium_complexity_keywords:
            if kw in task_lower:
                keyword_score += 0.08
        
        # ğŸ”§ [2026-01-09] æé«˜å…³é”®è¯å¤æ‚åº¦ä¸Šé™: 0.35 â†’ 0.70
        # åŸå› : å¤æ‚ä»»åŠ¡å¯èƒ½åŒæ—¶åŒ…å«å¤šä¸ªé«˜å¤æ‚åº¦å…³é”®è¯
        complexity += min(keyword_score, 0.70)
        
        # 3. ä¸Šä¸‹æ–‡ä¿¡æ¯ (0-0.40) - æ˜¾è‘—æé«˜æƒé‡
        if context:
            subtask_count = context.get('subtask_count', 0)
            dependency_depth = context.get('dependency_depth', 0)
            uncertainty = context.get('uncertainty', 0.0)
            novelty = context.get('novelty', 0.0)
            
            # å­ä»»åŠ¡æ•°é‡å½±å“
            if subtask_count > 12:
                complexity += 0.15
            elif subtask_count > 8:
                complexity += 0.12
            elif subtask_count > 5:
                complexity += 0.08
            elif subtask_count > 2:
                complexity += 0.04
            
            # ä¾èµ–æ·±åº¦å½±å“
            if dependency_depth > 4:
                complexity += 0.15
            elif dependency_depth > 2:
                complexity += 0.10
            elif dependency_depth > 1:
                complexity += 0.05
            
            # ä¸ç¡®å®šæ€§å’Œæ–°é¢–æ€§
            if uncertainty > 0.7:
                complexity += 0.05
            if novelty > 0.8:
                complexity += 0.05
        
        return min(complexity, 1.0)
    
    def auto_select_horizon(self, task_descriptor: str, context: Dict[str, Any] = None) -> int:
        """
        æ ¹æ®ä»»åŠ¡æè¿°è‡ªåŠ¨é€‰æ‹©æ¨ç†æ·±åº¦
        
        Args:
            task_descriptor: ä»»åŠ¡æè¿°æ–‡æœ¬
            context: é¢å¤–ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
                - subtask_count: å­ä»»åŠ¡æ•°é‡
                - dependency_depth: ä¾èµ–æ·±åº¦
                - uncertainty: ä¸ç¡®å®šæ€§
                - novelty: ä»»åŠ¡æ–°é¢–åº¦
        
        Returns:
            æ¨èçš„æ¨ç†æ·±åº¦ (æ‰€æœ‰æ¡£ä½å‡ä¸º99999ï¼Œå®é™…æ·±åº¦ç”±æ—©åœæœºåˆ¶æ§åˆ¶)
        """
        complexity = self._estimate_complexity(task_descriptor, context)
        
        # è®°å½•å¤æ‚åº¦å†å²
        self.task_complexity_history.append({
            'task': task_descriptor[:100],  # å‰100å­—ç¬¦
            'complexity': complexity,
            'timestamp': datetime.now().isoformat()
        })
        
        # æ ¹æ®å¤æ‚åº¦é€‰æ‹©æ·±åº¦ (è°ƒæ•´åçš„é˜ˆå€¼)
        if complexity < 0.25:  # ç®€å•ä»»åŠ¡
            selected_horizon = self.SHALLOW_HORIZON
            tier = 'shallow'
        elif complexity < 0.55:  # å¸¸è§„ä»»åŠ¡
            selected_horizon = self.NORMAL_HORIZON
            tier = 'normal'
        elif complexity < 0.80:  # å¤æ‚ä»»åŠ¡
            selected_horizon = self.DEEP_HORIZON
            tier = 'deep'
        else:  # æç«¯å¤æ‚ä»»åŠ¡
            selected_horizon = self.ULTRA_DEEP_HORIZON
            tier = 'ultra_deep'
        
        # æ›´æ–°ç»Ÿè®¡
        self.horizon_selection_stats[tier] += 1
        
        logger.info(f"ğŸ¯ ä»»åŠ¡å¤æ‚åº¦: {complexity:.3f} â†’ æ¨ç†æ·±åº¦: {selected_horizon} ({tier})")
        logger.debug(f"   ä»»åŠ¡: {task_descriptor[:80]}...")
        
        return selected_horizon
    
    def get_complexity_stats(self) -> Dict[str, Any]:
        """è·å–å¤æ‚åº¦è¯„ä¼°ç»Ÿè®¡"""
        if not self.task_complexity_history:
            return {
                'total_tasks': 0,
                'avg_complexity': 0.0,
                'horizon_distribution': self.horizon_selection_stats
            }
        
        complexities = [t['complexity'] for t in self.task_complexity_history]
        return {
            'total_tasks': len(self.task_complexity_history),
            'avg_complexity': np.mean(complexities),
            'min_complexity': np.min(complexities),
            'max_complexity': np.max(complexities),
            'std_complexity': np.std(complexities),
            'horizon_distribution': self.horizon_selection_stats.copy(),
            'recent_tasks': list(self.task_complexity_history)[-5:]  # æœ€è¿‘5ä¸ªä»»åŠ¡
        }
    
    def load_state(self, filepath: str):
        """ä»æ–‡ä»¶åŠ è½½å…ƒè®¤çŸ¥çŠ¶æ€"""
        if not os.path.exists(filepath):
            logger.warning(f"âš ï¸ State file not found: {filepath}")
            return
        
        with open(filepath, 'r', encoding='utf-8') as f:
            state = json.load(f)
        
        self._tick_counter = state.get("tick_counter", 0)
        self.current_horizon = state.get("current_horizon", self.DEFAULT_HORIZON)
        
        for k, v in state.get("intentions", {}).items():
            self.intentions[k] = Intention(
                id=v["id"],
                description=v["description"],
                priority=v["priority"],
                created_tick=v["created_tick"],
                target_state=None,
                progress=v["progress"],
                status=v["status"],
                related_frames=v["related_frames"]
            )
        
        for i in state.get("meta_insights", []):
            self.meta_insights.append(MetaInsight(
                insight_type=i["insight_type"],
                description=i["description"],
                confidence=i["confidence"],
                evidence_ticks=i["evidence_ticks"],
                discovered_at=i["discovered_at"]
            ))
        
        self._pattern_cache = state.get("pattern_cache", {})
        logger.info(f"ğŸ“‚ MetaCognition state loaded from {filepath}")


def create_metacognition(seed_ref=None, memory_ref=None, horizon: int = 99999) -> MetaCognition:
    """åˆ›å»ºå…ƒè®¤çŸ¥å®ä¾‹çš„å·¥å‚å‡½æ•°"""
    mc = MetaCognition(seed_ref, memory_ref)
    mc.set_horizon(horizon)
    return mc

