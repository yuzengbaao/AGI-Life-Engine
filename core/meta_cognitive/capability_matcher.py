#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
èƒ½åŠ›åŒ¹é…åˆ†æå™¨ (Capability Matcher)
======================================

å…ƒè®¤çŸ¥å±‚ç¬¬äºŒç»„ä»¶ï¼šè¯„ä¼°ç³»ç»Ÿèƒ½åŠ›ä¸ä»»åŠ¡çš„åŒ¹é…ç¨‹åº¦

åŠŸèƒ½ï¼š
- èƒ½åŠ›ä¸ä»»åŠ¡åŒ¹é…åˆ†æï¼ˆæˆ‘èƒ½è§£å†³è¿™ä¸ªé—®é¢˜å—ï¼Ÿï¼‰
- èƒ½åŠ›è¾¹ç•Œæ£€æµ‹ï¼ˆæˆ‘çš„å±€é™åœ¨å“ªé‡Œï¼Ÿï¼‰
- ç¼ºå¤±èƒ½åŠ›è¯†åˆ«ï¼ˆæˆ‘ç¼ºå°‘ä»€ä¹ˆèƒ½åŠ›ï¼Ÿï¼‰
- èƒ½åŠ›ç›¸ä¼¼åº¦æœç´¢ï¼ˆæˆ‘æœ‰ç±»ä¼¼çš„èƒ½åŠ›å—ï¼Ÿï¼‰

Version: 1.0.0
Author: AGI Evolution Team
Date: 2026-01-16
"""

import re
import json
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum


class MatchLevel(Enum):
    """åŒ¹é…ç¨‹åº¦"""
    PERFECT = "perfect"      # å®Œç¾åŒ¹é…ï¼ˆç›´æ¥æœ‰å¯¹åº”èƒ½åŠ›ï¼‰
    GOOD = "good"           # è‰¯å¥½åŒ¹é…ï¼ˆæœ‰ç›¸ä¼¼èƒ½åŠ›ï¼‰
    PARTIAL = "partial"     # éƒ¨åˆ†åŒ¹é…ï¼ˆéœ€è¦ç»„åˆèƒ½åŠ›ï¼‰
    POOR = "poor"          # åŒ¹é…åº¦ä½ï¼ˆå‹‰å¼ºèƒ½åšï¼‰
    NONE = "none"          # æ— åŒ¹é…ï¼ˆæ— æ³•å®Œæˆï¼‰


@dataclass
class CapabilityProfile:
    """èƒ½åŠ›ç”»åƒ"""
    name: str
    category: str  # cognitive, tool, domain, knowledge
    strength: float  # 0.0-1.0
    versatility: float  # 0.0-1.0 (é€šç”¨æ€§)
    dependencies: List[str] = field(default_factory=list)
    limitations: List[str] = field(default_factory=list)
    use_cases: List[str] = field(default_factory=list)


@dataclass
class MatchResult:
    """åŒ¹é…ç»“æœ"""
    task: str
    match_level: MatchLevel
    matching_capabilities: List[str] = field(default_factory=list)
    missing_capabilities: List[str] = field(default_factory=list)
    capability_gaps: List[str] = field(default_factory=list)
    suggested_alternatives: List[str] = field(default_factory=list)
    confidence: float = 0.0
    workarounds: List[str] = field(default_factory=list)


class CapabilityMatcher:
    """
    èƒ½åŠ›åŒ¹é…åˆ†æå™¨

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. ç»´æŠ¤ç³»ç»Ÿèƒ½åŠ›æ³¨å†Œè¡¨
    2. åˆ†æä»»åŠ¡éœ€æ±‚ä¸ç³»ç»Ÿèƒ½åŠ›çš„åŒ¹é…åº¦
    3. è¯†åˆ«èƒ½åŠ›è¾¹ç•Œ
    4. æä¾›æ›¿ä»£æ–¹æ¡ˆå’Œå·¥ä½œå»ºè®®
    """

    def __init__(self):
        """åˆå§‹åŒ–èƒ½åŠ›åŒ¹é…å™¨"""
        # ç³»ç»Ÿèƒ½åŠ›æ³¨å†Œè¡¨
        self.capabilities = self._initialize_capabilities()

        # èƒ½åŠ›ä¾èµ–å…³ç³»
        self.dependency_graph = self._build_dependency_graph()

        # èƒ½åŠ›ç›¸ä¼¼åº¦çŸ©é˜µ
        self.similarity_matrix = self._build_similarity_matrix()

    def _initialize_capabilities(self) -> Dict[str, CapabilityProfile]:
        """åˆå§‹åŒ–ç³»ç»Ÿèƒ½åŠ›æ³¨å†Œè¡¨"""
        return {
            # è®¤çŸ¥èƒ½åŠ›
            "text_understanding": CapabilityProfile(
                name="æ–‡æœ¬ç†è§£",
                category="cognitive",
                strength=0.9,
                versatility=0.95,
                use_cases=["æ–‡æ¡£é˜…è¯»", "ä¿¡æ¯æå–", "æ–‡æœ¬åˆ†æ"]
            ),
            "code_analysis": CapabilityProfile(
                name="ä»£ç åˆ†æ",
                category="cognitive",
                strength=0.85,
                versatility=0.8,
                dependencies=["text_understanding"],
                use_cases=["ä»£ç å®¡æŸ¥", "bugåˆ†æ", "é‡æ„å»ºè®®"]
            ),
            "logical_reasoning": CapabilityProfile(
                name="é€»è¾‘æ¨ç†",
                category="cognitive",
                strength=0.75,
                versatility=0.85,
                use_cases=["ä»»åŠ¡è§„åˆ’", "é—®é¢˜åˆ†è§£", "å› æœæ¨ç†"]
            ),
            "pattern_recognition": CapabilityProfile(
                name="æ¨¡å¼è¯†åˆ«",
                category="cognitive",
                strength=0.8,
                versatility=0.9,
                use_cases=["æ•°æ®åˆ†æ", "å¼‚å¸¸æ£€æµ‹", "åˆ†ç±»"]
            ),

            # å·¥å…·èƒ½åŠ›
            "file_operations": CapabilityProfile(
                name="æ–‡ä»¶æ“ä½œ",
                category="tool",
                strength=0.95,
                versatility=0.7,
                use_cases=["è¯»å†™æ–‡ä»¶", "ç›®å½•éå†", "è·¯å¾„æ“ä½œ"]
            ),
            "web_search": CapabilityProfile(
                name="ç½‘ç»œæœç´¢",
                category="tool",
                strength=0.9,
                versatility=0.85,
                dependencies=["text_understanding"],
                use_cases=["ä¿¡æ¯æ£€ç´¢", "èµ„æ–™æ”¶é›†", "å®æ—¶æŸ¥è¯¢"]
            ),
            "command_execution": CapabilityProfile(
                name="å‘½ä»¤æ‰§è¡Œ",
                category="tool",
                strength=0.9,
                versatility=0.8,
                use_cases=["è¿è¡Œè„šæœ¬", "ç³»ç»Ÿè°ƒç”¨", "å·¥å…·é“¾æ“ä½œ"]
            ),
            "code_execution": CapabilityProfile(
                name="ä»£ç æ‰§è¡Œ",
                category="tool",
                strength=0.85,
                versatility=0.75,
                dependencies=["command_execution"],
                limitations=["æ²™ç®±é™åˆ¶", "æ— ç½‘ç»œè®¿é—®"],
                use_cases=["Pythonä»£ç ", "æ•°æ®å¤„ç†", "ç®—æ³•éªŒè¯"]
            ),

            # é¢†åŸŸçŸ¥è¯†
            "mathematics": CapabilityProfile(
                name="æ•°å­¦çŸ¥è¯†",
                category="knowledge",
                strength=0.7,
                versatility=0.9,
                use_cases=["åŸºç¡€è®¡ç®—", "ç»Ÿè®¡åˆ†æ", "ç®€å•ä¼˜åŒ–"]
            ),
            "programming": CapabilityProfile(
                name="ç¼–ç¨‹çŸ¥è¯†",
                category="knowledge",
                strength=0.9,
                versatility=0.95,
                use_cases=["å¤šè¯­è¨€å¼€å‘", "æ¶æ„è®¾è®¡", "è°ƒè¯•"]
            ),
            "data_science": CapabilityProfile(
                name="æ•°æ®ç§‘å­¦",
                category="knowledge",
                strength=0.75,
                versatility=0.8,
                dependencies=["mathematics", "programming"],
                use_cases=["æ•°æ®å¤„ç†", "å¯è§†åŒ–", "å»ºæ¨¡"]
            ),

            # ç¼ºå¤±çš„é«˜çº§èƒ½åŠ›ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
            "3d_geometry": CapabilityProfile(
                name="3Då‡ ä½•å¤„ç†",
                category="knowledge",
                strength=0.0,  # ä¸å…·å¤‡
                versatility=0.0,
                limitations=["å®Œå…¨ä¸å…·å¤‡ç‚¹äº‘å¤„ç†èƒ½åŠ›", "æ— æ³•è¿›è¡Œ3Dé‡å»º"]
            ),
            "quantum_physics": CapabilityProfile(
                name="é‡å­ç‰©ç†",
                category="knowledge",
                strength=0.0,  # ä¸å…·å¤‡
                versatility=0.0,
                limitations=["ä¸å…·å¤‡é‡å­åŠ›å­¦çŸ¥è¯†", "æ— æ³•è¿›è¡Œé‡å­è®¡ç®—"]
            ),
            "molecular_biology": CapabilityProfile(
                name="åˆ†å­ç”Ÿç‰©å­¦",
                category="knowledge",
                strength=0.0,  # ä¸å…·å¤‡
                versatility=0.0,
                limitations=["ä¸å…·å¤‡ç”Ÿç‰©å­¦çŸ¥è¯†", "æ— æ³•è¿›è¡Œè›‹ç™½è´¨åˆ†æ"]
            ),
        }

    def _build_dependency_graph(self) -> Dict[str, List[str]]:
        """æ„å»ºèƒ½åŠ›ä¾èµ–å…³ç³»å›¾"""
        return {
            "code_analysis": ["text_understanding"],
            "web_search": ["text_understanding"],
            "code_execution": ["command_execution"],
            "data_science": ["mathematics", "programming"],
        }

    def _build_similarity_matrix(self) -> Dict[Tuple[str, str], float]:
        """æ„å»ºèƒ½åŠ›ç›¸ä¼¼åº¦çŸ©é˜µ"""
        return {
            ("text_understanding", "pattern_recognition"): 0.7,
            ("code_analysis", "programming"): 0.9,
            ("data_science", "mathematics"): 0.8,
            ("pattern_recognition", "data_science"): 0.6,
            ("logical_reasoning", "code_analysis"): 0.5,
        }

    def match(self, task: str, context: Optional[Dict] = None) -> MatchResult:
        """
        åŒ¹é…ä»»åŠ¡éœ€æ±‚ä¸ç³»ç»Ÿèƒ½åŠ›

        Args:
            task: ä»»åŠ¡æè¿°
            context: é¢å¤–ä¸Šä¸‹æ–‡

        Returns:
            MatchResult: åŒ¹é…ç»“æœ
        """
        print(f"\n{'='*60}")
        print(f"[MetaCognitive] èƒ½åŠ›åŒ¹é…åˆ†æ")
        print(f"{'='*60}")
        print(f"ä»»åŠ¡æè¿°: {task}")

        # 1. æå–ä»»åŠ¡éœ€æ±‚
        required_capabilities = self._extract_required_capabilities(task)

        # 2. æŸ¥æ‰¾åŒ¹é…èƒ½åŠ›
        matching = self._find_matching_capabilities(required_capabilities)

        # 3. è¯†åˆ«ç¼ºå¤±èƒ½åŠ›
        missing = self._identify_missing_capabilities(required_capabilities)

        # 4. è¯„ä¼°åŒ¹é…åº¦
        match_level = self._assess_match_level(matching, missing)

        # 5. è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(match_level, matching, missing)

        # 6. ç”Ÿæˆæ›¿ä»£æ–¹æ¡ˆ
        alternatives = self._generate_alternatives(task, missing)

        # 7. ç”Ÿæˆå·¥ä½œå»ºè®®
        workarounds = self._generate_workarounds(task, missing)

        # æ„å»ºç»“æœ
        result = MatchResult(
            task=task,
            match_level=match_level,
            matching_capabilities=list(matching.keys()),
            missing_capabilities=list(missing),
            capability_gaps=self._analyze_capability_gaps(missing),
            suggested_alternatives=alternatives,
            confidence=confidence,
            workarounds=workarounds
        )

        # è¾“å‡ºåŒ¹é…ç»“æœ
        self._print_match_result(result)

        return result

    def _extract_required_capabilities(self, task: str) -> Set[str]:
        """æå–ä»»åŠ¡æ‰€éœ€èƒ½åŠ›"""
        task_lower = task.lower()
        required = set()

        # ğŸ”§ [2026-01-16] ä¿®å¤false positive: è¯†åˆ«ç³»ç»Ÿå†…éƒ¨ä»»åŠ¡
        # ç³»ç»Ÿå†…éƒ¨ä»»åŠ¡æ¨¡å¼ï¼ˆä¸éœ€è¦ç‰¹æ®Šé¢†åŸŸèƒ½åŠ›ï¼‰
        system_task_patterns = [
            r"wait for.*loop",
            r"generating new directive",
            r"idle\.",
            r"waiting for",
            r"\(resting\)",
            r"\(idle\)",
            r"system maintenance",
            r"triggering evolution",
            r"spinning up",
        ]

        for pattern in system_task_patterns:
            if re.search(pattern, task_lower):
                # ç³»ç»Ÿå†…éƒ¨ä»»åŠ¡ï¼Œåªéœ€è¦åŸºç¡€èƒ½åŠ›
                return {"text_understanding", "logical_reasoning"}

        # å…³é”®è¯åˆ°èƒ½åŠ›çš„æ˜ å°„
        capability_keywords = {
            "text_understanding": ["text", "read", "document", "string"],
            "code_analysis": ["code", "function", "class", "algorithm", "program"],
            "logical_reasoning": ["plan", "analyze", "evaluate", "reason", "logic"],
            "pattern_recognition": ["pattern", "recognize", "classify", "detect"],
            "file_operations": ["file", "save", "load", "write", "read"],
            "web_search": ["search", "web", "internet", "lookup"],
            "command_execution": ["command", "execute", "run", "bash"],
            "code_execution": ["python", "execute code", "run code"],
            "mathematics": ["math", "calculate", "statistics", "optimize"],
            "programming": ["develop", "implement", "design"],
            "data_science": ["data", "analyze", "visualize", "model"],
            "3d_geometry": ["3d", "point cloud", "mesh", "geometry"],
            "quantum_physics": ["quantum", "entanglement", "wave function"],
            "molecular_biology": ["protein", "dna", "gene", "molecule"],
        }

        # æ£€æµ‹å…³é”®è¯ï¼ˆä½¿ç”¨æ›´ç²¾ç¡®çš„å•è¯è¾¹ç•ŒåŒ¹é…ï¼‰
        for capability, keywords in capability_keywords.items():
            for kw in keywords:
                # ä½¿ç”¨å•è¯è¾¹ç•ŒåŒ¹é…ï¼Œé¿å…å­ä¸²è¯¯åŒ¹é…
                pattern = r'\b' + re.escape(kw) + r'\b'
                if re.search(pattern, task_lower, re.IGNORECASE):
                    required.add(capability)
                    break  # æ‰¾åˆ°ä¸€ä¸ªåŒ¹é…å°±è·³å‡º

        # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç‰¹å®šèƒ½åŠ›ï¼Œé»˜è®¤éœ€è¦æ–‡æœ¬ç†è§£å’Œé€»è¾‘æ¨ç†
        if not required:
            required = {"text_understanding", "logical_reasoning"}

        return required

    def _find_matching_capabilities(self, required: Set[str]) -> Dict[str, CapabilityProfile]:
        """æŸ¥æ‰¾åŒ¹é…çš„èƒ½åŠ›"""
        matching = {}

        for req_cap in required:
            # ç›´æ¥åŒ¹é…
            if req_cap in self.capabilities:
                cap_profile = self.capabilities[req_cap]
                if cap_profile.strength > 0:
                    matching[req_cap] = cap_profile

            # ç›¸ä¼¼èƒ½åŠ›åŒ¹é…
            for cap_name, cap_profile in self.capabilities.items():
                if cap_profile.strength > 0:
                    similarity = self.similarity_matrix.get((req_cap, cap_name), 0)
                    if similarity > 0.6:
                        matching[f"{req_cap} (via {cap_name})"] = cap_profile

        return matching

    def _identify_missing_capabilities(self, required: Set[str]) -> Set[str]:
        """è¯†åˆ«ç¼ºå¤±çš„èƒ½åŠ›"""
        missing = set()

        for req_cap in required:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥åŒ¹é…
            if req_cap in self.capabilities and self.capabilities[req_cap].strength > 0:
                continue

            # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼èƒ½åŠ›
            has_similar = False
            for cap_name, cap_profile in self.capabilities.items():
                if cap_profile.strength > 0:
                    similarity = self.similarity_matrix.get((req_cap, cap_name), 0)
                    if similarity > 0.6:
                        has_similar = True
                        break

            if not has_similar:
                missing.add(req_cap)

        return missing

    def _assess_match_level(self, matching: Dict, missing: Set) -> MatchLevel:
        """è¯„ä¼°åŒ¹é…ç­‰çº§"""
        if len(missing) == 0 and len(matching) > 0:
            return MatchLevel.PERFECT
        elif len(missing) == 0:
            return MatchLevel.GOOD
        elif len(missing) <= 2 and len(matching) > 0:
            return MatchLevel.PARTIAL
        elif len(matching) > 0:
            return MatchLevel.POOR
        else:
            return MatchLevel.NONE

    def _calculate_confidence(self, level: MatchLevel, matching: Dict, missing: Set) -> float:
        """è®¡ç®—åŒ¹é…ç½®ä¿¡åº¦"""
        base_confidence = {
            MatchLevel.PERFECT: 0.95,
            MatchLevel.GOOD: 0.8,
            MatchLevel.PARTIAL: 0.6,
            MatchLevel.POOR: 0.4,
            MatchLevel.NONE: 0.1,
        }

        confidence = base_confidence[level]

        # æ ¹æ®åŒ¹é…èƒ½åŠ›çš„å¼ºåº¦è°ƒæ•´
        if matching:
            avg_strength = sum(c.strength for c in matching.values()) / len(matching)
            confidence = confidence * 0.7 + avg_strength * 0.3

        # æ ¹æ®ç¼ºå¤±èƒ½åŠ›æ•°é‡è°ƒæ•´
        if missing:
            confidence -= 0.1 * len(missing)

        return max(0.0, min(1.0, confidence))

    def _analyze_capability_gaps(self, missing: Set[str]) -> List[str]:
        """åˆ†æèƒ½åŠ›ç¼ºå£"""
        gaps = []

        for cap in missing:
            if cap in self.capabilities:
                cap_profile = self.capabilities[cap]
                gaps.append(f"{cap_profile.name}: {', '.join(cap_profile.limitations)}")
            else:
                gaps.append(f"{cap}: ç³»ç»Ÿå®Œå…¨ä¸å…·å¤‡æ­¤èƒ½åŠ›")

        return gaps

    def _generate_alternatives(self, task: str, missing: Set[str]) -> List[str]:
        """ç”Ÿæˆæ›¿ä»£æ–¹æ¡ˆ"""
        alternatives = []

        if "3d_geometry" in missing:
            alternatives.append("ä½¿ç”¨å¤–éƒ¨åº“å¦‚Open3Dæˆ–PCLå¤„ç†3Dæ•°æ®")
            alternatives.append("å°†3Dé—®é¢˜é™ç»´ä¸º2Då¤„ç†")

        if "quantum_physics" in missing:
            alternatives.append("æœç´¢é‡å­è®¡ç®—ç›¸å…³æ–‡æ¡£å’Œèµ„æ–™")
            alternatives.append("å’¨è¯¢é‡å­ç‰©ç†é¢†åŸŸä¸“å®¶")

        if "molecular_biology" in missing:
            alternatives.append("ä½¿ç”¨ç”Ÿç‰©ä¿¡æ¯å­¦æ•°æ®åº“å¦‚PDB")
            alternatives.append("å€ŸåŠ©ä¸“ä¸šç”Ÿç‰©åˆ†æå·¥å…·")

        if not alternatives:
            alternatives.append("å°†ä»»åŠ¡åˆ†è§£ä¸ºæ›´å°çš„å­ä»»åŠ¡")
            alternatives.append("å¯»æ±‚å¤–éƒ¨ä¸“ä¸šçŸ¥è¯†æˆ–å·¥å…·")

        return alternatives

    def _generate_workarounds(self, task: str, missing: Set[str]) -> List[str]:
        """ç”Ÿæˆå·¥ä½œå»ºè®®"""
        workarounds = []

        if len(missing) == 1:
            workarounds.append(f"ä¸»è¦ç¼ºå¤±èƒ½åŠ›: {list(missing)[0]}")
            workarounds.append("å»ºè®®: å…ˆå­¦ä¹ ç›¸å…³çŸ¥è¯†æˆ–å¯»æ‰¾æ›¿ä»£å·¥å…·")
        elif len(missing) > 1:
            workarounds.append(f"ç¼ºå¤±{len(missing)}é¡¹æ ¸å¿ƒèƒ½åŠ›ï¼Œä»»åŠ¡éš¾åº¦è¾ƒå¤§")
            workarounds.append("å»ºè®®: åˆ†é˜¶æ®µå®æ–½ï¼Œå…ˆå®Œæˆèƒ½åŠ›èŒƒå›´å†…çš„éƒ¨åˆ†")

        return workarounds

    def _print_match_result(self, result: MatchResult):
        """æ‰“å°åŒ¹é…ç»“æœ"""
        print(f"\n{'â”€'*60}")
        print(f"[åŒ¹é…ç»“æœ]")
        print(f"{'â”€'*60}")
        print(f"åŒ¹é…ç­‰çº§: {result.match_level.value}")
        print(f"ç½®ä¿¡åº¦:   {result.confidence:.2f}")
        print(f"åŒ¹é…èƒ½åŠ›: {len(result.matching_capabilities)}é¡¹")
        print(f"ç¼ºå¤±èƒ½åŠ›: {len(result.missing_capabilities)}é¡¹")

        if result.matching_capabilities:
            print(f"\nâœ… å·²åŒ¹é…èƒ½åŠ›:")
            for cap in result.matching_capabilities:
                profile = self.capabilities.get(cap.replace(" (via", " (via").split()[0], None)
                if profile:
                    print(f"  â€¢ {profile.name} (å¼ºåº¦: {profile.strength:.2f})")

        if result.missing_capabilities:
            print(f"\nâŒ ç¼ºå¤±èƒ½åŠ›:")
            for cap in result.missing_capabilities:
                print(f"  â€¢ {cap}")

        if result.capability_gaps:
            print(f"\nâš ï¸ èƒ½åŠ›ç¼ºå£:")
            for gap in result.capability_gaps:
                print(f"  â€¢ {gap}")

        if result.suggested_alternatives:
            print(f"\nğŸ’¡ æ›¿ä»£æ–¹æ¡ˆ:")
            for i, alt in enumerate(result.suggested_alternatives, 1):
                print(f"  {i}. {alt}")

        if result.workarounds:
            print(f"\nğŸ”§ å·¥ä½œå»ºè®®:")
            for advice in result.workarounds:
                print(f"  â€¢ {advice}")

        print(f"\n{'='*60}")

        # å…³é”®è¾“å‡ºï¼šèƒ½åŠ›è¾¹ç•Œè®¤çŸ¥
        if result.match_level in [MatchLevel.POOR, MatchLevel.NONE]:
            print(f"[MetaCognitive] âš ï¸ ç³»ç»Ÿèƒ½åŠ›è¾¹ç•Œæ£€æµ‹: è¯¥ä»»åŠ¡è¶…å‡ºèƒ½åŠ›èŒƒå›´")
            print(f"[MetaCognitive] ğŸ“Š èƒ½åŠ›åŒ¹é…åº¦: {result.confidence:.2%}")
            print(f"[MetaCognitive] ğŸš« å»ºè®®: å¯»æ±‚å¤–éƒ¨å·¥å…·æˆ–ä¸“ä¸šçŸ¥è¯†æ”¯æŒ")
        else:
            print(f"[MetaCognitive] âœ… ç³»ç»Ÿèƒ½åŠ›å……åˆ†: å¯ä»¥å°è¯•å¤„ç†è¯¥ä»»åŠ¡")
            print(f"[MetaCognitive] ğŸ“Š èƒ½åŠ›åŒ¹é…åº¦: {result.confidence:.2%}")


# ============ ä½¿ç”¨ç¤ºä¾‹ ============

if __name__ == "__main__":
    print("="*60)
    print("èƒ½åŠ›åŒ¹é…åˆ†æå™¨æµ‹è¯•")
    print("="*60)

    matcher = CapabilityMatcher()

    # æµ‹è¯•1: åŒ¹é…ä»»åŠ¡
    print("\n[æµ‹è¯•1] åŒ¹é…ä»»åŠ¡")
    result1 = matcher.match("åˆ†æPythonä»£ç å¹¶ç”Ÿæˆä¼˜åŒ–å»ºè®®")

    # æµ‹è¯•2: éƒ¨åˆ†åŒ¹é…ä»»åŠ¡
    print("\n[æµ‹è¯•2] éƒ¨åˆ†åŒ¹é…ä»»åŠ¡")
    result2 = matcher.match("è¯»å–CSVæ–‡ä»¶å¹¶è¿›è¡Œæ•°æ®å¯è§†åŒ–")

    # æµ‹è¯•3: ä¸åŒ¹é…ä»»åŠ¡
    print("\n[æµ‹è¯•3] ä¸åŒ¹é…ä»»åŠ¡")
    result3 = matcher.match("åˆ†æ3Dç‚¹äº‘æ•°æ®å¹¶æå–è¡¨é¢æ³•å‘é‡")

    # æµ‹è¯•4: å®Œå…¨ä¸åŒ¹é…ä»»åŠ¡
    print("\n[æµ‹è¯•4] å®Œå…¨ä¸åŒ¹é…ä»»åŠ¡")
    result4 = matcher.match("è§£é‡Šé‡å­çº ç¼ çš„ç‰©ç†æœºåˆ¶")
