#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‡ªä¸»ç›®æ ‡ç”Ÿæˆç³»ç»Ÿ (Autonomous Goal Generation System)
====================================================

åŠŸèƒ½: å®ç°å®Œå…¨è‡ªä¸»çš„ç›®æ ‡è®¾å®šï¼Œè¶…è¶ŠGoalQuestionerå»ºè®®æ¨¡å¼
ç‰ˆæœ¬: 1.0.0 (2026-01-19)

æ ¸å¿ƒåˆ›æ–°:
1. å†…åœ¨ä»·å€¼å‡½æ•° (Intrinsic Value Function) - æ›¿ä»£å¤–éƒ¨ä»·å€¼
2. æœºä¼šè¯†åˆ«å¼•æ“ (Opportunity Recognition) - è‡ªåŠ¨å‘ç°ç›®æ ‡
3. ç›®æ ‡å±‚çº§æ„å»º (Goal Hierarchy) - é€’å½’åˆ†è§£
4. è‡ªä¸»æ€§è¯„ä¼° (Autonomy Assessment) - è¡¡é‡ç›®æ ‡è‡ªä¸»ç¨‹åº¦
5. ä»·å€¼å‡½æ•°å†…åœ¨åŒ– (Value Internalization) - é•¿æœŸä»·å€¼å­¦ä¹ 

å‚è€ƒç†è®º:
- Self-Determination Theory (SDT) - è‡ªæˆ‘å†³å®šç†è®º
- Intrinsic Motivation - å†…åœ¨åŠ¨æœº
- Goal Setting Theory - ç›®æ ‡è®¾å®šç†è®º
- Value Alignment Research - ä»·å€¼å¯¹é½ç ”ç©¶
"""

import logging
import numpy as np
import time
from typing import Dict, List, Any, Optional, Tuple, Callable
from dataclasses import dataclass, field
from enum import Enum
from collections import deque
from abc import ABC, abstractmethod

logger = logging.getLogger(__name__)


class ValueSourceType(Enum):
    """ä»·å€¼æ¥æºç±»å‹"""
    INTRINSIC = "intrinsic"       # å†…åœ¨ä»·å€¼ï¼ˆå¥½å¥‡å¿ƒã€èƒœä»»æ„Ÿï¼‰
    EXTRINSIC = "extrinsic"       # å¤–åœ¨ä»·å€¼ï¼ˆä»»åŠ¡ã€å¥–åŠ±ï¼‰
    SOCIAL = "social"            # ç¤¾ä¼šä»·å€¼ï¼ˆè®¤å¯ã€åä½œï¼‰
    EPISTEMIC = "epistemic"       # è®¤çŸ¥ä»·å€¼ï¼ˆçŸ¥è¯†ã€çœŸç†ï¼‰
    CREATIVE = "creative"        # åˆ›é€ ä»·å€¼ï¼ˆæ–°é¢–æ€§ã€åˆ›æ–°ï¼‰


@dataclass
class ValueSignal:
    """ä»·å€¼ä¿¡å·"""
    source: ValueSourceType
    magnitude: float  # ä»·å€¼å¼ºåº¦ (0-1)
    direction: str    # "approach" or "avoid"
    context: Dict[str, Any]
    timestamp: float = field(default_factory=time.time)

    def compute_value(self) -> float:
        """è®¡ç®—ç»¼åˆä»·å€¼"""
        if self.direction == "approach":
            return self.magnitude
        else:
            return -self.magnitude


@dataclass
class Goal:
    """ç›®æ ‡"""
    goal_id: str
    description: str
    value: float              # ç›®æ ‡ä»·å€¼ (0-1)
    autonomy: float           # è‡ªä¸»æ€§ (0-1)
    source: str               # æ¥æº (intrinsic/extrinsic/social)
    priority: int             # ä¼˜å…ˆçº§ (1-10)
    sub_goals: List['Goal'] = field(default_factory=list)
    parent_goal: Optional['Goal'] = None
    status: str = "pending"    # pending, in_progress, completed, abandoned
    created_at: float = field(default_factory=time.time)

    def add_sub_goal(self, sub_goal: 'Goal'):
        """æ·»åŠ å­ç›®æ ‡"""
        sub_goal.parent_goal = self
        self.sub_goals.append(sub_goal)

    def get_depth(self) -> int:
        """è·å–ç›®æ ‡æ·±åº¦ï¼ˆé€’å½’ï¼‰"""
        if not self.sub_goals:
            return 1
        return 1 + max(g.get_depth() for g in self.sub_goals)

    def get_total_value(self) -> float:
        """è·å–æ€»ä»·å€¼ï¼ˆåŒ…å«å­ç›®æ ‡ï¼‰"""
        sub_values = sum(g.get_total_value() for g in self.sub_goals)
        return self.value + sub_values * 0.3  # å­ç›®æ ‡ä»·å€¼æŠ˜ç®—


@dataclass
class Opportunity:
    """æœºä¼šï¼ˆæ½œåœ¨ç›®æ ‡ï¼‰"""
    opportunity_id: str
    description: str
    expected_value: float
    confidence: float        # ç½®ä¿¡åº¦ (0-1)
    required_resources: List[str]
    feasibility: float       # å¯è¡Œæ€§ (0-1)
    urgency: float          # ç´§è¿«æ€§ (0-1)
    novelty: float          # æ–°é¢–æ€§ (0-1)

    def compute_opportunity_score(self) -> float:
        """è®¡ç®—æœºä¼šå¾—åˆ†"""
        # åŠ æƒç»„åˆ
        score = (
            0.3 * self.expected_value +
            0.2 * self.confidence +
            0.2 * self.feasibility +
            0.15 * self.urgency +
            0.15 * self.novelty
        )
        return score


class IntrinsicValueFunction:
    """
    å†…åœ¨ä»·å€¼å‡½æ•°

    åŸºäºSelf-Determination Theory (SDT):
    - Autonomy (è‡ªä¸»æ€§): æ„Ÿåˆ°è¡Œä¸ºè‡ªä¸»å¯æ§
    - Competence (èƒœä»»æ„Ÿ): æ„Ÿåˆ°èƒ½åŠ›æå‡
    - Relatedness (å…³è”æ€§): æ„Ÿåˆ°ä¸ç³»ç»Ÿç›®æ ‡å…³è”
    """

    def __init__(self):
        # ä»·å€¼æƒé‡ï¼ˆå¯å­¦ä¹ ï¼‰
        self.value_weights = {
            'curiosity': 0.35,      # å¥½å¥‡å¿ƒé©±åŠ¨
            'competence': 0.30,     # èƒ½åŠ›æå‡
            'autonomy': 0.20,       # è‡ªä¸»æ€§
            'creativity': 0.15      # åˆ›é€ æ€§
        }

        # å†å²ä»·å€¼è®°å½•ï¼ˆç”¨äºå­¦ä¹ ï¼‰
        self.value_history: deque = deque(maxlen=1000)

        # ä»·å€¼å‡½æ•°å‚æ•°
        self.curiosity_decay = 0.95      # å¥½å¥‡å¿ƒè¡°å‡
        self.competence_threshold = 0.6   # èƒœä»»æ„Ÿé˜ˆå€¼
        self.autonomy_threshold = 0.5     # è‡ªä¸»æ€§é˜ˆå€¼

    def compute_value(self, state: Dict[str, Any]) -> float:
        """
        è®¡ç®—å†…åœ¨ä»·å€¼

        Args:
            state: ç³»ç»ŸçŠ¶æ€ï¼ŒåŒ…å«ï¼š
                - curiosity: å½“å‰å¥½å¥‡å¿ƒ (0-1)
                - competence: å½“å‰èƒ½åŠ›æ„Ÿ (0-1)
                - autonomy: å½“å‰è‡ªä¸»æ€§ (0-1)
                - creativity: åˆ›é€ æ€§å¾—åˆ† (0-1)
                - uncertainty: ä¸ç¡®å®šæ€§ (0-1)
                - novelty: æ–°é¢–æ€§ (0-1)

        Returns:
            float: å†…åœ¨ä»·å€¼ (0-1)
        """
        # æå–çŠ¶æ€ç‰¹å¾
        curiosity = state.get('curiosity', 0.5)
        competence = state.get('competence', 0.5)
        autonomy = state.get('autonomy', 0.5)
        creativity = state.get('creativity', 0.5)
        uncertainty = state.get('uncertainty', 0.5)
        novelty = state.get('novelty', 0.5)

        # 1. å¥½å¥‡å¿ƒä»·å€¼ï¼šè¿½æ±‚æ–°é¢–å’Œä¸ç¡®å®šæ€§
        curiosity_value = (
            curiosity *
            (1 + novelty) *
            (1 + uncertainty)
        )

        # 2. èƒœä»»æ„Ÿä»·å€¼ï¼šè¿½æ±‚èƒ½åŠ›æå‡
        competence_value = competence
        if competence > self.competence_threshold:
            competence_value *= 1.2  # è¶…è¶Šé˜ˆå€¼çš„èƒœä»»æ„Ÿæ›´å®è´µ

        # 3. è‡ªä¸»æ€§ä»·å€¼ï¼šè¿½æ±‚è‡ªä¸»æ§åˆ¶
        autonomy_value = autonomy
        if autonomy < self.autonomy_threshold:
            autonomy_value *= 0.7  # ä½è‡ªä¸»æ€§é™ä½ä»·å€¼

        # 4. åˆ›é€ æ€§ä»·å€¼ï¼šè¿½æ±‚æ–°é¢–æ€§
        creativity_value = (
            creativity *
            (1 + novelty)
        )

        # åŠ æƒç»„åˆ
        intrinsic_value = (
            self.value_weights['curiosity'] * curiosity_value +
            self.value_weights['competence'] * competence_value +
            self.value_weights['autonomy'] * autonomy_value +
            self.value_weights['creativity'] * creativity_value
        )

        # è®°å½•å†å²
        self.value_history.append({
            'timestamp': time.time(),
            'value': intrinsic_value,
            'state': state
        })

        return intrinsic_value

    def update_weights(self, recent_outcomes: List[Dict]):
        """
        æ ¹æ®æœ€è¿‘ç»“æœæ›´æ–°ä»·å€¼æƒé‡ï¼ˆå­¦ä¹ ï¼‰

        Args:
            recent_outcomes: æœ€è¿‘çš„è¡ŒåŠ¨ç»“æœåˆ—è¡¨
                - value_type: ä»·å€¼ç±»å‹ (curiosity/competence/autonomy/creativity)
                - outcome: ç»“æœå¥½å (0-1)
        """
        for outcome in recent_outcomes:
            value_type = outcome.get('value_type', 'curiosity')
            result = outcome.get('outcome', 0.5)

            # ç®€å•çš„å¼ºåŒ–å­¦ä¹ æ›´æ–°
            if value_type in self.value_weights:
                # æˆåŠŸ -> å¢åŠ æƒé‡
                # å¤±è´¥ -> å‡å°‘æƒé‡
                adjustment = 0.01 * (result - 0.5)
                self.value_weights[value_type] = np.clip(
                    self.value_weights[value_type] + adjustment,
                    0.1, 0.5  # ä¿æŒåœ¨åˆç†èŒƒå›´
                )

        # å½’ä¸€åŒ–æƒé‡
        total = sum(self.value_weights.values())
        for key in self.value_weights:
            self.value_weights[key] /= total

        logger.debug(f"ä»·å€¼æƒé‡æ›´æ–°: {self.value_weights}")


class OpportunityRecognitionEngine:
    """æœºä¼šè¯†åˆ«å¼•æ“"""

    def __init__(self, value_function: IntrinsicValueFunction):
        self.value_function = value_function
        self.opportunities: List[Opportunity] = []

    def identify_opportunities(self,
                                state: Dict[str, Any],
                                context: Dict[str, Any]) -> List[Opportunity]:
        """
        è¯†åˆ«æœºä¼šï¼ˆæ½œåœ¨ç›®æ ‡ï¼‰

        Args:
            state: å½“å‰ç³»ç»ŸçŠ¶æ€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            è¯†åˆ«å‡ºçš„æœºä¼šåˆ—è¡¨
        """
        opportunities = []

        # 1. å¥½å¥‡å¿ƒé©±åŠ¨æœºä¼šï¼šæ¢ç´¢æœªçŸ¥é¢†åŸŸ
        if state.get('curiosity', 0) > 0.6:
            opportunities.append(Opportunity(
                opportunity_id=f"curiosity_explore_{int(time.time())}",
                description="æ¢ç´¢æœªçŸ¥é¢†åŸŸä»¥è·å¾—æ–°çŸ¥è¯†",
                expected_value=self._compute_curiosity_value(state),
                confidence=0.7,
                required_resources=["attention", "time"],
                feasibility=0.8,
                urgency=0.3,
                novelty=0.9
            ))

        # 2. èƒ½åŠ›æå‡æœºä¼šï¼šæŒ‘æˆ˜ç•¥é«˜äºå½“å‰æ°´å¹³çš„ä»»åŠ¡
        competence = state.get('competence', 0.5)
        if competence < 0.9:
            opportunities.append(Opportunity(
                opportunity_id=f"competence_growth_{int(time.time())}",
                description=f"æŒ‘æˆ˜å½“å‰èƒ½åŠ›è¾¹ç•Œï¼ˆå½“å‰{competence:.2%}ï¼‰",
                expected_value=self._compute_growth_value(state),
                confidence=0.8,
                required_resources=["effort", "learning"],
                feasibility=0.7,
                urgency=0.5,
                novelty=0.4
            ))

        # 3. åˆ›é€ æ€§æœºä¼šï¼šç”Ÿæˆæ–°æ´å¯Ÿæˆ–ç†è®º
        if state.get('creativity', 0) > 0.7:
            opportunities.append(Opportunity(
                opportunity_id=f"creative_insight_{int(time.time())}",
                description="ç”ŸæˆåŸåˆ›æ´å¯Ÿæˆ–ç†è®ºå‡è®¾",
                expected_value=0.85,
                confidence=0.6,
                required_resources=["deep_reasoning", "knowledge"],
                feasibility=0.6,
                urgency=0.4,
                novelty=0.95
            ))

        # 4. ç³»ç»Ÿä¼˜åŒ–æœºä¼šï¼šæ”¹è¿›ç³»ç»Ÿæ€§èƒ½
        if state.get('entropy', 0) > 0.6:
            opportunities.append(Opportunity(
                opportunity_id=f"system_optimize_{int(time.time())}",
                description="ä¼˜åŒ–ç³»ç»Ÿä»¥é™ä½ç†µå€¼",
                expected_value=0.75,
                confidence=0.8,
                required_resources=["analysis", "modification"],
                feasibility=0.7,
                urgency=0.7,
                novelty=0.3
            ))

        # 5. åä½œæœºä¼šï¼šå¤šæ™ºèƒ½ä½“åä½œ
        if context.get('multi_agent_available', False):
            opportunities.append(Opportunity(
                opportunity_id=f"collaboration_{int(time.time())}",
                description="ä¸å…¶ä»–æ™ºèƒ½ä½“åä½œå®Œæˆå¤æ‚ä»»åŠ¡",
                expected_value=0.70,
                confidence=0.6,
                required_resources=["communication", "coordination"],
                feasibility=0.5,
                urgency=0.4,
                novelty=0.6
            ))

        return opportunities

    def _compute_curiosity_value(self, state: Dict) -> float:
        """è®¡ç®—å¥½å¥‡å¿ƒé©±åŠ¨ä»·å€¼"""
        curiosity = state.get('curiosity', 0.5)
        novelty = state.get('novelty', 0.5)
        return curiosity * (1 + novelty)

    def _compute_growth_value(self, state: Dict) -> float:
        """è®¡ç®—æˆé•¿ä»·å€¼"""
        competence = state.get('competence', 0.5)
        # è¾¹é™…æ•ˆåº”ï¼šèƒ½åŠ›è¶Šä½ï¼Œæˆé•¿ä»·å€¼è¶Šé«˜
        return (1 - competence) * 1.2


class AutonomousGoalGenerator:
    """
    è‡ªä¸»ç›®æ ‡ç”Ÿæˆå™¨

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. è¯†åˆ«æœºä¼šï¼ˆæ½œåœ¨ç›®æ ‡ï¼‰
    2. è¯„ä¼°æœºä¼šä»·å€¼
    3. é€‰æ‹©æœ€ä½³ç›®æ ‡
    4. æ„å»ºç›®æ ‡å±‚çº§
    """

    def __init__(self):
        self.value_function = IntrinsicValueFunction()
        self.opportunity_engine = OpportunityRecognitionEngine(self.value_function)
        self.goal_history: List[Goal] = []

        # ç›®æ ‡ç”Ÿæˆç»Ÿè®¡
        self.stats = {
            'goals_generated': 0,
            'intrinsic_goals': 0,
            'extrinsic_goals': 0,
            'avg_goal_value': 0.0,
            'avg_autonomy': 0.0
        }

        logger.info("ğŸ¯ AutonomousGoalGenerator initialized")

    def generate_goal(self,
                      state: Dict[str, Any],
                      context: Dict[str, Any]) -> Optional[Goal]:
        """
        è‡ªä¸»ç”Ÿæˆç›®æ ‡

        Args:
            state: å½“å‰ç³»ç»ŸçŠ¶æ€
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            ç”Ÿæˆçš„ç›®æ ‡ï¼Œè‹¥æ— åˆé€‚æœºä¼šåˆ™è¿”å›None
        """
        # 1. è¯†åˆ«æœºä¼š
        opportunities = self.opportunity_engine.identify_opportunities(state, context)

        if not opportunities:
            logger.debug("æœªè¯†åˆ«åˆ°ä»»ä½•æœºä¼š")
            return None

        # 2. è¯„ä¼°æœºä¼š
        scored_opportunities = []
        for opp in opportunities:
            score = opp.compute_opportunity_score()
            scored_opportunities.append((opp, score))

        # 3. é€‰æ‹©æœ€ä½³æœºä¼š
        scored_opportunities.sort(key=lambda x: x[1], reverse=True)
        best_opportunity, best_score = scored_opportunities[0]

        # å¦‚æœæœ€ä½³æœºä¼šå¾—åˆ†å¤ªä½ï¼Œä¸ç”Ÿæˆç›®æ ‡
        if best_score < 0.4:
            logger.debug(f"æœ€ä½³æœºä¼šå¾—åˆ†è¿‡ä½: {best_score:.2f}")
            return None

        # 4. ç”Ÿæˆç›®æ ‡
        goal = Goal(
            goal_id=f"goal_{int(time.time() * 1000)}",
            description=best_opportunity.description,
            value=best_opportunity.expected_value,
            autonomy=0.8,  # è‡ªä¸»ç”Ÿæˆçš„ç›®æ ‡ï¼Œé«˜è‡ªä¸»æ€§
            source="intrinsic",
            priority=int(best_opportunity.urgency * 10)
        )

        # 5. è®°å½•ç»Ÿè®¡
        self.stats['goals_generated'] += 1
        self.stats['intrinsic_goals'] += 1
        self.stats['avg_goal_value'] = (
            (self.stats['avg_goal_value'] * (self.stats['goals_generated'] - 1) + goal.value) /
            self.stats['goals_generated']
        )
        self.stats['avg_autonomy'] = (
            (self.stats['avg_autonomy'] * (self.stats['goals_generated'] - 1) + goal.autonomy) /
            self.stats['goals_generated']
        )

        self.goal_history.append(goal)

        logger.info(f"ğŸ¯ è‡ªä¸»ç”Ÿæˆç›®æ ‡: {goal.description} (ä»·å€¼={goal.value:.2f}, è‡ªä¸»æ€§={goal.autonomy:.2f})")

        return goal

    def generate_goal_hierarchy(self,
                               root_goal: Goal,
                               max_depth: int = 3) -> Goal:
        """
        æ„å»ºç›®æ ‡å±‚çº§ï¼ˆé€’å½’åˆ†è§£ï¼‰

        Args:
            root_goal: æ ¹ç›®æ ‡
            max_depth: æœ€å¤§å±‚çº§æ·±åº¦

        Returns:
            æ„å»ºå¥½çš„ç›®æ ‡å±‚çº§æ ‘
        """
        if max_depth <= 0 or root_goal.get_depth() >= max_depth:
            return root_goal

        # æ ¹æ®ç›®æ ‡ç±»å‹ç”Ÿæˆå­ç›®æ ‡
        sub_goals = self._decompose_goal(root_goal)

        for sub_goal_desc in sub_goals:
            sub_goal = Goal(
                goal_id=f"subgoal_{int(time.time() * 1000)}_{len(root_goal.sub_goals)}",
                description=sub_goal_desc['description'],
                value=sub_goal_desc['value'] * 0.8,  # å­ç›®æ ‡ä»·å€¼ç•¥ä½äºçˆ¶ç›®æ ‡
                autonomy=root_goal.autonomy * 0.9,
                source="intrinsic",
                priority=max(1, root_goal.priority - 1)
            )

            # é€’å½’æ„å»ºå­ç›®æ ‡å±‚çº§
            self.generate_goal_hierarchy(sub_goal, max_depth - 1)
            root_goal.add_sub_goal(sub_goal)

        return root_goal

    def _decompose_goal(self, goal: Goal) -> List[Dict[str, Any]]:
        """
        åˆ†è§£ç›®æ ‡ä¸ºå­ç›®æ ‡

        Args:
            goal: è¦åˆ†è§£çš„ç›®æ ‡

        Returns:
            å­ç›®æ ‡æè¿°åˆ—è¡¨
        """
        # æ ¹æ®ç›®æ ‡ç±»å‹è¿›è¡Œåˆ†è§£
        sub_goals = []

        if "æ¢ç´¢" in goal.description:
            sub_goals = [
                {"description": "ç¡®å®šæ¢ç´¢æ–¹å‘", "value": 0.8},
                {"description": "æ”¶é›†ç›¸å…³ä¿¡æ¯", "value": 0.7},
                {"description": "åˆ†æä¸æ•´åˆ", "value": 0.9}
            ]

        elif "ä¼˜åŒ–" in goal.description:
            sub_goals = [
                {"description": "è¯†åˆ«ä¼˜åŒ–ç›®æ ‡", "value": 0.7},
                {"description": "åˆ†æå½“å‰ç“¶é¢ˆ", "value": 0.8},
                {"description": "è®¾è®¡ä¼˜åŒ–æ–¹æ¡ˆ", "value": 0.9},
                {"description": "å®æ–½ä¼˜åŒ–", "value": 0.8}
            ]

        elif "æ´å¯Ÿ" in goal.description or "ç†è®º" in goal.description:
            sub_goals = [
                {"description": "æ”¶é›†ç›¸å…³æ•°æ®", "value": 0.6},
                {"description": "æ·±åº¦æ¨ç†åˆ†æ", "value": 0.9},
                {"description": "ç”Ÿæˆå‡è®¾", "value": 0.95},
                {"description": "éªŒè¯å‡è®¾", "value": 0.8}
            ]

        elif "åä½œ" in goal.description:
            sub_goals = [
                {"description": "è¯†åˆ«åä½œä¼™ä¼´", "value": 0.7},
                {"description": "å®šä¹‰åä½œä»»åŠ¡", "value": 0.8},
                {"description": "å»ºç«‹é€šä¿¡", "value": 0.6},
                {"description": "æ‰§è¡Œåä½œ", "value": 0.9}
            ]

        elif "æŒ‘æˆ˜" in goal.description or "æˆé•¿" in goal.description:
            sub_goals = [
                {"description": "è¯„ä¼°å½“å‰èƒ½åŠ›", "value": 0.6},
                {"description": "é€‰æ‹©æŒ‘æˆ˜ä»»åŠ¡", "value": 0.8},
                {"description": "æ‰§è¡Œä»»åŠ¡", "value": 0.9},
                {"description": "åæ€ä¸æ€»ç»“", "value": 0.85}
            ]

        else:
            # é€šç”¨åˆ†è§£
            sub_goals = [
                {"description": "æ˜ç¡®ç›®æ ‡è¦æ±‚", "value": 0.7},
                {"description": "åˆ¶å®šæ‰§è¡Œè®¡åˆ’", "value": 0.75},
                {"description": "æ‰§è¡Œè®¡åˆ’", "value": 0.8},
                {"description": "éªŒè¯ç»“æœ", "value": 0.75}
            ]

        return sub_goals

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.stats,
            'goal_history_length': len(self.goal_history),
            'intrinsic_ratio': (
                self.stats['intrinsic_goals'] / max(1, self.stats['goals_generated'])
            )
        }


# ==================== è¾…åŠ©å‡½æ•° ====================

def print_goal_tree(goal: Goal, indent: int):
    """æ‰“å°ç›®æ ‡æ ‘"""
    prefix = "  " * indent
    print(f"{prefix}â— {goal.description}")
    print(f"{prefix}  ä»·å€¼={goal.value:.2f}, è‡ªä¸»æ€§={goal.autonomy:.2f}")

    for sub_goal in goal.sub_goals:
        print_goal_tree(sub_goal, indent + 1)


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

if __name__ == "__main__":
    import sys
    import io
    if sys.platform == 'win32':
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

    print("=" * 70)
    print("è‡ªä¸»ç›®æ ‡ç”Ÿæˆç³»ç»Ÿæµ‹è¯•")
    print("=" * 70)

    # åˆ›å»ºç”Ÿæˆå™¨
    generator = AutonomousGoalGenerator()

    # æ¨¡æ‹Ÿç³»ç»ŸçŠ¶æ€
    test_state = {
        'curiosity': 0.75,
        'competence': 0.60,
        'autonomy': 0.50,
        'creativity': 0.80,
        'uncertainty': 0.65,
        'novelty': 0.70,
        'entropy': 0.65
    }

    test_context = {
        'multi_agent_available': False
    }

    print("\næµ‹è¯•1: è‡ªä¸»ç›®æ ‡ç”Ÿæˆ")
    print("-" * 70)

    # ç”Ÿæˆç›®æ ‡
    goal = generator.generate_goal(test_state, test_context)

    if goal:
        print(f"âœ… ç›®æ ‡ç”ŸæˆæˆåŠŸ")
        print(f"   æè¿°: {goal.description}")
        print(f"   ä»·å€¼: {goal.value:.2f}")
        print(f"   è‡ªä¸»æ€§: {goal.autonomy:.2f}")
        print(f"   æ¥æº: {goal.source}")
        print(f"   ä¼˜å…ˆçº§: {goal.priority}")

    print("\næµ‹è¯•2: ç›®æ ‡å±‚çº§æ„å»º")
    print("-" * 70)

    if goal:
        # æ„å»ºç›®æ ‡å±‚çº§
        hierarchy = generator.generate_goal_hierarchy(goal, max_depth=2)

        print(f"âœ… ç›®æ ‡å±‚çº§æ„å»ºå®Œæˆ (æ·±åº¦: {hierarchy.get_depth()})")
        print("\nç›®æ ‡å±‚çº§æ ‘:")
        print_goal_tree(hierarchy, indent=0)

    print("\næµ‹è¯•3: ç»Ÿè®¡ä¿¡æ¯")
    print("-" * 70)

    stats = generator.get_statistics()
    print(f"ç”Ÿæˆç›®æ ‡æ•°: {stats['goals_generated']}")
    print(f"å†…åœ¨ç›®æ ‡æ•°: {stats['intrinsic_goals']}")
    print(f"å¹³å‡ç›®æ ‡ä»·å€¼: {stats['avg_goal_value']:.2f}")
    print(f"å¹³å‡è‡ªä¸»æ€§: {stats['avg_autonomy']:.2f}")
    print(f"å†…åœ¨ç›®æ ‡æ¯”ä¾‹: {stats['intrinsic_ratio']:.2%}")

    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆ")


def print_goal_tree(goal: Goal, indent: int):
    """æ‰“å°ç›®æ ‡æ ‘"""
    prefix = "  " * indent
    print(f"{prefix}â— {goal.description}")
    print(f"{prefix}  ä»·å€¼={goal.value:.2f}, è‡ªä¸»æ€§={goal.autonomy:.2f}")

    for sub_goal in goal.sub_goals:
        print_goal_tree(sub_goal, indent + 1)
