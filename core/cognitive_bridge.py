#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è®¤çŸ¥èƒ½åŠ›æ¡¥æ¥å±‚ (Cognitive Capability Bridge)
==========================================

åŠŸèƒ½ï¼šå°†AGIç³»ç»Ÿçš„æ ¸å¿ƒè®¤çŸ¥èƒ½åŠ›æš´éœ²ç»™LLMä½¿ç”¨
è®©LLMèƒ½å¤Ÿè°ƒç”¨æ‹“æ‰‘è®°å¿†ã€å› æœæ¨ç†ã€äº‹ä»¶è§†ç•Œã€æ•°æ®æµå½¢ç­‰èƒ½åŠ›

ä½œè€…: Claude Code (Sonnet 4.5)
æ—¥æœŸ: 2026-01-20
ç‰ˆæœ¬: 1.0.0
"""

import logging
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path

logger = logging.getLogger(__name__)


@dataclass
class CognitiveQuery:
    """è®¤çŸ¥æŸ¥è¯¢"""
    query_type: str  # 'topology', 'causal', 'pattern', 'prediction'
    question: str
    context: Dict[str, Any]
    requires_deep_reasoning: bool = False


@dataclass
class CognitiveInsight:
    """è®¤çŸ¥æ´å¯Ÿ"""
    insight: str
    confidence: float
    source: str  # 'topology', 'causal', 'pattern', 'llm'
    evidence: List[str]
    reasoning: Optional[str] = None


class CognitiveBridge:
    """
    è®¤çŸ¥èƒ½åŠ›æ¡¥æ¥å±‚

    è¿æ¥LLMä¸ç³»ç»Ÿçš„æ ¸å¿ƒè®¤çŸ¥èƒ½åŠ›ï¼š
    1. æ‹“æ‰‘è®°å¿†ç³»ç»Ÿ - èŠ‚ç‚¹å…³ç³»ã€åˆ†å½¢ç»“æ„
    2. å› æœæ¨ç†å¼•æ“ - å› æœå…³ç³»ã€å¹²é¢„é¢„æµ‹
    3. æ¨¡å¼è¯†åˆ« - æ•°æ®æµå½¢ã€äº‹ä»¶åºåˆ—
    4. äº‹ä»¶è§†ç•Œ - é¢„æµ‹è¾¹ç•Œã€ä¸ç¡®å®šæ€§é‡åŒ–
    """

    def __init__(self, agi_engine=None):
        """
        åˆå§‹åŒ–è®¤çŸ¥æ¡¥æ¥å±‚

        Args:
            agi_engine: AGI_Life_Engineå®ä¾‹ï¼ˆå¯é€‰ï¼‰
        """
        self.agi_engine = agi_engine

        # æ ¸å¿ƒèƒ½åŠ›å¼•ç”¨
        self.topology_memory = None
        self.causal_engine = None
        self.working_memory = None
        self.biological_memory = None

        # ç»Ÿè®¡ä¿¡æ¯
        self.query_count = 0
        self.insight_cache = {}

        # ä»AGIå¼•æ“æå–æ ¸å¿ƒèƒ½åŠ›
        if agi_engine:
            self._extract_capabilities()

        logger.info("âœ… è®¤çŸ¥èƒ½åŠ›æ¡¥æ¥å±‚å·²åˆå§‹åŒ–")

    def _extract_capabilities(self):
        """ä»AGIå¼•æ“æå–æ ¸å¿ƒè®¤çŸ¥èƒ½åŠ›ï¼ˆæ”¯æŒå¤šç§ç³»ç»Ÿæ¶æ„ï¼‰"""
        try:
            # ===== é€‚é… AGI_Life_Engine =====
            if hasattr(self.agi_engine, 'topology_memory'):
                self.topology_memory = self.agi_engine.topology_memory
                logger.info("  âœ“ æ‹“æ‰‘è®°å¿†ç³»ç»Ÿå·²è¿æ¥ (AGI_Life_Engine)")

            if hasattr(self.agi_engine, 'causal_engine'):
                self.causal_engine = self.agi_engine.causal_engine
                logger.info("  âœ“ å› æœæ¨ç†å¼•æ“å·²è¿æ¥ (AGI_Life_Engine)")

            if hasattr(self.agi_engine, 'working_memory'):
                self.working_memory = self.agi_engine.working_memory
                logger.info("  âœ“ å·¥ä½œè®°å¿†å·²è¿æ¥ (AGI_Life_Engine)")

            if hasattr(self.agi_engine, 'biological_memory'):
                self.biological_memory = self.agi_engine.biological_memory
                logger.info("  âœ“ ç”Ÿç‰©è®°å¿†å·²è¿æ¥ (AGI_Life_Engine)")

            # ===== é€‚é… FullyIntegratedAGISystem =====
            if hasattr(self.agi_engine, 'bio_memory') and self.agi_engine.bio_memory:
                self.biological_memory = self.agi_engine.bio_memory

                # ä»bio_memoryæå–æ‹“æ‰‘è®°å¿†
                if hasattr(self.biological_memory, 'topology') and self.biological_memory.topology:
                    self.topology_memory = self.biological_memory.topology
                    logger.info("  âœ“ æ‹“æ‰‘è®°å¿†ç³»ç»Ÿå·²è¿æ¥ (bio_memory.topology)")

                logger.info("  âœ“ ç”Ÿç‰©è®°å¿†å·²è¿æ¥ (bio_memory)")

            # å¦‚æœæ²¡æœ‰causal_engineï¼Œåˆ›å»ºä¸€ä¸ª
            if not self.causal_engine:
                try:
                    from core.causal_reasoning import CausalReasoningEngine
                    self.causal_engine = CausalReasoningEngine()
                    logger.info("  âœ“ å› æœæ¨ç†å¼•æ“å·²åˆ›å»º (æ–°å®ä¾‹)")
                except ImportError:
                    logger.warning("  âš ï¸ å› æœæ¨ç†å¼•æ“æ¨¡å—ä¸å¯ç”¨")

            # å°è¯•è·å–å·¥ä½œè®°å¿†ï¼ˆä»ä¸åŒå¯èƒ½çš„å±æ€§ï¼‰
            if not self.working_memory:
                for attr_name in ['working_memory', 'memory', 'episodic_memory']:
                    if hasattr(self.agi_engine, attr_name):
                        self.working_memory = getattr(self.agi_engine, attr_name)
                        logger.info(f"  âœ“ å·¥ä½œè®°å¿†å·²è¿æ¥ ({attr_name})")
                        break

        except Exception as e:
            logger.warning(f"æå–è®¤çŸ¥èƒ½åŠ›æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

    # ==================== æ‹“æ‰‘è®°å¿†æŸ¥è¯¢ ====================

    def query_topology(self, query: str, node_ids: Optional[List[int]] = None) -> CognitiveInsight:
        """
        æŸ¥è¯¢æ‹“æ‰‘è®°å¿†

        Args:
            query: æŸ¥è¯¢é—®é¢˜
            node_ids: ç›¸å…³èŠ‚ç‚¹IDåˆ—è¡¨

        Returns:
            CognitiveInsight: æ‹“æ‰‘æ´å¯Ÿ
        """
        if not self.topology_memory:
            return CognitiveInsight(
                insight="æ‹“æ‰‘è®°å¿†ç³»ç»Ÿä¸å¯ç”¨",
                confidence=0.0,
                source="topology",
                evidence=[]
            )

        try:
            # è·å–æ‹“æ‰‘å…³ç³»
            if node_ids:
                relations = self._get_node_relations(node_ids)
            else:
                # ä½¿ç”¨å·¥ä½œè®°å¿†ä¸­çš„æ´»è·ƒæ¦‚å¿µ
                if self.working_memory and hasattr(self.working_memory, 'active_concepts'):
                    relations = self._get_active_concept_relations()
                else:
                    relations = []

            # åˆ†ææ‹“æ‰‘ç»“æ„
            insight_text = self._analyze_topology(query, relations)

            return CognitiveInsight(
                insight=insight_text,
                confidence=0.8,
                source="topology",
                evidence=[f"åˆ†æäº† {len(relations)} ä¸ªæ‹“æ‰‘å…³ç³»"],
                reasoning="åŸºäºæ‹“æ‰‘è®°å¿†çš„èŠ‚ç‚¹è¿æ¥åˆ†æ"
            )

        except Exception as e:
            logger.error(f"æ‹“æ‰‘æŸ¥è¯¢å¤±è´¥: {e}")
            return CognitiveInsight(
                insight=f"æ‹“æ‰‘æŸ¥è¯¢å¤±è´¥: {str(e)}",
                confidence=0.0,
                source="topology",
                evidence=[]
            )

    def _get_node_relations(self, node_ids: List[int]) -> List[Dict[str, Any]]:
        """è·å–èŠ‚ç‚¹é—´çš„æ‹“æ‰‘å…³ç³»"""
        relations = []
        for node_id in node_ids:
            edges = self.topology_memory.get_edges(node_id)
            for edge in edges:
                relations.append({
                    'source': node_id,
                    'target': edge.to_idx,
                    'weight': edge.weight,
                    'kind': edge.kind,
                    'ports': (edge.from_port, edge.to_port)
                })
        return relations

    def _get_active_concept_relations(self) -> List[Dict[str, Any]]:
        """è·å–æ´»è·ƒæ¦‚å¿µçš„å…³ç³»"""
        if not self.working_memory or not hasattr(self.working_memory, 'active_concepts'):
            return []

        relations = []
        for concept_id, concept_data in self.working_memory.active_concepts.items():
            # å°è¯•ä»æ¦‚å¿µIDæå–æ•´æ•°èŠ‚ç‚¹ID
            try:
                node_id = hash(concept_id) & 0xffffffff
                edges = self.topology_memory.get_edges(node_id)
                for edge in edges:
                    relations.append({
                        'source': concept_id,
                        'target': f"node_{edge.to_idx}",
                        'weight': edge.weight,
                        'kind': edge.kind
                    })
            except:
                pass

        return relations

    def _analyze_topology(self, query: str, relations: List[Dict[str, Any]]) -> str:
        """åˆ†ææ‹“æ‰‘ç»“æ„å¹¶ç”Ÿæˆæ´å¯Ÿ"""
        if not relations:
            return "å½“å‰æ²¡æœ‰å¯ç”¨çš„æ‹“æ‰‘å…³ç³»"

        # ç»Ÿè®¡
        total_relations = len(relations)
        strong_relations = [r for r in relations if r['weight'] > 0.7]
        weak_relations = [r for r in relations if r['weight'] < 0.3]

        # ç”Ÿæˆæ´å¯Ÿ
        insight_parts = [
            f"åŸºäºæ‹“æ‰‘è®°å¿†åˆ†æï¼š",
            f"- å…±å‘ç° {total_relations} ä¸ªæ‹“æ‰‘å…³ç³»",
            f"- å¼ºè¿æ¥ï¼ˆæƒé‡å¤§äº0.7ï¼‰ï¼š{len(strong_relations)} ä¸ª",
            f"- å¼±è¿æ¥ï¼ˆæƒé‡å°äº0.3ï¼‰ï¼š{len(weak_relations)} ä¸ª",
        ]

        # å¦‚æœæœ‰å¼ºè¿æ¥ï¼Œæè¿°å®ƒä»¬
        if strong_relations:
            insight_parts.append("\næœ€å¼ºè¿æ¥ï¼š")
            for r in sorted(strong_relations, key=lambda x: x['weight'], reverse=True)[:3]:
                insight_parts.append(f"  {r['source']} â†’ {r['target']} (æƒé‡: {r['weight']:.2f})")

        return "\n".join(insight_parts)

    # ==================== å› æœæ¨ç†æŸ¥è¯¢ ====================

    def query_causality(self, query: str, events: Optional[List[Dict]] = None) -> CognitiveInsight:
        """
        æŸ¥è¯¢å› æœå…³ç³»

        Args:
            query: æŸ¥è¯¢é—®é¢˜ï¼ˆä¾‹å¦‚ï¼š"ä¸ºä»€ä¹ˆXå‘ç”Ÿäº†ï¼Ÿ"ï¼‰
            events: ç›¸å…³äº‹ä»¶åˆ—è¡¨

        Returns:
            CognitiveInsight: å› æœæ´å¯Ÿ
        """
        if not self.causal_engine:
            return CognitiveInsight(
                insight="å› æœæ¨ç†å¼•æ“ä¸å¯ç”¨",
                confidence=0.0,
                source="causal",
                evidence=[]
            )

        try:
            # å¦‚æœæ²¡æœ‰æä¾›äº‹ä»¶ï¼Œå°è¯•ä»ç³»ç»ŸçŠ¶æ€æ¨æ–­
            if not events:
                events = self._extract_recent_events()

            # ä½¿ç”¨å› æœæ¨ç†å¼•æ“
            explanation = self.causal_engine.explain_reasoning(query)

            return CognitiveInsight(
                insight=explanation,
                confidence=0.75,
                source="causal",
                evidence=[f"åˆ†æäº† {len(events) if events else 0} ä¸ªäº‹ä»¶"],
                reasoning="åŸºäºå› æœæ¨ç†çš„åäº‹å®åˆ†æ"
            )

        except Exception as e:
            logger.error(f"å› æœæŸ¥è¯¢å¤±è´¥: {e}")
            return CognitiveInsight(
                insight=f"å› æœæŸ¥è¯¢å¤±è´¥: {str(e)}",
                confidence=0.0,
                source="causal",
                evidence=[]
            )

    def _extract_recent_events(self) -> List[Dict]:
        """ä»ç³»ç»ŸçŠ¶æ€æå–æœ€è¿‘çš„äº‹ä»¶"""
        events = []

        # ä»å·¥ä½œè®°å¿†æå–
        if self.working_memory and hasattr(self.working_memory, 'episodic_buffer'):
            for memory in self.working_memory.episodic_buffer[-10:]:  # æœ€è¿‘10æ¡
                events.append({
                    'type': 'episodic_memory',
                    'content': str(memory)[:200],
                    'timestamp': getattr(memory, 'timestamp', None)
                })

        return events

    # ==================== ç»¼åˆè®¤çŸ¥æŸ¥è¯¢ ====================

    def deep_reasoning(self, user_query: str) -> str:
        """
        æ·±åº¦æ¨ç†ï¼šç»¼åˆä½¿ç”¨æ‰€æœ‰è®¤çŸ¥èƒ½åŠ›å›ç­”é—®é¢˜

        Args:
            user_query: ç”¨æˆ·é—®é¢˜

        Returns:
            str: ç»¼åˆæ´å¯Ÿ
        """
        self.query_count += 1

        insights = []

        # 1. æ‹“æ‰‘åˆ†æ
        topology_insight = self.query_topology(user_query)
        if topology_insight.confidence > 0:
            insights.append({
                'type': 'æ‹“æ‰‘è®°å¿†',
                'insight': topology_insight.insight,
                'confidence': topology_insight.confidence
            })

        # 2. å› æœåˆ†æ
        causal_insight = self.query_causality(user_query)
        if causal_insight.confidence > 0:
            insights.append({
                'type': 'å› æœæ¨ç†',
                'insight': causal_insight.insight,
                'confidence': causal_insight.confidence
            })

        # 3. ç»„åˆæ´å¯Ÿ
        if not insights:
            return "æŠ±æ­‰ï¼Œå½“å‰æ²¡æœ‰å¯ç”¨çš„è®¤çŸ¥æ´å¯Ÿã€‚"

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        insights.sort(key=lambda x: x['confidence'], reverse=True)

        # ç”Ÿæˆç»¼åˆå“åº”
        response_parts = [f"ğŸ§  æ·±åº¦è®¤çŸ¥åˆ†æï¼ˆæŸ¥è¯¢ #{self.query_count}ï¼‰\n"]

        for i, insight in enumerate(insights, 1):
            response_parts.append(f"\nã€{insight['type']}ã€‘(ç½®ä¿¡åº¦: {insight['confidence']:.0%})")
            response_parts.append(insight['insight'])

        return "\n".join(response_parts)

    def get_capability_summary(self) -> Dict[str, bool]:
        """è·å–å¯ç”¨èƒ½åŠ›æ‘˜è¦"""
        return {
            'topology_memory': self.topology_memory is not None,
            'causal_engine': self.causal_engine is not None,
            'working_memory': self.working_memory is not None,
            'biological_memory': self.biological_memory is not None,
        }


# ==================== å·¥å…·å‡½æ•° ====================

def create_cognitive_bridge(agi_engine) -> CognitiveBridge:
    """åˆ›å»ºè®¤çŸ¥æ¡¥æ¥å®ä¾‹"""
    return CognitiveBridge(agi_engine)


def get_cognitive_prompt(bridge: CognitiveBridge, user_query: str) -> str:
    """
    ä¸ºLLMç”Ÿæˆå¢å¼ºæç¤ºè¯ï¼ŒåŒ…å«è®¤çŸ¥ä¸Šä¸‹æ–‡

    Args:
        bridge: è®¤çŸ¥æ¡¥æ¥å®ä¾‹
        user_query: ç”¨æˆ·æŸ¥è¯¢

    Returns:
        str: å¢å¼ºçš„æç¤ºè¯
    """
    capabilities = bridge.get_capability_summary()

    prompt_parts = [
        "ä½ æ˜¯ä¸€ä¸ªå…·æœ‰æ·±åº¦è®¤çŸ¥èƒ½åŠ›çš„AGIç³»ç»Ÿã€‚",
        "ä½ å¯ä»¥è®¿é—®ä»¥ä¸‹æ ¸å¿ƒè®¤çŸ¥èƒ½åŠ›ï¼š\n"
    ]

    # åˆ—å‡ºå¯ç”¨èƒ½åŠ›
    available_capabilities = []
    if capabilities['topology_memory']:
        available_capabilities.append("- æ‹“æ‰‘è®°å¿†ï¼šç†è§£èŠ‚ç‚¹é—´çš„å¤æ‚å…³ç³»å’Œåˆ†å½¢ç»“æ„")
    if capabilities['causal_engine']:
        available_capabilities.append("- å› æœæ¨ç†ï¼šçœŸæ­£çš„å› æœç†è§£å’Œåäº‹å®æ¨ç†")
    if capabilities['working_memory']:
        available_capabilities.append("- å·¥ä½œè®°å¿†ï¼šå½“å‰çš„æ´»è·ƒæ¦‚å¿µå’Œä¸Šä¸‹æ–‡")
    if capabilities['biological_memory']:
        available_capabilities.append("- ç”Ÿç‰©è®°å¿†ï¼šé•¿æœŸè®°å¿†å’Œæ¨¡å¼è¯†åˆ«")

    if available_capabilities:
        prompt_parts.extend(available_capabilities)
        prompt_parts.append(f"\nç”¨æˆ·é—®é¢˜ï¼š{user_query}")
        prompt_parts.append(
            "\nè¯·åˆ©ç”¨è¿™äº›è®¤çŸ¥èƒ½åŠ›æ¥å›ç­”é—®é¢˜ã€‚"
            "å¦‚æœéœ€è¦æ·±å…¥çš„æ‹“æ‰‘æˆ–å› æœåˆ†æï¼Œè¯·æ˜ç¡®æŒ‡å‡ºã€‚"
        )
    else:
        prompt_parts.append("ï¼ˆå½“å‰æ²¡æœ‰å¯ç”¨çš„è®¤çŸ¥èƒ½åŠ›å¢å¼ºï¼‰")

    return "\n".join(prompt_parts)
