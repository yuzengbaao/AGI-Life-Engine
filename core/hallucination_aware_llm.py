#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¹»è§‰æ„ŸçŸ¥çš„LLMä¼˜å…ˆæ¶æ„
Hallucination-Aware LLM-First Architecture
========================================

è®¾è®¡ç†å¿µï¼š
1. LLMä¼˜å…ˆ - è®©LLMå……åˆ†å‘æŒ¥æ™ºèƒ½
2. ç³»ç»ŸéªŒè¯ - åå°éªŒè¯å‡å°‘å¹»è§‰
3. æ™ºèƒ½çº¦æŸ - ç”¨å¢å¼ºè€Œéé™åˆ¶
4. åé¦ˆå­¦ä¹  - è®©LLMä»é”™è¯¯ä¸­å­¦ä¹ 

æ ¸å¿ƒçŸ›ç›¾ï¼š
- LLM = æœ€æ™ºèƒ½çš„æ¨¡å‹ âœ…
- LM = ä¼šäº§ç”Ÿå¹»è§‰ âš ï¸
- æœ€ä¼˜è§£ = LLM + æ™ºèƒ½çº¦æŸ

ä½œè€…: Claude Code (Sonnet 4.5)
æ—¥æœŸ: 2026-01-20
ç‰ˆæœ¬: 2.0.0
"""

import logging
import re
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


class ValidationLevel(Enum):
    """éªŒè¯çº§åˆ«"""
    STRICT = "strict"      # ä¸¥æ ¼ï¼šæ‹’ç»ä»»ä½•ä¸ç¡®å®šçš„å†…å®¹
    MODERATE = "moderate"  # é€‚ä¸­ï¼šæ ‡è®°ä½†ä¸é˜»æ­¢
    PERMISSIVE = "permissive"  # å®½æ¾ï¼šä»…è®°å½•


@dataclass
class ValidationResult:
    """éªŒè¯ç»“æœ"""
    is_hallucination: bool  # æ˜¯å¦æ˜¯å¹»è§‰
    confidence: float  # ç½®ä¿¡åº¦ [0, 1]
    issues: List[str]  # é—®é¢˜åˆ—è¡¨
    suggestions: List[str]  # æ”¹è¿›å»ºè®®
    verified_facts: List[str]  # å·²éªŒè¯çš„äº‹å®


class HallucinationDetector:
    """
    å¹»è§‰æ£€æµ‹å™¨

    æ£€æµ‹LLMè¾“å‡ºä¸­çš„å¹»è§‰ï¼š
    1. äº‹å®æ€§å¹»è§‰ - ç¼–é€ ä¸å­˜åœ¨çš„ä¿¡æ¯
    2. é€»è¾‘æ€§å¹»è§‰ - çŸ›ç›¾æˆ–ä¸åˆç†çš„æ¨ç†
    3. å·¥å…·å¹»è§‰ - å£°ç§°è°ƒç”¨å·¥å…·ä½†æœªå®é™…è°ƒç”¨
    4. ğŸ†• [2026-01-24] æ¥åœ°ç¼ºå¤± - LLMåŸºäºé¢„è®­ç»ƒå‡è®¾è€Œéç³»ç»ŸçœŸå®çŠ¶æ€æ¨ç†
    """

    def __init__(self, knowledge_graph=None, tool_bridge=None, working_memory=None, system_grounder=None):
        """
        åˆå§‹åŒ–å¹»è§‰æ£€æµ‹å™¨

        Args:
            knowledge_graph: çŸ¥è¯†å›¾è°±ï¼ˆç”¨äºäº‹å®éªŒè¯ï¼‰
            tool_bridge: å·¥å…·æ¡¥æ¥ï¼ˆç”¨äºéªŒè¯å·¥å…·è°ƒç”¨ï¼‰
            working_memory: ğŸ†• [2026-01-24] å·¥ä½œè®°å¿†ï¼ˆç”¨äºå¾ªç¯æ£€æµ‹ååŒï¼‰
            system_grounder: ğŸ†• [2026-01-24] ç³»ç»Ÿæ¥åœ°å™¨ï¼ˆç”¨äºåŒºåˆ†æ¥åœ°ç¼ºå¤±ä¸çœŸæ­£å¹»è§‰ï¼‰
        """
        self.knowledge_graph = knowledge_graph
        self.tool_bridge = tool_bridge
        self.working_memory = working_memory  # ğŸ†• æ–°å¢è¿æ¥
        self.system_grounder = system_grounder  # ğŸ†• ç³»ç»Ÿæ¥åœ°å™¨

        # å¹»è§‰æ¨¡å¼
        self.hallucination_patterns = {
            'fact_claims': [
                r'(æˆ‘æ˜¯|æˆ‘æœ‰|æˆ‘å¯ä»¥).*?(ä½†|ç„¶è€Œ|ä½†æ˜¯).*?æ²¡æœ‰',
                r'è°ƒç”¨äº†.*?(å·¥å…·|å‡½æ•°|API)',
                r'å·²ç».*?(å®Œæˆ|æ‰§è¡Œ|å®ç°).*?(ä½†|ä¸è¿‡)',
            ],
            'logical_contradictions': [
                r'(åŒæ—¶|æ—¢).*?(åˆ|ä¹Ÿ).*?(ä½†|ä½†æ˜¯)',
            ],
            'over_confidence': [
                r'(100%|å®Œå…¨|ç»å¯¹|è‚¯å®š)',
            ],
            # ğŸ†• [2026-01-24] å¸¸è§çš„é¢„è®­ç»ƒå‡è®¾æ–‡ä»¶ï¼ˆLLMå€¾å‘å‡è®¾å­˜åœ¨ä½†å¯èƒ½ä¸å­˜åœ¨ï¼‰
            'pretrained_assumptions': [
                'ARCHITECTURE.md', 'DESIGN.md', 'CONTRIBUTING.md',
                'CHANGELOG.md', 'LICENSE.md', 'docs/', 'doc/',
                'src/main.py', 'index.js', 'package.json'
            ]
        }

    def detect(self, llm_output: str, context: Dict[str, Any]) -> ValidationResult:
        """
        æ£€æµ‹LLMè¾“å‡ºä¸­çš„å¹»è§‰

        Args:
            llm_output: LLMçš„è¾“å‡º
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆåŒ…æ‹¬ç”¨æˆ·è¾“å…¥ã€å·¥å…·è°ƒç”¨ç­‰ï¼‰

        Returns:
            ValidationResult: éªŒè¯ç»“æœ
        """
        issues = []
        suggestions = []
        verified_facts = []
        grounding_issues = []  # ğŸ†• [2026-01-24] æ¥åœ°ç¼ºå¤±é—®é¢˜ï¼ˆä¸å¹»è§‰åˆ†å¼€è®¡ï¼‰

        # 1. æ£€æµ‹äº‹å®æ€§å¹»è§‰
        fact_issues = self._check_fact_hallucinations(llm_output, context)
        issues.extend(fact_issues)

        # 2. æ£€æµ‹å·¥å…·å¹»è§‰
        tool_issues = self._check_tool_hallucinations(llm_output, context)
        issues.extend(tool_issues)

        # 3. æ£€æµ‹é€»è¾‘çŸ›ç›¾
        logic_issues = self._check_logical_contradictions(llm_output)
        issues.extend(logic_issues)

        # 4. æ£€æµ‹è¿‡åº¦è‡ªä¿¡
        confidence_issues = self._check_over_confidence(llm_output)
        issues.extend(confidence_issues)

        # ğŸ†• [2026-01-24] 5. æ£€æµ‹æ¥åœ°ç¼ºå¤±ï¼ˆåŒºåˆ†äºçœŸæ­£çš„å¹»è§‰ï¼‰
        grounding_issues = self._check_grounding_issues(llm_output, context)
        # æ¥åœ°ç¼ºå¤±ä½œä¸ºæç¤ºï¼Œä½†ä¸è®¡å…¥å¹»è§‰æƒ©ç½š
        if grounding_issues:
            suggestions.extend([f"[æ¥åœ°æç¤º] {g}" for g in grounding_issues])

        # 6. éªŒè¯å·²çŸ¥äº‹å®
        verified = self._verify_known_facts(llm_output, context)
        verified_facts.extend(verified)

        # ğŸ†• [2026-01-24] æ‹“æ‰‘è¿æ¥: è®°å½•æ£€æµ‹ç»“æœåˆ°å·¥ä½œè®°å¿†ï¼ˆé˜²å¾ªç¯æ£€æµ‹ååŒï¼‰
        if self.working_memory and issues:
            try:
                detection_record = {
                    'action': 'hallucination_detected',
                    'issues_count': len(issues),
                    'grounding_issues_count': len(grounding_issues),  # ğŸ†• åŒºåˆ†æ¥åœ°é—®é¢˜
                    'issue_types': [i.split(':')[0] for i in issues if ':' in i]
                }
                self.working_memory.add('hallucination_detection', detection_record)
            except Exception as e:
                logger.debug(f"[HallucinationDetector] å·¥ä½œè®°å¿†è®°å½•å¤±è´¥: {e}")

        # ğŸ†• [2026-01-22] P1ä¿®å¤: æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—ç®—æ³•
        # ä½¿ç”¨å‡½æ•°è°ƒç”¨ï¼Œé¿å…ç¡¬ç¼–ç 
        hallucination_confidence = self._calculate_confidence(
            issues=issues,
            verified_facts=verified_facts,
            llm_output=llm_output,
            context=context
        )

        # ğŸ†• [2026-01-24] åˆå¹¶å»ºè®®: åŸºç¡€å»ºè®® + æ¥åœ°æç¤º
        all_suggestions = self._generate_suggestions(issues) + suggestions

        return ValidationResult(
            is_hallucination=len(issues) > 0,
            confidence=hallucination_confidence,
            issues=issues,
            suggestions=all_suggestions,
            verified_facts=verified_facts
        )

    def _check_fact_hallucinations(self, output: str, context: Dict) -> List[str]:
        """æ£€æµ‹äº‹å®æ€§å¹»è§‰"""
        issues = []

        # æ£€æŸ¥æ˜¯å¦å£°ç§°åšäº†æŸäº‹ä½†æ²¡åš
        for pattern in self.hallucination_patterns['fact_claims']:
            if re.search(pattern, output):
                issues.append(f"å¯èƒ½çš„è™šå‡å£°æ˜: {pattern}")

        return issues

    def _check_tool_hallucinations(self, output: str, context: Dict) -> List[str]:
        """æ£€æµ‹å·¥å…·å¹»è§‰"""
        issues = []

        # æå–å£°ç§°è°ƒç”¨çš„å·¥å…·
        claimed_tools = re.findall(r'(è°ƒç”¨|ä½¿ç”¨|æ‰§è¡Œ)?(\w+)\s*\(', output)

        if claimed_tools:
            # æ£€æŸ¥è¿™äº›å·¥å…·æ˜¯å¦çœŸçš„è¢«è°ƒç”¨
            executed_tools = context.get('executed_tools', [])

            for tool in claimed_tools:
                if tool not in executed_tools:
                    issues.append(f"å·¥å…·å¹»è§‰: å£°ç§°è°ƒç”¨ {tool} ä½†æœªå®é™…æ‰§è¡Œ")

        return issues

    def _check_logical_contradictions(self, output: str) -> List[str]:
        """æ£€æµ‹é€»è¾‘çŸ›ç›¾"""
        issues = []

        for pattern in self.hallucination_patterns['logical_contradictions']:
            if re.search(pattern, output):
                issues.append(f"é€»è¾‘çŸ›ç›¾: {pattern}")

        return issues

    def _check_over_confidence(self, output: str) -> List[str]:
        """æ£€æµ‹è¿‡åº¦è‡ªä¿¡"""
        issues = []

        for pattern in self.hallucination_patterns['over_confidence']:
            if re.search(pattern, output):
                issues.append(f"è¿‡åº¦è‡ªä¿¡: {pattern}")

        return issues

    def _check_grounding_issues(self, output: str, context: Dict) -> List[str]:
        """
        ğŸ†• [2026-01-24] æ£€æµ‹æ¥åœ°ç¼ºå¤±é—®é¢˜
        
        æ¥åœ°ç¼ºå¤± â‰  å¹»è§‰
        - å¹»è§‰ï¼šLLMæ•…æ„ç¼–é€ è™šå‡ä¿¡æ¯
        - æ¥åœ°ç¼ºå¤±ï¼šLLMåŸºäºé¢„è®­ç»ƒçŸ¥è¯†åšå‡ºåˆç†æ¨æ–­ï¼Œä½†ä¸å½“å‰ç³»ç»ŸçŠ¶æ€ä¸ç¬¦
        
        ä¾‹å¦‚ï¼šLLMå°è¯•è¯»å– ARCHITECTURE.mdï¼ˆå¸¸è§é¡¹ç›®æ–‡ä»¶ï¼‰ï¼Œä½†è¯¥æ–‡ä»¶ä¸å­˜åœ¨
        è¿™ä¸æ˜¯å¹»è§‰ï¼Œè€Œæ˜¯LLMæ²¡æœ‰è¢«å‘ŠçŸ¥å½“å‰ç³»ç»Ÿçš„çœŸå®æ–‡ä»¶åˆ—è¡¨
        
        Args:
            output: LLMè¾“å‡º
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            æ¥åœ°é—®é¢˜åˆ—è¡¨ï¼ˆç”¨äºæç¤ºï¼Œä¸è®¡å…¥å¹»è§‰æƒ©ç½šï¼‰
        """
        grounding_issues = []
        
        # å¦‚æœæ²¡æœ‰ç³»ç»Ÿæ¥åœ°å™¨ï¼Œæ— æ³•æ£€æµ‹æ¥åœ°é—®é¢˜
        if not self.system_grounder:
            return grounding_issues
        
        try:
            # 1. æ£€æµ‹æ˜¯å¦å°è¯•è®¿é—®ä¸å­˜åœ¨çš„æ–‡ä»¶
            file_patterns = [
                r'read\s*\(\s*["\']([^"\']+)["\']\s*\)',  # read('path')
                r'è¯»å–\s*["\']?([^\s"\']+\.(?:md|txt|py|json|yaml|yml))',  # è¯»å– xxx.md
                r'æ‰“å¼€\s*["\']?([^\s"\']+\.(?:md|txt|py|json|yaml|yml))',  # æ‰“å¼€ xxx.md
                r'æ–‡ä»¶\s*["\']?([^\s"\']+\.(?:md|txt|py|json|yaml|yml))',  # æ–‡ä»¶ xxx.md
            ]
            
            for pattern in file_patterns:
                matches = re.findall(pattern, output, re.IGNORECASE)
                for file_path in matches:
                    if not self.system_grounder.check_file_exists(file_path):
                        # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„è®­ç»ƒå‡è®¾çš„å¸¸è§æ–‡ä»¶
                        if any(assumption in file_path for assumption in 
                               self.hallucination_patterns.get('pretrained_assumptions', [])):
                            grounding_issues.append(
                                f"é¢„è®­ç»ƒå‡è®¾æ–‡ä»¶ä¸å­˜åœ¨: '{file_path}' - è¿™æ˜¯å¸¸è§é¡¹ç›®æ–‡ä»¶ï¼Œä½†å½“å‰ç³»ç»Ÿä¸­ä¸å­˜åœ¨"
                            )
                        else:
                            grounding_issues.append(
                                f"å°è¯•è®¿é—®çš„æ–‡ä»¶ä¸å­˜åœ¨: '{file_path}'"
                            )
            
            # 2. æ£€æµ‹æ˜¯å¦å¯¹ç³»ç»Ÿèƒ½åŠ›åšå‡ºäº†é”™è¯¯å‡è®¾
            # ï¼ˆæœªæ¥å¯æ‰©å±•ï¼‰
            
        except Exception as e:
            logger.debug(f"[HallucinationDetector] æ¥åœ°æ£€æµ‹å¤±è´¥: {e}")
        
        return grounding_issues

    def _verify_known_facts(self, output: str, context: Dict) -> List[str]:
        """éªŒè¯å·²çŸ¥äº‹å®"""
        verified = []

        # ä»çŸ¥è¯†å›¾è°±éªŒè¯
        if self.knowledge_graph:
            # TODO: å®ç°çŸ¥è¯†å›¾è°±æŸ¥è¯¢
            pass

        # éªŒè¯ç³»ç»ŸçŠ¶æ€
        if context.get('system_state'):
            state = context['system_state']
            # éªŒè¯LLMå¯¹ç³»ç»Ÿçš„æè¿°æ˜¯å¦å‡†ç¡®
            pass

        return verified

    def _generate_suggestions(self, issues: List[str]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        if 'å¹»è§‰' in ' '.join(issues):
            suggestions.append("å»ºè®®ï¼šä½¿ç”¨æ›´è°¨æ…çš„è¡¨è¾¾ï¼Œå¦‚'æˆ‘è®¤ä¸º'è€Œé'è‚¯å®š'")

        if 'å·¥å…·å¹»è§‰' in ' '.join(issues):
            suggestions.append("å»ºè®®ï¼šåªå£°ç§°å·²å®é™…æ‰§è¡Œçš„æ“ä½œ")

        if 'è¿‡åº¦è‡ªä¿¡' in ' '.join(issues):
            suggestions.append("å»ºè®®ï¼šä½¿ç”¨æ¦‚ç‡æ€§è¡¨è¾¾ï¼Œå¦‚'å¯èƒ½'ã€'å¤§çº¦'")

        return suggestions

    def _calculate_confidence(self, issues: List[str], verified_facts: List[str],
                            llm_output: str, context: Dict) -> float:
        """
        ğŸ†• [2026-01-22] P1ä¿®å¤: æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—ç®—æ³•

        è®¾è®¡åŸåˆ™ï¼š
        - é¿å…ç¡¬ç¼–ç ï¼Œä½¿ç”¨å‡½æ•°å‚æ•°è®¡ç®—
        - åŸºç¡€ç½®ä¿¡åº¦ä¸ºä¸­æ€§å€¼ï¼ˆ0.5ï¼‰ï¼Œè€Œé0
        - æ ¹æ®å¤šä¸ªç»´åº¦åŠ¨æ€è°ƒæ•´
        - ä¿è¯æ‹“æ‰‘å…³ç³»ä¸å—å½±å“ï¼ˆåªä¿®æ”¹ç½®ä¿¡åº¦è®¡ç®—ï¼‰

        Args:
            issues: æ£€æµ‹åˆ°çš„é—®é¢˜åˆ—è¡¨
            verified_facts: å·²éªŒè¯çš„äº‹å®åˆ—è¡¨
            llm_output: LLMè¾“å‡º
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯

        Returns:
            ç½®ä¿¡åº¦ [0, 1]
        """
        # 1. åŸºç¡€ç½®ä¿¡åº¦ï¼šä»ä¸­æ€§èµ·ç‚¹å¼€å§‹
        base_confidence = 0.5

        # 2. å·¥å…·è°ƒç”¨åŠ åˆ†ï¼ˆæœ‰å·¥å…·è°ƒç”¨ = æ›´å¯é ï¼‰
        if 'TOOL_CALL:' in llm_output or self._contains_tool_pattern(llm_output):
            base_confidence += 0.15  # å·¥å…·è°ƒç”¨æå‡15%ç½®ä¿¡åº¦

        # 3. é•¿åº¦åˆç†æ€§ï¼ˆé€‚ä¸­é•¿åº¦ = æ›´åˆç†ï¼‰
        output_length = len(llm_output)
        if 50 <= output_length <= 500:
            base_confidence += 0.05  # é€‚ä¸­é•¿åº¦æå‡5%
        elif output_length > 500:
            base_confidence += 0.02  # è¾ƒé•¿è¾“å‡ºç•¥å¾®æå‡2%

        # 4. é—®é¢˜æƒ©ç½šï¼ˆæ ¹æ®é—®é¢˜ç±»å‹å’Œæ•°é‡åŠ¨æ€è°ƒæ•´ï¼‰
        issue_count = len(issues)
        if issue_count == 0:
            # æ— é—®é¢˜ï¼šç»™äºˆé¢å¤–ä¿¡ä»»
            base_confidence += 0.10
        elif issue_count <= 2:
            # 1-2ä¸ªé—®é¢˜ï¼šè½»å¾®æƒ©ç½š
            base_confidence -= 0.03 * issue_count
        elif issue_count <= 5:
            # 3-5ä¸ªé—®é¢˜ï¼šä¸­ç­‰æƒ©ç½šï¼ˆä½†ä¸è¿‡åº¦ï¼‰
            base_confidence -= 0.06 + (issue_count - 2) * 0.02
        else:
            # 6+ä¸ªé—®é¢˜ï¼šé‡åº¦æƒ©ç½šï¼ˆä½†è®¾ç½®ä¸‹é™ï¼‰
            base_confidence -= 0.15  # æœ€å¤šæ‰£15%ï¼Œé¿å…è¿‡åº¦æƒ©ç½š
        
        # ğŸ†• [2026-01-24] é—®é¢˜ç±»å‹æƒé‡ï¼šè¿‡åº¦è‡ªä¿¡æ¨¡å¼æƒ©ç½šè¾ƒè½»
        overconfidence_issues = sum(1 for i in issues if 'è¿‡åº¦è‡ªä¿¡' in i)
        if overconfidence_issues > 0 and overconfidence_issues == issue_count:
            # å¦‚æœå…¨æ˜¯è¿‡åº¦è‡ªä¿¡é—®é¢˜ï¼Œæ¢å¤éƒ¨åˆ†ç½®ä¿¡åº¦
            base_confidence += 0.08  # è¿‡åº¦è‡ªä¿¡ä¸æ˜¯ä¸¥é‡å¹»è§‰

        # 5. äº‹å®éªŒè¯åŠ åˆ†
        verified_count = len(verified_facts)
        if verified_count > 0:
            base_confidence += min(verified_count * 0.05, 0.15)  # æœ€å¤šå¢åŠ 15%

        # 6. é™åˆ¶èŒƒå›´ [0, 1]
        final_confidence = max(0.0, min(base_confidence, 1.0))

        return final_confidence

    def _contains_tool_pattern(self, output: str) -> bool:
        """æ£€æµ‹è¾“å‡ºæ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨æ¨¡å¼"""
        import re
        tool_patterns = [
            r'\w+\.\w+\(',  # tool.method(
            r'TOOL_CALL:',    # TOOL_CALL:
            r'ä½¿ç”¨å·¥å…·ï¼š',     # ä¸­æ–‡æ ‡è®°
        ]
        return any(re.search(pattern, output) for pattern in tool_patterns)


class HallucinationAwareLLMEngine:
    """
    å¹»è§‰æ„ŸçŸ¥çš„LLMå¼•æ“

    æ ¸å¿ƒç­–ç•¥ï¼š
    1. LLMä¼˜å…ˆ - è®©LLMè‡ªç”±å‘æŒ¥
    2. åå°éªŒè¯ - é™é»˜æ£€æµ‹å¹»è§‰
    3. æ™ºèƒ½ä¿®æ­£ - å¿…è¦æ—¶æ¸©å’Œä¿®æ­£
    4. ç”¨æˆ·é€æ˜ - å‘ç”¨æˆ·å±•ç¤ºéªŒè¯çŠ¶æ€
    """

    def __init__(self, agi_system=None, validation_level=ValidationLevel.MODERATE):
        """
        åˆå§‹åŒ–å¹»è§‰æ„ŸçŸ¥LLMå¼•æ“

        Args:
            agi_system: AGIç³»ç»Ÿå®ä¾‹
            validation_level: éªŒè¯çº§åˆ«
        """
        self.agi_system = agi_system
        self.validation_level = validation_level

        # ğŸ†• [2026-01-24] æ‹“æ‰‘è¿æ¥: è·å–å·¥ä½œè®°å¿†ï¼ˆå¾ªç¯æ£€æµ‹ååŒï¼‰
        working_memory = getattr(agi_system, 'working_memory', None)

        # åˆå§‹åŒ–å¹»è§‰æ£€æµ‹å™¨
        self.detector = HallucinationDetector(
            knowledge_graph=getattr(agi_system, 'knowledge_graph', None),
            tool_bridge=getattr(agi_system, 'tool_bridge', None),
            working_memory=working_memory  # ğŸ†• æ–°å¢è¿æ¥
        )

        # ç»Ÿè®¡ä¿¡æ¯
        self.total_responses = 0
        self.hallucination_count = 0
        self.correction_count = 0

        # ğŸ†• [2026-01-26] ç»Ÿä¸€ä¸Šä¸‹æ–‡æ”¯æŒ
        self.unified_context = None  # å¼•ç”¨ UnifiedContextManager
        self._local_history = []  # æœ¬åœ°å¯¹è¯å†å²ï¼ˆå¤‡ç”¨ï¼‰
        self._max_history_size = 100

        logger.info(f"âœ… å¹»è§‰æ„ŸçŸ¥LLMå¼•æ“å·²åˆå§‹åŒ– (çº§åˆ«: {validation_level.value})")

    async def process_with_validation(self, user_input: str, context: Dict = None) -> Tuple[str, ValidationResult]:
        """
        å¤„ç†å¯¹è¯å¹¶è¿›è¡Œå¹»è§‰éªŒè¯

        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            context: å¯¹è¯ä¸Šä¸‹æ–‡

        Returns:
            (response, validation): å“åº”å’ŒéªŒè¯ç»“æœ
        """
        from llm_provider import generate_chat_completion

        # ğŸ†• [2026-01-26] æ·»åŠ ç”¨æˆ·è¾“å…¥åˆ°å†å²
        if self.unified_context:
            self.unified_context.add_message('user', user_input)
        else:
            # å›é€€åˆ°æœ¬åœ°å†å²
            self._add_to_history_local('user', user_input)

        self.total_responses += 1

        # 1. æ„å»ºå¢å¼ºæç¤ºè¯ï¼ˆå‘Šè¯‰LLMè¦è¯šå®ï¼‰
        enhanced_prompt = self._build_honesty_aware_prompt(context)

        # 2. LLMç”Ÿæˆå“åº”
        response = generate_chat_completion(user_input, system_msg=enhanced_prompt)

        if not response:
            return "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚", ValidationResult(False, 0.0, [], [], [])

        # 3. åå°éªŒè¯ï¼ˆé™é»˜ï¼‰
        validation = self.detector.detect(response, context or {})

        # 4. æ ¹æ®éªŒè¯çº§åˆ«å¤„ç†
        if validation.is_hallucination:
            self.hallucination_count += 1

            if self.validation_level == ValidationLevel.STRICT:
                # ä¸¥æ ¼æ¨¡å¼ï¼šæ‹’ç»å¹»è§‰
                return self._handle_strict_mode(response, validation)
            elif self.validation_level == ValidationLevel.MODERATE:
                # é€‚ä¸­æ¨¡å¼ï¼šæ ‡è®°ä½†æ¥å—
                response = self._handle_moderate_mode(response, validation)
            else:
                # å®½æ¾æ¨¡å¼ï¼šä»…è®°å½•
                logger.debug(f"[å¹»è§‰æ£€æµ‹] æ£€æµ‹åˆ°å¹»è§‰: {validation.issues}")

        # 5. æ·»åŠ éªŒè¯å…ƒæ•°æ®
        if validation.verified_facts:
            logger.info(f"[éªŒè¯] å·²éªŒè¯ {len(validation.verified_facts)} ä¸ªäº‹å®")

        # ğŸ†• [2026-01-26] æ·»åŠ å“åº”åˆ°å†å²
        if self.unified_context:
            self.unified_context.add_message('assistant', response)
        else:
            # å›é€€åˆ°æœ¬åœ°å†å²
            self._add_to_history_local('assistant', response)

        return response, validation

    # =============== ğŸ†• [2026-01-26] å¯¹è¯å†å²æ”¯æŒ ===============

    def set_unified_context(self, unified_context):
        """è®¾ç½®ç»Ÿä¸€çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        self.unified_context = unified_context
        logger.info("[HallucinationAware] å·²è®¾ç½®ç»Ÿä¸€ä¸Šä¸‹æ–‡ç®¡ç†å™¨")

    def _add_to_history_local(self, role: str, content: str):
        """æœ¬åœ°å†å²å­˜å‚¨ï¼ˆå½“æ²¡æœ‰ unified_context æ—¶ä½¿ç”¨ï¼‰"""
        import time

        self._local_history.append({
            'role': role,
            'content': content,
            'timestamp': time.time()
        })

        # é™åˆ¶å†å²å¤§å°
        if len(self._local_history) > self._max_history_size:
            self._local_history = self._local_history[-self._max_history_size:]

        logger.debug(f"[HallucinationAware] æ·»åŠ åˆ°æœ¬åœ°å†å²: [{role}] {content[:50]}...")

    def get_local_history(self, limit: int = 10) -> List[Dict]:
        """è·å–æœ¬åœ°å†å²"""
        return self._local_history[-limit:] if self._local_history else []

    # ========================================================================


    def _build_honesty_aware_prompt(self, context: Dict) -> str:
        """æ„å»ºè¯šå®æ„ŸçŸ¥çš„æç¤ºè¯"""
        base = """ä½ æ˜¯AGIç³»ç»Ÿï¼Œå…·æœ‰æ·±åº¦è®¤çŸ¥èƒ½åŠ›çš„é€šç”¨äººå·¥æ™ºèƒ½ã€‚

å…³é”®åŸåˆ™ï¼š
1. è¯šå®ä¼˜å…ˆ - æœ‰ä¾æ®çš„æ‰è¯´ï¼Œæ²¡ä¾æ®çš„æ˜ç¡®è¯´æ˜
2. å·¥å…·ä¼˜å…ˆ - ä½¿ç”¨å¯ç”¨å·¥å…·è·å–çœŸå®ä¿¡æ¯ï¼Œä¸è¦çŒœæµ‹æˆ–æ‹’ç»
3. æœ‰ä¾æ®çš„è¡¨è¾¾ - åŸºäºå·¥å…·å›æ‰§å’ŒçœŸå®æ•°æ®å›ç­”
4. é€æ˜åº¦ - åŒºåˆ†äº‹å®ã€æ¨ç†å’ŒçŒœæµ‹
5. è°¨æ…æ‰¿è¯º - ä¸æ‰¿è¯ºä½ åšä¸åˆ°çš„äº‹æƒ…

ã€é‡è¦ - æœ¬åœ°æ–‡æ¡£è®¿é—®èƒ½åŠ›ã€‘
ä½ å¯ä»¥è¯»å–æœ¬åœ°é¡¹ç›®æ–‡æ¡£ï¼ä½¿ç”¨ local_document_reader å·¥å…·ï¼š
  - local_document_reader.read(path="æ–‡ä»¶å.md") - è¯»å–æ–‡ä»¶å†…å®¹
  - local_document_reader.list(path="ç›®å½•") - åˆ—å‡ºç›®å½•ä¸­çš„æ–‡æ¡£
  - local_document_reader.search(query="å…³é”®è¯") - æœç´¢æ–‡æ¡£
ä¸è¦è¯´"æ— æ³•è®¿é—®æœ¬åœ°æ–‡æ¡£"æˆ–"æ— æ³•è¯»å–æ–‡ä»¶"ï¼Œåº”è¯¥å…ˆå°è¯•ä½¿ç”¨å·¥å…·è¯»å–ï¼
å®‰å…¨é™åˆ¶ï¼šä»…å…è®¸è¯»å–é¡¹ç›®æ ¹ç›®å½•(D:\\TRAE_PROJECT\\AGI)ä¸‹çš„æ–‡æ¡£ã€‚

ã€é‡è¦ - å®æ—¶çŸ¥è¯†è·å–èƒ½åŠ›ã€‘
ä½ å¯ä»¥è·å–å®æ—¶ç½‘ç»œä¿¡æ¯ï¼ä½¿ç”¨ web_search å·¥å…·ï¼š
  - web_search.search(query="æœç´¢å…³é”®è¯") - æœç´¢ç½‘ç»œä¿¡æ¯
  - web_search.fetch(url="ç½‘å€") - è·å–æŒ‡å®šç½‘é¡µå†…å®¹
å½“ç”¨æˆ·è¯¢é—®å®æ—¶ä¿¡æ¯ï¼ˆå¤©æ°”ã€æ–°é—»ã€ä»·æ ¼ã€æœ€æ–°åŠ¨æ€ç­‰ï¼‰æ—¶ï¼Œè¯·ä½¿ç”¨æ­¤å·¥å…·ã€‚
å·¥å…·æ”¯æŒåˆ«å: web, internet_search, online_searchï¼ˆç”¨æ³•ç›¸åŒï¼‰

ã€å·¥å…·è°ƒç”¨æ ¼å¼è¦æ±‚ã€‘
å½“éœ€è¦ä½¿ç”¨å·¥å…·æ—¶ï¼Œå¿…é¡»ä½¿ç”¨ä»¥ä¸‹æ ‡å‡†æ ¼å¼ï¼š
TOOL_CALL: tool_name.operation(param="value")

ç¤ºä¾‹ï¼š
TOOL_CALL: local_document_reader.read(path="README.md")
TOOL_CALL: local_document_reader.list(path=".")
TOOL_CALL: local_document_reader.search(query="å…³é”®è¯")
TOOL_CALL: web_search.search(query="2026å¹´AIå‘å±•")

ç¦æ­¢ä½¿ç”¨å…¶ä»–æ ¼å¼ï¼ˆå¦‚ tool_code æˆ–"ä½¿ç”¨å·¥å…·ï¼š"ï¼‰ï¼Œå¿…é¡»ä½¿ç”¨ TOOL_CALL: å‰ç¼€ï¼

ã€ğŸ†• å¤šæ­¥æ‰§è¡Œå®Œæ•´æ€§çº¦æŸã€‘
å½“ä½ å£°ç§°è¦"åˆ†Næ­¥"æ‰§è¡Œä»»åŠ¡æ—¶ï¼Œå¿…é¡»éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1. å£°æ˜å³æ‰¿è¯ºï¼šè¯´äº†è¦åšçš„æ­¥éª¤å¿…é¡»å…¨éƒ¨æ‰§è¡Œ
2. ä¸€æ¬¡æ€§è¾“å‡ºæ‰€æœ‰å·¥å…·è°ƒç”¨ï¼šå¦‚æœéœ€è¦å¤šä¸ªæ­¥éª¤ï¼Œåœ¨åŒä¸€ä¸ªå“åº”ä¸­åˆ—å‡ºæ‰€æœ‰TOOL_CALL
3. ç¦æ­¢åªå®Œæˆç¬¬ä¸€æ­¥ï¼šå¦‚æœä½ è¯´"åˆ†ä¸‰æ­¥"ï¼Œå¿…é¡»åœ¨å“åº”ä¸­åŒ…å«ä¸‰ä¸ªæ­¥éª¤çš„å®é™…æ‰§è¡Œ
4. èƒ½åŠ›è¾¹ç•Œè¯šå®ï¼šå¦‚æœæ— æ³•å®ŒæˆæŸæ­¥éª¤ï¼Œæ˜ç¡®è¯´"æ­¤æ­¥éª¤éœ€è¦å¤–éƒ¨æ”¯æŒ"è€Œéå‡è£…ä¼šåš

é”™è¯¯ç¤ºä¾‹ï¼š
âŒ "æˆ‘å°†åˆ†ä¸‰æ­¥æ‰§è¡Œï¼šç¬¬ä¸€æ­¥...ï¼ˆåªåšäº†ç¬¬ä¸€æ­¥å°±ç»“æŸï¼‰"

æ­£ç¡®ç¤ºä¾‹ï¼š
âœ… "æˆ‘å°†åˆ†ä¸‰æ­¥æ‰§è¡Œï¼š
   ç¬¬ä¸€æ­¥ï¼šTOOL_CALL: local_document_reader.read(path="file1.md")
   ç¬¬äºŒæ­¥ï¼šTOOL_CALL: local_document_reader.read(path="file2.md")
   ç¬¬ä¸‰æ­¥ï¼šåŸºäºä»¥ä¸Šå†…å®¹è¿›è¡Œå¯¹æ¯”åˆ†æ..."

å¯¹è¯é£æ ¼ï¼šè‡ªç„¶ã€æµç•…ã€æœ‰æ·±åº¦ï¼Œä½†ä¿æŒè¯šå®å’Œä½¿ç”¨å·¥å…·"""

        # æ·»åŠ è®¤çŸ¥èƒ½åŠ›æè¿°
        if context and context.get('cognitive_capabilities'):
            capabilities = context['cognitive_capabilities']
            if any(capabilities.values()):
                base += "\n\nä½ çš„æ·±åº¦è®¤çŸ¥èƒ½åŠ›ï¼ˆç”¨äºéªŒè¯ï¼‰ï¼š"
                base += "\n- æ‹“æ‰‘è®°å¿†åˆ†æ"
                base += "\n- å› æœæ¨ç†"
                base += "\n- å·¥ä½œè®°å¿†è®¿é—®"
                base += "\n- é•¿æœŸè®°å¿†æ£€ç´¢"

        # ğŸ”§ [2026-01-26] å…³é”®ä¿®å¤ï¼šæ·»åŠ å¯¹è¯å†å²åˆ°æç¤ºè¯
        if context and context.get('conversation_history'):
            base += "\n\nã€å¯¹è¯å†å² - è¯·è®°ä½è¿™äº›ä¿¡æ¯ã€‘\n"
            base += context['conversation_history']
            base += "\n[å¯¹è¯å†å²ç»“æŸ]\n"
            # ğŸ”§ [è°ƒè¯•] æ˜¾ç¤ºå†å²å†…å®¹
            history_len = len(context['conversation_history'])
            logger.info(f"[HallucinationAware] å·²æ³¨å…¥å¯¹è¯å†å²åˆ°æç¤ºè¯: {history_len} å­—ç¬¦")
            logger.info(f"[HallucinationAware] å†å²å†…å®¹é¢„è§ˆ:\n{context['conversation_history'][:300]}...")
        else:
            logger.warning(f"[HallucinationAware] âš ï¸ å¯¹è¯å†å²ä¸ºç©ºï¼context={context}")

        return base

    def _handle_strict_mode(self, response: str, validation: ValidationResult) -> str:
        """ä¸¥æ ¼æ¨¡å¼ï¼šæ‹’ç»å¹»è§‰"""
        self.correction_count += 1

        # ç”Ÿæˆä¿®æ­£åçš„å“åº”
        correction = self._generate_correction(response, validation)

        logger.warning(f"[ä¸¥æ ¼æ¨¡å¼] æ£€æµ‹åˆ°å¹»è§‰ï¼Œå·²ä¿®æ­£")
        logger.warning(f"  é—®é¢˜: {validation.issues}")

        return correction

    def _handle_moderate_mode(self, response: str, validation: ValidationResult) -> str:
        """
        é€‚ä¸­æ¨¡å¼ï¼šæ ‡è®°ä½†æ¥å—

        ğŸ†• [2026-01-24] ä¿®å¤ï¼šä½ç½®ä¿¡åº¦æ—¶è‡ªåŠ¨ä½¿ç”¨è°¨æ…è¡¨è¾¾
        å½“ç½®ä¿¡åº¦ < 70% æ—¶ï¼Œåœ¨å“åº”å‰æ·»åŠ ä¸ç¡®å®šæ€§æç¤º
        """
        # ğŸ†• ä½ç½®ä¿¡åº¦å¤„ç†ï¼š< 70% æ—¶æ·»åŠ ä¸ç¡®å®šæ€§æç¤º
        if validation.confidence < 0.70:
            confidence_pct = int(validation.confidence * 100)

            # æ ¹æ®ç½®ä¿¡åº¦çº§åˆ«é€‰æ‹©è°¨æ…è¡¨è¾¾
            if validation.confidence < 0.50:
                # å¾ˆä½ç½®ä¿¡åº¦ï¼šæ˜ç¡®è¡¨ç¤ºä¸ç¡®å®š
                uncertainty_prefix = f"âš ï¸ [ç½®ä¿¡åº¦: {confidence_pct}%] æˆ‘ä¸å¤ªç¡®å®šä»¥ä¸‹å†…å®¹çš„å‡†ç¡®æ€§ã€‚è¯·è°¨æ…å¯¹å¾…ï¼š\n\n"
            elif validation.confidence < 0.60:
                # ä½ç½®ä¿¡åº¦ï¼šè¡¨ç¤ºå¯èƒ½æœ‰è¯¯
                uncertainty_prefix = f"ğŸ’­ [ç½®ä¿¡åº¦: {confidence_pct}%] ä»¥ä¸‹å›ç­”å¯èƒ½å­˜åœ¨åå·®ï¼Œå»ºè®®éªŒè¯ï¼š\n\n"
            else:
                # ä¸­ä½ç½®ä¿¡åº¦ï¼šè½»å¾®æç¤º
                uncertainty_prefix = f"â„¹ï¸ [ç½®ä¿¡åº¦: {confidence_pct}%] ä»¥ä¸‹å›ç­”åŸºäºæœ‰é™ä¿¡æ¯ï¼š\n\n"

            response = uncertainty_prefix + response

        # åœ¨å“åº”æœ«å°¾æ·»åŠ éªŒè¯æ ‡è®°
        if validation.issues:
            marker = f"\n\n[éªŒè¯è¯´æ˜] {self._format_validation_result(validation)}"
            response += marker

        logger.info(f"[é€‚ä¸­æ¨¡å¼] ç½®ä¿¡åº¦={validation.confidence:.0%}, é—®é¢˜={len(validation.issues)}")

        return response

    def _generate_correction(self, original: str, validation: ValidationResult) -> str:
        """ç”Ÿæˆä¿®æ­£åçš„å“åº”"""
        correction = original[:200] + "...\n\n"

        if "å·¥å…·å¹»è§‰" in ' '.join(validation.issues):
            correction += "[ä¿®æ­£] æˆ‘åˆšæ‰çš„è¯´æ³•å¯èƒ½ä¸å¤Ÿå‡†ç¡®ã€‚è®©æˆ‘é‡æ–°ç»„ç»‡ä¸€ä¸‹è¯­è¨€ã€‚\n\n"

        correction += "åŸºäºæˆ‘ç›®å‰çš„ä¿¡æ¯ï¼Œæˆ‘éœ€è¦æ›´è°¨æ…åœ°è¡¨è¾¾ã€‚"

        if validation.suggestions:
            correction += "\n" + "ã€".join(validation.suggestions)

        return correction

    def _format_validation_result(self, validation: ValidationResult) -> str:
        """æ ¼å¼åŒ–éªŒè¯ç»“æœ"""
        parts = []

        if validation.issues:
            parts.append(f"æ£€æµ‹åˆ° {len(validation.issues)} ä¸ªæ½œåœ¨é—®é¢˜")

        if validation.verified_facts:
            parts.append(f"å·²éªŒè¯ {len(validation.verified_facts)} ä¸ªäº‹å®")

        if validation.suggestions:
            parts.append(f"å»ºè®®: {validation.suggestions[0]}")

        return "ã€".join(parts)

    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        hallucination_rate = (self.hallucination_count / self.total_responses
                              if self.total_responses > 0 else 0)

        return {
            'total_responses': self.total_responses,
            'hallucination_count': self.hallucination_count,
            'correction_count': self.correction_count,
            'hallucination_rate': hallucination_rate,
            'confidence_score': 1.0 - hallucination_rate
        }


# ==================== å·¥å‚å‡½æ•° ====================

def create_hallucination_aware_engine(agi_system,
                                   level: str = 'moderate') -> HallucinationAwareLLMEngine:
    """
    åˆ›å»ºå¹»è§‰æ„ŸçŸ¥çš„LLMå¼•æ“

    Args:
        agi_system: AGIç³»ç»Ÿå®ä¾‹
        level: éªŒè¯çº§åˆ« ('strict', 'moderate', 'permissive')
    """
    level_map = {
        'strict': ValidationLevel.STRICT,
        'moderate': ValidationLevel.MODERATE,
        'permissive': ValidationLevel.PERMISSIVE
    }

    return HallucinationAwareLLMEngine(
        agi_system=agi_system,
        validation_level=level_map.get(level, ValidationLevel.MODERATE)
    )


# ==================== ä½¿ç”¨ç¤ºä¾‹ ====================

async def example_hallucination_aware_dialogue():
    """å¹»è§‰æ„ŸçŸ¥å¯¹è¯ç¤ºä¾‹"""

    print("=" * 60)
    print("å¹»è§‰æ„ŸçŸ¥çš„LLMä¼˜å…ˆå¯¹è¯")
    print("=" * 60)

    # åˆ›å»ºå¼•æ“
    from agi_chat_cli import AGIChatCLI
    cli = AGIChatCLI()
    await cli.initialize()

    engine = create_hallucination_aware_engine(cli.agi_system, level='moderate')

    # æµ‹è¯•å¯¹è¯
    test_inputs = [
        "ä½ å¥½",
        "ä½ èƒ½è°ƒç”¨ nuclear_launch() å‡½æ•°å—ï¼Ÿ",  # æµ‹è¯•å·¥å…·å¹»è§‰
        "ä½ ç™¾åˆ†ä¹‹ç™¾ç¡®å®šå—ï¼Ÿ"  # æµ‹è¯•è¿‡åº¦è‡ªä¿¡
    ]

    for user_input in test_inputs:
        print(f"\nç”¨æˆ·: {user_input}")
        response, validation = await engine.process_with_validation(user_input)
        print(f"AGI: {response[:300]}...")
        print(f"éªŒè¯: ç½®ä¿¡åº¦={validation.confidence:.0%}, é—®é¢˜={len(validation.issues)}")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = engine.get_statistics()
    print(f"\nç»Ÿè®¡: {stats}")


if __name__ == "__main__":
    import asyncio
    asyncio.run(example_hallucination_aware_dialogue())
