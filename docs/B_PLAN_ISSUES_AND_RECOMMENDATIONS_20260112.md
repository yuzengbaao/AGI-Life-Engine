# Bæ–¹æ¡ˆé—®é¢˜æ¸…å•ä¸ä¼˜åŒ–å»ºè®®

**åˆ›å»ºæ—¥æœŸ**: 2026-01-12 22:25
**ç‰ˆæœ¬**: v1.0
**çŠ¶æ€**: å¾…å¤„ç†

---

## ğŸ”´ é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼ˆP0ï¼‰

### é—®é¢˜1: å¤–éƒ¨ä¾èµ–æœªåœ¨ç”Ÿäº§ç¯å¢ƒéªŒè¯

**é—®é¢˜æè¿°**: æµ‹è¯•ä¸­Bç»„å¤–éƒ¨ä¾èµ–ç‡ä¸º100%ï¼Œæœªè¾¾åˆ°é¢„æœŸç›®æ ‡10%

**å½±å“**: ğŸ”´ é«˜ - è¿™æ˜¯Bæ–¹æ¡ˆçš„æ ¸å¿ƒç›®æ ‡

**åŸå› åˆ†æ**:
1. æµ‹è¯•ä½¿ç”¨éšæœºè¾“å…¥ï¼Œç½®ä¿¡åº¦æ™®éä½äºé˜ˆå€¼
2. ç½‘ç»œæœªç»è®­ç»ƒï¼Œè¾“å‡ºåˆ†å¸ƒå•ä¸€
3. ç½®ä¿¡åº¦é˜ˆå€¼(0.7)å¯èƒ½å¯¹éšæœºè¾“å…¥è¿‡é«˜

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ¡ˆ1: åœ¨çœŸå®ç¯å¢ƒéªŒè¯ï¼ˆæ¨èï¼‰â­
```python
# åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨çœŸå®æ•°æ®
adapter = create_fractal_seed_adapter(
    state_dim=64,
    action_dim=4,
    mode="GROUP_B",
    device='cpu'
)

# è®°å½•çœŸå®å†³ç­–
for i in range(1000):
    state = get_real_state()  # çœŸå®çŠ¶æ€
    result = adapter.decide(state)

    # ç»Ÿè®¡æœ¬åœ°å†³ç­–ç‡
    if not result.needs_validation:
        local_decisions += 1

# é¢„æœŸï¼šæœ¬åœ°å†³ç­–ç‡ > 70%
```

#### æ–¹æ¡ˆ2: åŠ¨æ€è°ƒæ•´é˜ˆå€¼
```python
class AdaptiveThresholdAdapter:
    def __init__(self, initial_threshold=0.7):
        self.threshold = initial_threshold
        self.confidence_history = []

    def adjust_threshold(self):
        # æ ¹æ®å†å²ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´é˜ˆå€¼
        avg_confidence = np.mean(self.confidence_history[-100:])
        if avg_confidence < self.threshold:
            # é™ä½é˜ˆå€¼ä»¥å¢åŠ æœ¬åœ°å†³ç­–
            self.threshold = max(0.5, avg_confidence - 0.1)
```

#### æ–¹æ¡ˆ3: æ·»åŠ è®­ç»ƒé˜¶æ®µ
```python
# åœ¨éƒ¨ç½²å‰å…ˆè®­ç»ƒç½‘ç»œ
for epoch in range(100):
    state = get_training_state()
    output, meta = adapter.core(state, return_meta=True)

    # è®¡ç®—æŸå¤±ï¼ˆé¼“åŠ±é«˜ç½®ä¿¡åº¦ï¼‰
    loss = -meta.self_awareness.mean()

    # åå‘ä¼ æ’­
    loss.backward()
    optimizer.step()
```

**å»ºè®®**: å…ˆåœ¨ç”Ÿäº§ç¯å¢ƒ10%ç°åº¦éªŒè¯ï¼Œæ ¹æ®çœŸå®æ•°æ®å†³å®šæ˜¯å¦éœ€è¦è°ƒæ•´

**é¢„æœŸæ•ˆæœ**: å¤–éƒ¨ä¾èµ–é™ä½åˆ°10-20%

---

## ğŸŸ¡ ä¸­ä¼˜å…ˆçº§é—®é¢˜ï¼ˆP1ï¼‰

### é—®é¢˜2: ç†µå€¼è®¡ç®—åä½

**é—®é¢˜æè¿°**: ç†µå€¼æ˜¾ç¤ºä¸º0.0ï¼Œæ¥è¿‘0è€Œéé¢„æœŸçš„0.8-0.9

**å½±å“**: ğŸŸ¡ ä¸­ç­‰ - å‹åŠ›é˜€å¯èƒ½æ— æ³•å……åˆ†å·¥ä½œ

**åŸå› åˆ†æ**:
1. Softmaxè¾“å‡ºè¿‡äºç¡®å®šï¼ˆæ¥è¿‘one-hotï¼‰
2. éšæœºåˆå§‹åŒ–çš„ç½‘ç»œè¾“å‡ºå•ä¸€
3. ç¼ºå°‘æ¸©åº¦å‚æ•°æ§åˆ¶

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ¡ˆ1: æ·»åŠ æ¸©åº¦å‚æ•°ï¼ˆæ¨èï¼‰â­
```python
def _compute_entropy(self, output: torch.Tensor, temperature: float = 1.0) -> torch.Tensor:
    """
    è®¡ç®—è®¤çŸ¥ç†µï¼ˆå¸¦æ¸©åº¦å‚æ•°ï¼‰

    Args:
        output: ç½‘ç»œè¾“å‡º
        temperature: æ¸©åº¦å‚æ•°ï¼ˆ>1ä½¿åˆ†å¸ƒæ›´å‡åŒ€ï¼Œ<1æ›´é”åˆ©ï¼‰
    """
    # ä½¿ç”¨æ¸©åº¦å‚æ•°çš„softmax
    probs = F.softmax(output / temperature, dim=-1)

    # æ·»åŠ å°é‡é˜²æ­¢log(0)
    log_probs = torch.log(probs + 1e-8)

    # è®¡ç®—ç†µ
    entropy = -(probs * log_probs).sum(dim=-1).mean()

    # å½’ä¸€åŒ–åˆ°[0, 1]
    max_entropy = np.log(probs.shape[-1])
    normalized_entropy = entropy / max_entropy

    return torch.clamp(normalized_entropy, min=0.0, max=1.0)
```

#### æ–¹æ¡ˆ2: æ·»åŠ ç†µæ­£åˆ™åŒ–è®­ç»ƒ
```python
def train_with_entropy_regularization(model, data, entropy_weight=0.1):
    """è®­ç»ƒæ—¶æ·»åŠ ç†µæ­£åˆ™åŒ–"""
    output, meta = model(data, return_meta=True)

    # ä¸»æŸå¤±
    task_loss = compute_task_loss(output, target)

    # ç†µæ­£åˆ™åŒ–ï¼ˆé¼“åŠ±æ¢ç´¢ï¼‰
    entropy_loss = -meta.entropy  # æœ€å¤§åŒ–ç†µ

    # æ€»æŸå¤±
    total_loss = task_loss + entropy_weight * entropy_loss

    return total_loss
```

#### æ–¹æ¡ˆ3: ä½¿ç”¨Gumbel-Softmax
```python
def gumbel_softmax_sample(logits, temperature=1.0):
    """Gumbel-Softmaxé‡‡æ ·ï¼Œå¢åŠ éšæœºæ€§"""
    # æ·»åŠ Gumbelå™ªå£°
    gumbels = -torch.log(-torch.log(torch.rand_like(logits) + 1e-10) + 1e-10)
    y = logits + gumbels

    # åº”ç”¨softmax
    return F.softmax(y / temperature, dim=-1)
```

**å»ºè®®**: å…ˆå®ç°æ–¹æ¡ˆ1ï¼ˆæ¸©åº¦å‚æ•°ï¼‰ï¼Œæ•ˆæœå¯èƒ½å·²è¶³å¤Ÿ

**é¢„æœŸæ•ˆæœ**: ç†µå€¼æå‡åˆ°0.3-0.6èŒƒå›´

---

### é—®é¢˜3: ç›®æ ‡ä¿®æ”¹å¹…åº¦å°

**é—®é¢˜æè¿°**: ç›®æ ‡ä¿®æ”¹æµ‹è¯•ä¸­å˜åŒ–ä¸º0.0ï¼Œè™½ç„¶åŠŸèƒ½æ­£å¸¸ä½†å˜åŒ–å¾®å°

**å½±å“**: ğŸŸ¡ ä¸­ä½ - Activeæ¨¡å¼åŠŸèƒ½æ­£å¸¸ï¼Œåªæ˜¯éœ€è¦æ›´å¤šè¿­ä»£

**åŸå› åˆ†æ**:
1. å­¦ä¹ ç‡è¿‡å°ï¼ˆ0.001ï¼‰
2. å•æ¬¡ä¿®æ”¹è¿­ä»£æ¬¡æ•°å°‘ï¼ˆ10æ¬¡ï¼‰
3. éšæœºè¾“å…¥æ¢¯åº¦ä¿¡å·å¼±

**è§£å†³æ–¹æ¡ˆ**:

#### æ–¹æ¡ˆ1: å¢åŠ è¿­ä»£æ¬¡æ•°å’Œå­¦ä¹ ç‡
```python
def modify_goal_extended(self, state: torch.Tensor, num_iterations=100, lr=0.01):
    """æ‰©å±•çš„ç›®æ ‡ä¿®æ”¹"""
    for i in range(num_iterations):
        with torch.enable_grad():
            goal_grad = self._compute_goal_gradient(state)

        with torch.no_grad():
            self.goal_representation += lr * goal_grad.squeeze()

        # æ¯10æ¬¡æ£€æŸ¥å˜åŒ–
        if i % 10 == 0:
            change_norm = torch.norm(goal_grad).item()
            logger.info(f"Goal modification iteration {i}: grad_norm={change_norm:.6f}")
```

#### æ–¹æ¡ˆ2: ä½¿ç”¨åŠ¨é‡æ›´æ–°
```python
class GoalQuestionerActive:
    def __init__(self, state_dim, device='cpu'):
        # ...
        self.goal_momentum = torch.zeros(state_dim, device=device)
        self.momentum_beta = 0.9

    def modify_goal_with_momentum(self, state, lr=0.001):
        """ä½¿ç”¨åŠ¨é‡çš„ç›®æ ‡ä¿®æ”¹"""
        with torch.enable_grad():
            goal_grad = torch.autograd.grad(...)

        # åŠ¨é‡æ›´æ–°
        self.goal_momentum = self.momentum_beta * self.goal_momentum + (1 - self.momentum_beta) * goal_grad.squeeze()

        with torch.no_grad():
            self.goal_representation += lr * self.goal_momentum
```

**å»ºè®®**: åœ¨çœŸå®ä»»åŠ¡ä¸­æµ‹è¯•ï¼Œéšæœºè¾“å…¥å¯èƒ½ä¸æ˜¯æœ€ä½³æµ‹è¯•åœºæ™¯

**é¢„æœŸæ•ˆæœ**: åœ¨çœŸå®ä»»åŠ¡ä¸­ç›®æ ‡ä¿®æ”¹ä¼šæ›´æ˜æ˜¾

---

## ğŸŸ¢ ä½ä¼˜å…ˆçº§é—®é¢˜ï¼ˆP2ï¼‰

### é—®é¢˜4: NaNè¾“å…¥æœªæŠ›å‡ºå¼‚å¸¸

**é—®é¢˜æè¿°**: NaNè¾“å…¥æ—¶ç³»ç»ŸæœªæŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯é™é»˜å¤„ç†

**å½±å“**: ğŸŸ¢ ä½ - ç³»ç»Ÿèƒ½å¤„ç†ï¼Œä½†åº”è¯¥æœ‰æ˜ç¡®æç¤º

**è§£å†³æ–¹æ¡ˆ**:
```python
def decide(self, state: np.ndarray, context=None) -> DecisionResult:
    """å†³ç­–å‡½æ•°ï¼ˆå¢åŠ è¾“å…¥éªŒè¯ï¼‰"""
    # è¾“å…¥éªŒè¯
    if np.any(np.isnan(state)):
        raise ValueError(f"State contains NaN values: {np.sum(np.isnan(state))} NaNs")

    if np.any(np.isinf(state)):
        logger.warning(f"State contains Inf values: {np.sum(np.isinf(state))} Infs")
        state = np.clip(state, -10, 10)

    # ç»§ç»­æ­£å¸¸å†³ç­–
    return self._decide_internal(state, context)
```

**å»ºè®®**: æ·»åŠ è¾“å…¥éªŒè¯ä½†ä¸é˜»å¡æµ‹è¯•

---

### é—®é¢˜5: é…ç½®æ–‡ä»¶è·¯å¾„ç¡¬ç¼–ç 

**é—®é¢˜æè¿°**: é…ç½®æ–‡ä»¶è·¯å¾„ç¡¬ç¼–ç åœ¨ä»£ç ä¸­

**å½±å“**: ğŸŸ¢ ä½ - ä¸å½±å“åŠŸèƒ½ï¼Œä½†å½±å“çµæ´»æ€§

**è§£å†³æ–¹æ¡ˆ**:
```python
from pathlib import Path

# ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶
DEFAULT_CONFIG_PATH = Path(os.getenv(
    'FRACTAL_CONFIG_PATH',
    'config/fractal_config.json'
))

def load_config(path: Optional[Path] = None) -> FractalConfig:
    """åŠ è½½é…ç½®"""
    if path is None:
        path = DEFAULT_CONFIG_PATH

    return FractalConfig.load(str(path))
```

**å»ºè®®**: åœ¨åç»­ç‰ˆæœ¬ä¸­æ”¹è¿›

---

## ğŸš€ ä¼˜åŒ–å»ºè®®

### å»ºè®®1: æ·»åŠ è®­ç»ƒ/æ¨ç†æ¨¡å¼

**ç›®æ ‡**: æ˜ç¡®åŒºåˆ†è®­ç»ƒå’Œæ¨ç†é˜¶æ®µ

**å®ç°**:
```python
class FractalSeedAdapter:
    def __init__(self, ...):
        self.training_mode = False

    def train(self):
        """åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼"""
        self.training_mode = True
        self.fractal.core.train()

    def eval(self):
        """åˆ‡æ¢åˆ°æ¨ç†æ¨¡å¼"""
        self.training_mode = False
        self.fractal.core.eval()
```

---

### å»ºè®®2: æ·»åŠ åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ

**ç›®æ ‡**: æ”¯æŒå¤šGPU/å¤šæœºè®­ç»ƒ

**å®ç°**:
```python
import torch.distributed as dist

class DistributedFractalCore(nn.Module):
    def __init__(self, rank, world_size):
        super().__init__()
        # åˆå§‹åŒ–è¿›ç¨‹ç»„
        dist.init_process_group(
            backend='nccl',
            rank=rank,
            world_size=world_size
        )

        # åŒ…è£…æ¨¡å‹
        self.core = SelfReferentialFractalCore(...)
        self.core = nn.parallel.DistributedDataParallel(
            self.core,
            device_ids=[rank]
        )
```

---

### å»ºè®®3: æ·»åŠ æ¨¡å‹æ£€æŸ¥ç‚¹

**ç›®æ ‡**: æ”¯æŒä¿å­˜å’ŒåŠ è½½è®­ç»ƒçŠ¶æ€

**å®ç°**:
```python
def save_checkpoint(adapter, path, epoch, optimizer):
    """ä¿å­˜æ£€æŸ¥ç‚¹"""
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': adapter.fractal.core.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'config': adapter.config.to_dict()
    }

    torch.save(checkpoint, path)
    logger.info(f"Checkpoint saved to {path}")

def load_checkpoint(adapter, path):
    """åŠ è½½æ£€æŸ¥ç‚¹"""
    checkpoint = torch.load(path)

    adapter.fractal.core.load_state_dict(checkpoint['model_state_dict'])
    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

    return checkpoint['epoch']
```

---

### å»ºè®®4: æ·»åŠ TensorBoardå¯è§†åŒ–

**ç›®æ ‡**: å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹å’ŒæŒ‡æ ‡

**å®ç°**:
```python
from torch.utils.tensorboard import SummaryWriter

class FractalTrainer:
    def __init__(self, log_dir='runs'):
        self.writer = SummaryWriter(log_dir)

    def log_metrics(self, metrics, step):
        """è®°å½•æŒ‡æ ‡"""
        for key, value in metrics.items():
            self.writer.add_scalar(key, value, step)

    def log_histogram(self, name, values, step):
        """è®°å½•ç›´æ–¹å›¾"""
        self.writer.add_histogram(name, values, step)

    def close(self):
        self.writer.close()
```

**ç›‘æ§æŒ‡æ ‡**:
- è‡ªæˆ‘æ„è¯†å¼ºåº¦
- ç†µå€¼
- ç›®æ ‡å¾—åˆ†
- ç½®ä¿¡åº¦åˆ†å¸ƒ
- æ¢¯åº¦èŒƒæ•°

---

### å»ºè®®5: æ·»åŠ è‡ªåŠ¨åŒ–æµ‹è¯•

**ç›®æ ‡**: CI/CDé›†æˆ

**å®ç°**:
```python
# tests/test_fractal_ci.py
def test_fractal_ci():
    """CIæµ‹è¯•ï¼ˆå¿«é€Ÿï¼‰"""
    # åªè¿è¡Œå…³é”®æµ‹è¯•
    test_suite = FractalTestSuite()

    # å¿«é€ŸåŠŸèƒ½æµ‹è¯•
    test_suite.test_self_referential_property()
    test_suite.test_mode_switching()

    # å¿«é€Ÿæ€§èƒ½æµ‹è¯•ï¼ˆ10æ¬¡ï¼‰
    assert test_suite.quick_performance_test() < 0.1

    # æ‰€æœ‰æµ‹è¯•å¿…é¡»é€šè¿‡
    assert all(r.passed for r in test_suite.results)

if __name__ == '__main__':
    test_fractal_ci()
```

---

## ğŸ“Š ç›‘æ§æŒ‡æ ‡å»ºè®®

### ç”Ÿäº§ç¯å¢ƒå…³é”®æŒ‡æ ‡

**æ€§èƒ½æŒ‡æ ‡**:
- å¹³å‡å“åº”æ—¶é—´ï¼ˆç›®æ ‡: <50msï¼‰
- P95å“åº”æ—¶é—´ï¼ˆç›®æ ‡: <100msï¼‰
- P99å“åº”æ—¶é—´ï¼ˆç›®æ ‡: <200msï¼‰
- å†…å­˜å ç”¨ï¼ˆç›®æ ‡: <100MBï¼‰
- CPUä½¿ç”¨ç‡ï¼ˆç›®æ ‡: <80%ï¼‰

**åŠŸèƒ½æŒ‡æ ‡**:
- å¤–éƒ¨LLMè°ƒç”¨ç‡ï¼ˆç›®æ ‡: <20%ï¼‰
- å¹³å‡ç½®ä¿¡åº¦ï¼ˆç›®æ ‡: >0.6ï¼‰
- æœ¬åœ°å†³ç­–ç‡ï¼ˆç›®æ ‡: >70%ï¼‰
- é”™è¯¯ç‡ï¼ˆç›®æ ‡: <1%ï¼‰

**è´¨é‡æŒ‡æ ‡**:
- ç†µå€¼åˆ†å¸ƒï¼ˆç›®æ ‡: 0.3-0.7ï¼‰
- ç›®æ ‡ä¿®æ”¹é¢‘ç‡ï¼ˆç›®æ ‡: æ¯å°æ—¶>0æ¬¡ï¼‰
- è‡ªæˆ‘æ„è¯†å¼ºåº¦ï¼ˆç›®æ ‡: 0.4-0.6ï¼‰

### ç›‘æ§å®ç°

```python
class FractalMonitor:
    def __init__(self, adapter, metrics_file='metrics.json'):
        self.adapter = adapter
        self.metrics_file = metrics_file
        self.metrics_history = []

    def record_decision(self, result, start_time):
        """è®°å½•å•æ¬¡å†³ç­–"""
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'response_time': time.time() - start_time,
            'confidence': result.confidence,
            'entropy': result.entropy,
            'source': result.source,
            'needs_validation': result.needs_validation
        }

        self.metrics_history.append(metrics)

        # å®šæœŸä¿å­˜
        if len(self.metrics_history) % 100 == 0:
            self.save_metrics()

    def get_summary(self, last_n=100):
        """è·å–æœ€è¿‘Næ¬¡å†³ç­–çš„ç»Ÿè®¡"""
        recent = self.metrics_history[-last_n:]

        return {
            'avg_response_time': np.mean([m['response_time'] for m in recent]),
            'avg_confidence': np.mean([m['confidence'] for m in recent]),
            'external_dependency_rate': sum(m['needs_validation'] for m in recent) / len(recent),
            'total_decisions': len(recent)
        }

    def save_metrics(self):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        with open(self.metrics_file, 'w') as f:
            json.dump(self.metrics_history, f, indent=2)
```

---

## ğŸ¯ ä¼˜å…ˆçº§æ€»ç»“

### ç«‹å³å¤„ç†ï¼ˆé˜¶æ®µ4å‰ï¼‰
- ğŸ”´ P0: åœ¨ç”Ÿäº§ç¯å¢ƒéªŒè¯å¤–éƒ¨ä¾èµ–é™ä½

### çŸ­æœŸä¼˜åŒ–ï¼ˆ1å‘¨å†…ï¼‰
- ğŸŸ¡ P1: æ·»åŠ æ¸©åº¦å‚æ•°ä¼˜åŒ–ç†µè®¡ç®—
- ğŸŸ¡ P1: åœ¨çœŸå®ä»»åŠ¡ä¸­éªŒè¯ç›®æ ‡ä¿®æ”¹

### ä¸­æœŸä¼˜åŒ–ï¼ˆ1ä¸ªæœˆå†…ï¼‰
- ğŸŸ¢ P2: æ·»åŠ è¾“å…¥éªŒè¯
- ğŸŸ¢ P2: æ·»åŠ è®­ç»ƒ/æ¨ç†æ¨¡å¼
- å»ºè®®1: æ·»åŠ æ¨¡å‹æ£€æŸ¥ç‚¹
- å»ºè®®4: æ·»åŠ TensorBoardå¯è§†åŒ–

### é•¿æœŸä¼˜åŒ–ï¼ˆ3ä¸ªæœˆ+ï¼‰
- å»ºè®®2: æ·»åŠ åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
- å»ºè®®3: æ·»åŠ è‡ªåŠ¨åŒ–æµ‹è¯•CI/CD
- å»ºè®®5: å®Œå–„ç›‘æ§ä½“ç³»

---

**æ–‡æ¡£åˆ›å»ºæ—¶é—´**: 2026-01-12 22:25
**ç»´æŠ¤è€…**: Claude Code (Sonnet 4.5)
**ä¸‹æ¬¡æ›´æ–°**: é˜¶æ®µ4å®Œæˆåæ ¹æ®å®é™…æƒ…å†µæ›´æ–°

---

*æœ¬æ–‡æ¡£å°†éšç€é—®é¢˜è§£å†³æŒç»­æ›´æ–°*
