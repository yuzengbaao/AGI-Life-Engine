#!/usr/bin/env python3
"""
AGI AUTONOMOUS CORE V6.1 - æ™ºèƒ½ä¿®å¤ä¸å®Œæ•´å®ç°

V6.1 æ ¸å¿ƒæ”¹è¿›ï¼š
- âœ… è‡ªåŠ¨è¯­æ³•é”™è¯¯ä¿®å¤ï¼ˆæœªç»ˆæ­¢å­—ç¬¦ä¸²ã€æ‹¬å·åŒ¹é…ï¼‰
- âœ… API æ™ºèƒ½é‡è¯•æœºåˆ¶ï¼ˆæŒ‡æ•°é€€é¿ã€é€Ÿç‡é™åˆ¶æ£€æµ‹ï¼‰
- âœ… å®Œæ•´ä»£ç ç”Ÿæˆï¼ˆä»éª¨æ¶åˆ°å®ç°ï¼‰
- âœ… é”™è¯¯æ¨¡å¼è¯†åˆ«ä¸å­¦ä¹ 
- âœ… è´¨é‡é—¨æ§ä¸è‡ªåŠ¨éªŒè¯

åŸºäº V6.0ï¼Œä¸“æ³¨äºç”Ÿäº§å¯ç”¨æ€§æå‡
"""

import asyncio
import json
import time
import os
import sys
import ast
import re
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from pathlib import Path

# Fix encoding for Windows
sys.stdout.reconfigure(encoding='utf-8', errors='replace')
os.environ['PYTHONIOENCODING'] = 'utf-8'

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
    print("[Init] Environment variables loaded")
except:
    print("[Init] dotenv not available, using system env")


class DeepSeekLLM:
    """DeepSeek LLM å®¢æˆ·ç«¯ - V6.1 å¢å¼ºç‰ˆ"""

    def __init__(self):
        self.client = None
        self.model = None
        self._init_provider()

        # V6.1 æ–°å¢ï¼šé‡è¯•é…ç½®
        self.max_retries = 2  # å‡å°‘é‡è¯•æ¬¡æ•°é¿å…é•¿æ—¶é—´ç­‰å¾…
        self.base_retry_delay = 2  # åˆå§‹å»¶è¿Ÿ 2 ç§’
        self.rate_limit_wait = 60  # é€Ÿç‡é™åˆ¶ç­‰å¾…æ—¶é—´

    def _init_provider(self):
        """Initialize DeepSeek provider"""
        try:
            import openai

            api_key = os.getenv("DEEPSEEK_API_KEY")
            if not api_key:
                print("[LLM] Warning: DEEPSEEK_API_KEY not found")
                return

            self.client = openai.AsyncOpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com/v1",
                timeout=120.0  # V6.1: å¢åŠ è¶…æ—¶åˆ° 120 ç§’ä»¥æ”¯æŒå¤§è¯·æ±‚
            )
            self.model = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")

            print(f"[LLM] DeepSeek client initialized")
            print(f"[LLM] Model: {self.model}")
            print(f"[LLM] V6.1: Smart retry enabled")

        except ImportError:
            print("[LLM] Error: openai package not installed")
        except Exception as e:
            print(f"[LLM] Error: {e}")

    async def generate(
        self,
        prompt: str,
        max_tokens: int = 8000,
        temperature: float = 0.7
    ) -> str:
        """ç”Ÿæˆå“åº” - V6.1 å¸¦æ™ºèƒ½é‡è¯•"""

        for attempt in range(self.max_retries):
            try:
                if not self.client:
                    return self._simulate_response(prompt)

                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                return response.choices[0].message.content

            except Exception as e:
                error_str = str(e).lower()

                # åˆ¤æ–­é”™è¯¯ç±»å‹
                if 'timeout' in error_str or 'connection' in error_str:
                    # ç½‘ç»œé”™è¯¯ï¼šæŒ‡æ•°é€€é¿
                    if attempt < self.max_retries - 1:
                        wait_time = self.base_retry_delay * (2 ** attempt)
                        print(f"[LLM] Connection error, waiting {wait_time}s before retry {attempt+1}/{self.max_retries}")
                        await asyncio.sleep(wait_time)
                        continue

                elif 'rate' in error_str or 'limit' in error_str:
                    # é€Ÿç‡é™åˆ¶é”™è¯¯ï¼šç­‰å¾…æ›´é•¿æ—¶é—´
                    if attempt < self.max_retries - 1:
                        print(f"[LLM] Rate limit hit, waiting {self.rate_limit_wait}s")
                        await asyncio.sleep(self.rate_limit_wait)
                        continue

                # å…¶ä»–é”™è¯¯æˆ–é‡è¯•æ¬¡æ•°ç”¨å°½
                print(f"[LLM] API error: {e}")
                if attempt == self.max_retries - 1:
                    # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
                    raise
                # ç»§ç»­ä¸‹ä¸€æ¬¡é‡è¯•
                continue

        # æ‰€æœ‰é‡è¯•å¤±è´¥
        raise Exception(f"API call failed after {self.max_retries} retries")

    def _simulate_response(self, prompt: str) -> str:
        """æ¨¡æ‹Ÿå“åº”"""
        return "# Simulated response\ndef placeholder():\n    pass"


class MultiFileBatchGenerator:
    """
    å¤šæ–‡ä»¶æ‰¹é‡ç”Ÿæˆå™¨ - V6.1 å¢å¼ºç‰ˆ

    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. è‡ªåŠ¨è¯­æ³•é”™è¯¯ä¿®å¤
    2. æ›´å®Œæ•´çš„ä»£ç å®ç°
    3. è´¨é‡é—¨æ§
    """

    def __init__(self, llm: DeepSeekLLM):
        self.llm = llm
        self.stats = {
            "files_generated": 0,
            "total_methods": 0,
            "total_batches": 0,
            "total_tokens": 0,
            "errors_fixed": 0  # V6.1 æ–°å¢
        }

    async def generate_project(
        self,
        project_description: str,
        base_dir: str
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå®Œæ•´çš„å¤šæ¨¡å—é¡¹ç›® - V6.1 å¢å¼ºç‰ˆ"""

        print(f"\n[Project] Starting multi-file project generation...")
        print(f"[Project] Base directory: {base_dir}")

        # Step 1: è§£æé¡¹ç›®ç»“æ„
        print(f"\n[Step 1] Parsing project structure...")
        modules = await self._parse_project_structure(project_description)

        if not modules:
            print(f"[Project] No modules found in description")
            return {"status": "failed", "reason": "no modules"}

        print(f"[Step 1] Found {len(modules)} modules to generate:")
        for i, module in enumerate(modules, 1):
            print(f"  {i}. {module['path']}")

        # Step 2: ä¸ºæ¯ä¸ªæ¨¡å—ç”Ÿæˆä»£ç 
        print(f"\n[Step 2] Generating modules...")
        generated_files = []

        for i, module in enumerate(modules, 1):
            print(f"\n[{i}/{len(modules)}] Generating {module['path']}...")
            print(f"  Description: {module.get('description', 'N/A')}")

            # ç”Ÿæˆå•ä¸ªæ¨¡å—
            code, methods_count, batches = await self._generate_module(
                module,
                base_dir
            )

            if code:
                # ä¿å­˜æ–‡ä»¶
                file_path = self._save_module(base_dir, module['path'], code)
                generated_files.append(file_path)

                print(f"  âœ“ Generated {methods_count} methods in {batches} batches")
                print(f"  âœ“ Saved to: {file_path}")

                self.stats["files_generated"] += 1
                self.stats["total_methods"] += methods_count
                self.stats["total_batches"] += batches
            else:
                print(f"  âœ— Failed to generate {module['path']}")

        # Step 3: éªŒè¯æ‰€æœ‰æ–‡ä»¶
        print(f"\n[Step 3] Validating all generated files...")
        validation_results = await self._validate_project(base_dir, generated_files)

        # V6.1 æ–°å¢: Step 3.5 è‡ªåŠ¨ä¿®å¤è¯­æ³•é”™è¯¯
        if not validation_results["all_valid"]:
            print(f"\n[Step 3.5] Auto-fixing syntax errors...")
            fix_results = await self._auto_fix_syntax_errors(base_dir, validation_results)

            # é‡æ–°éªŒè¯
            print(f"\n[Step 3.6] Re-validating after fixes...")
            validation_results = await self._validate_project(base_dir, generated_files)

            self.stats["errors_fixed"] = fix_results.get("fixed_count", 0)

        # Step 4: ç”Ÿæˆé¡¹ç›®å…ƒæ•°æ®
        print(f"\n[Step 4] Generating project metadata...")
        self._generate_metadata(base_dir, modules, validation_results)

        # æ‰“å°ç»Ÿè®¡
        print(f"\n{'='*70}")
        print(f"[Project] Generation Complete!")
        print(f"{'='*70}")
        print(f"Files generated: {self.stats['files_generated']}")
        print(f"Total methods: {self.stats['total_methods']}")
        print(f"Total batches: {self.stats['total_batches']}")
        print(f"Est. tokens used: {self.stats['total_tokens']}")
        print(f"Errors fixed: {self.stats['errors_fixed']}")  # V6.1
        print(f"Validation: {'âœ“ All files valid' if validation_results['all_valid'] else 'âš  Some files have issues'}")

        return {
            "status": "success",
            "files": generated_files,
            "stats": self.stats,
            "validation": validation_results
        }

    async def _parse_project_structure(self, description: str) -> List[Dict]:
        """è§£æé¡¹ç›®æè¿°ï¼Œæå–æ¨¡å—åˆ—è¡¨"""
        prompt = f"""You are analyzing a project description to identify all Python modules that need to be generated.

Project Description:
{description}

Extract ALL Python module files mentioned. For each module, identify:
1. The file path (e.g., "core/task_parser.py")
2. The purpose/description of the module

Return JSON:
{{
    "modules": [
        {{
            "path": "core/task_parser.py",
            "description": "parses natural language tasks into structured actions"
        }}
    ]
}}

IMPORTANT:
- Extract ALL modules mentioned
- Include main.py or entry points if mentioned
- Return ONLY valid JSON"""

        try:
            response = await self.llm.generate(prompt, max_tokens=2000, temperature=0.3)
            json_str = self._extract_json(response)
            data = json.loads(json_str)
            return data.get("modules", [])

        except Exception as e:
            print(f"[Parse] Error: {e}")
            # Fallback: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
            modules = []
            pattern = r'([\w/]+\.py)\s*[â€“-]\s*([^\n]+)'
            matches = re.findall(pattern, description)

            for path, desc in matches:
                modules.append({
                    "path": path.strip(),
                    "description": desc.strip()
                })

            return modules

    async def _generate_module(
        self,
        module: Dict,
        base_dir: str
    ) -> Tuple[str, int, int]:
        """ç”Ÿæˆå•ä¸ªæ¨¡å— - V6.1 å¢å¼ºç‰ˆï¼ˆæ›´å®Œæ•´çš„å®ç°ï¼‰"""

        module_path = module['path']
        description = module.get('description', '')

        # Phase 1: ç”Ÿæˆæ¨¡å—éª¨æ¶
        skeleton_prompt = f"""Generate a PRODUCTION-READY Python module for:

File: {module_path}
Purpose: {description}

Requirements:
1. Include necessary imports
2. Define class(es) with proper names
3. Add method signatures with complete docstrings
4. Use type hints for all parameters and returns
5. Include proper error handling
6. Add logging where appropriate
7. Make it production-ready

IMPORTANT: Keep method bodies as 'pass' - they will be implemented in next phase.

Output ONLY the complete Python code:"""

        skeleton_response = await self.llm.generate(skeleton_prompt, max_tokens=4000)
        skeleton = self._extract_code(skeleton_response)

        # æå–æ–¹æ³•å
        methods = re.findall(r'def\s+(\w+)\s*\(', skeleton)

        if not methods:
            print(f"  [Warning] No methods found in skeleton")
            return skeleton, 0, 0

        print(f"  [Phase 1] Skeleton: {len(methods)} methods found")

        # Phase 2: V6.1 æ”¹è¿› - åˆ†æ‰¹å®ç°æ–¹æ³•ï¼ˆæ›´å®Œæ•´çš„å®ç°ï¼‰
        implemented_code = skeleton
        implemented_methods = []
        batches = 0
        max_methods_per_batch = 3  # æ¯æ‰¹å®ç° 3 ä¸ªæ–¹æ³•

        num_batches = (len(methods) + max_methods_per_batch - 1) // max_methods_per_batch

        for batch_num in range(num_batches):
            start_idx = batch_num * max_methods_per_batch
            end_idx = min(start_idx + max_methods_per_batch, len(methods))
            batch_methods = methods[start_idx:end_idx]

            # V6.1: ç”Ÿæˆæ›´å®Œæ•´çš„æ–¹æ³•å®ç°
            batch_code = await self._implement_methods_v61(
                implemented_code,
                batch_methods,
                implemented_methods,
                module_path,
                description
            )

            if batch_code:
                implemented_code = batch_code
                implemented_methods.extend(batch_methods)
                batches += 1
                self.stats['total_tokens'] += 6000
            else:
                print(f"  [Batch {batch_num + 1}] âœ— Failed")

        return implemented_code, len(methods), batches

    async def _implement_methods_v61(
        self,
        current_code: str,
        batch_methods: List[str],
        implemented_methods: List[str],
        module_path: str,
        module_description: str
    ) -> str:
        """
        V6.1: å®ç°ä¸€æ‰¹æ–¹æ³• - ç”Ÿæˆæ›´å®Œæ•´çš„å®ç°è€Œé pass
        """

        methods_str = ", ".join(batch_methods)
        implemented_str = ", ".join(implemented_methods) if implemented_methods else "None"

        prompt = f"""You are implementing methods for module: {module_path}

Module purpose: {module_description}

Current code state (first 2000 chars):
```python
{current_code[:2000]}
```

Already implemented: {implemented_str}

Task: Implement ONLY these methods: {methods_str}

REQUIREMENTS for implementation:
1. Replace their 'pass' with ACTUAL WORKING CODE
2. Include proper error handling (try/except)
3. Add logging for important operations
4. Return appropriate values (don't return None unless meaningful)
5. Add type checking where applicable
6. Include helpful comments
7. Keep it simple but functional
8. Make it production-ready

Keep all other methods as 'pass'.
Maintain the exact same structure.

Return the FULL updated code (no markdown, no explanation):"""

        try:
            response = await self.llm.generate(prompt, max_tokens=8000, temperature=0.5)
            return self._extract_code(response)
        except Exception as e:
            print(f"  [Error] Implementation failed: {e}")
            return current_code  # è¿”å›åŸä»£ç 

    def _save_module(self, base_dir: str, module_path: str, code: str) -> str:
        """ä¿å­˜æ¨¡å—åˆ°æ–‡ä»¶"""
        full_path = os.path.join(base_dir, module_path)
        os.makedirs(os.path.dirname(full_path), exist_ok=True)

        with open(full_path, 'w', encoding='utf-8') as f:
            f.write(code)

        return full_path

    async def _validate_project(
        self,
        base_dir: str,
        files: List[str]
    ) -> Dict:
        """éªŒè¯æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶"""
        results = {
            "all_valid": True,
            "files": {}
        }

        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    code = f.read()

                ast.parse(code)

                results["files"][file_path] = {
                    "valid": True,
                    "syntax_ok": True,
                    "lines": len(code.split('\n'))
                }

            except SyntaxError as e:
                results["all_valid"] = False
                results["files"][file_path] = {
                    "valid": False,
                    "error": str(e)
                }
                print(f"  [Validation] âœ— {file_path}: {e}")

            except Exception as e:
                results["all_valid"] = False
                results["files"][file_path] = {
                    "valid": False,
                    "error": str(e)
                }
                print(f"  [Validation] âœ— {file_path}: {e}")

        return results

    # ========== V6.1 æ–°å¢: è‡ªåŠ¨è¯­æ³•é”™è¯¯ä¿®å¤ ==========

    async def _auto_fix_syntax_errors(
        self,
        base_dir: str,
        validation_results: Dict
    ) -> Dict:
        """
        V6.1: è‡ªåŠ¨ä¿®å¤è¯­æ³•é”™è¯¯

        ç­–ç•¥ï¼š
        1. æ£€æµ‹æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²
        2. è‡ªåŠ¨è¡¥å…¨å¼•å·/æ‹¬å·
        3. é‡æ–°éªŒè¯
        """
        fixed_files = []
        fix_count = 0

        for file_path, file_info in validation_results.get("files", {}).items():
            if not file_info.get("valid", True):
                error = file_info.get("error", "")

                # æ£€æµ‹æœªç»ˆæ­¢å­—ç¬¦ä¸²
                if "unterminated" in error.lower() and "string" in error.lower():
                    print(f"[Fix] Attempting to fix {file_path}")

                    try:
                        # è¯»å–æ–‡ä»¶
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()

                        # å°è¯•ä¿®å¤
                        fixed_content = self._fix_unterminated_string(content, error)

                        if fixed_content != content:
                            # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
                            with open(file_path, 'w', encoding='utf-8') as f:
                                f.write(fixed_content)

                            # é‡æ–°éªŒè¯
                            try:
                                ast.parse(fixed_content)
                                fixed_files.append(file_path)
                                fix_count += 1
                                print(f"[Fix] âœ“ Fixed: {file_path}")
                            except:
                                print(f"[Fix] âœ— Still broken: {file_path}")

                    except Exception as e:
                        print(f"[Fix] Error fixing {file_path}: {e}")

        return {
            "fixed_files": fixed_files,
            "fixed_count": fix_count
        }

    def _fix_unterminated_string(self, content: str, error: str) -> str:
        """
        V6.1: ä¿®å¤æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²

        ç­–ç•¥ï¼š
        1. æ£€æµ‹ä¸‰å¼•å·å­—ç¬¦ä¸²
        2. æ£€æµ‹ f-string
        3. è‡ªåŠ¨è¡¥å…¨
        """

        # ç­–ç•¥ 1: æ£€æµ‹ä¸‰å¼•å·å­—ç¬¦ä¸²
        if 'triple-quoted' in error:
            lines = content.split('\n')
            in_triple_string = False
            triple_char = None
            last_triple_line = -1

            for i, line in enumerate(lines):
                # æ£€æŸ¥ä¸‰å¼•å·
                if '"""' in line:
                    count = line.count('"""')
                    if count % 2 == 1:
                        in_triple_string = not in_triple_string
                        triple_char = '"""'
                        last_triple_line = i

                if "'''" in line:
                    count = line.count("'''")
                    if count % 2 == 1:
                        in_triple_string = not in_triple_string
                        triple_char = "'''"
                        last_triple_line = i

            # å¦‚æœä»ç„¶åœ¨å­—ç¬¦ä¸²ä¸­ï¼Œåœ¨æœ«å°¾æ·»åŠ é—­åˆ
            if in_triple_string and triple_char:
                content = content.rstrip() + "\n" + triple_char + "\n"

        # ç­–ç•¥ 2: æ£€æµ‹ f-string
        elif 'f-string' in error:
            lines = content.split('\n')
            for i, line in enumerate(lines):
                # ç®€å•ç­–ç•¥ï¼šæŸ¥æ‰¾æœªé—­åˆçš„ f"
                if 'f"' in line or "f'" in line:
                    # æ£€æŸ¥å¼•å·å¹³è¡¡
                    quote_count = line.count('"') + line.count("'")
                    fquote_count = line.count('f"') + line.count("f'")

                    if fquote_count > quote_count / 2:
                        # å¯èƒ½æœ‰æœªé—­åˆçš„ f-stringï¼Œåœ¨è¡Œæœ«æ·»åŠ å¼•å·
                        if line.rstrip().endswith('\\'):
                            # è¡Œæœ«æœ‰åæ–œæ ï¼Œåˆ é™¤å¹¶æ·»åŠ å¼•å·
                            lines[i] = line.rstrip()[:-1] + '"\n'
                        else:
                            lines[i] = line.rstrip() + '"\n'

            content = '\n'.join(lines)

        # ç­–ç•¥ 3: æ£€æµ‹æ™®é€šæœªé—­åˆå­—ç¬¦ä¸²
        else:
            # å°è¯•åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ ç¼ºå¤±çš„å¼•å·
            lines = content.split('\n')
            for i in range(len(lines) - 1, -1, -1):
                line = lines[i]
                # æŸ¥æ‰¾å¯èƒ½æœ‰æœªé—­åˆå­—ç¬¦ä¸²çš„è¡Œ
                if '"' in line or "'" in line:
                    # ç®€å•å¯å‘å¼ï¼šå¦‚æœè¡Œæœ«æ²¡æœ‰é€—å·æˆ–æ‹¬å·ï¼Œå¯èƒ½æœ‰æœªé—­åˆå­—ç¬¦ä¸²
                    stripped = line.strip()
                    if not stripped.endswith((',', ')', ']', '}', ':')):
                        # å°è¯•æ·»åŠ å¼•å·
                        if '"' in line and line.count('"') % 2 == 1:
                            lines[i] = line + '"'
                            break
                        elif "'" in line and line.count("'") % 2 == 1:
                            lines[i] = line + "'"
                            break

            content = '\n'.join(lines)

        return content

    # ========== ç»“æŸ V6.1 æ–°å¢ ==========

    def _generate_metadata(
        self,
        base_dir: str,
        modules: List[Dict],
        validation: Dict
    ):
        """ç”Ÿæˆé¡¹ç›®å…ƒæ•°æ®"""
        metadata = {
            "generated_at": datetime.now().isoformat(),
            "generator": "AGI_AUTONOMOUS_CORE_V6_1",
            "modules": modules,
            "validation": validation,
            "stats": self.stats
        }

        metadata_path = os.path.join(base_dir, "project_metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, default=str)

        print(f"  âœ“ Metadata saved to: {metadata_path}")

    def _extract_code(self, text: str) -> str:
        """æå–ä»£ç å—"""
        if "```python" in text:
            return text.split("```python")[1].split("```")[0].strip()
        if "```" in text:
            return text.split("```")[1].split("```")[0].strip()
        return text

    def _extract_json(self, text: str) -> str:
        """æå– JSON"""
        try:
            if "```json" in text:
                return text.split("```json")[1].split("```")[0].strip()
            if "```" in text:
                return text.split("```")[1].split("```")[0].strip()
            if "{" in text and "}" in text:
                return text[text.find("{"):text.rfind("}")+1]
            return text
        except:
            return "{}"


class AutonomousAGI_V6_1:
    """
    AGI Core V6.1 - æ™ºèƒ½ä¿®å¤ä¸å®Œæ•´å®ç°ç‰ˆæœ¬

    æ ¸å¿ƒæ”¹è¿›ï¼š
    - âœ… è‡ªåŠ¨è¯­æ³•é”™è¯¯ä¿®å¤
    - âœ… API æ™ºèƒ½é‡è¯•æœºåˆ¶
    - âœ… æ›´å®Œæ•´çš„ä»£ç å®ç°
    - âœ… é”™è¯¯æ¨¡å¼å­¦ä¹ 
    """

    def __init__(self):
        print("=" * 70)
        print("AGI AUTONOMOUS CORE V6.1 - INTELLIGENT FIX & FULL IMPLEMENTATION")
        print("=" * 70)
        print("[V6.1] Auto syntax error fixing")
        print("[V6.1] Smart API retry with exponential backoff")
        print("[V6.1] Full method implementation (not just pass)")
        print("[V6.1] Error pattern learning")
        print("=" * 70)

        self.llm = DeepSeekLLM()
        self.generator = MultiFileBatchGenerator(self.llm)
        self.memory = []
        self.step_count = 0
        self.error_patterns = {}  # V6.1: é”™è¯¯æ¨¡å¼ç»Ÿè®¡

        self.workspace = "data/autonomous_outputs_v6_1"
        os.makedirs(self.workspace, exist_ok=True)

        print(f"[Init] Workspace: {self.workspace}")
        print(f"[Init] Ready. V6.1 enhancements enabled.")
        print("=" * 70)

    async def autonomous_loop(self):
        """å®Œå…¨è‡ªä¸»å¾ªç¯ - V6.1 å¢å¼ºç‰ˆ"""
        while True:
            self.step_count += 1
            tick_time = datetime.now().strftime("%H:%M:%S")
            print(f"\n[Tick {self.step_count}] {tick_time}")
            print("-" * 70)

            try:
                # è‡ªä¸»å†³ç­–
                goal = await self._autonomous_decision()

                # æ‰§è¡Œè¡ŒåŠ¨å¹¶è·å–ç»“æœ
                action_result = None

                if goal["action"] == "create_project":
                    action_result = await self._create_project(goal)

                elif goal["action"] == "reflect":
                    action_result = await self._self_reflection()

                elif goal["action"] == "improve":
                    action_result = await self._improve_project()

                else:
                    print(f"[Action] {goal['action']}: {goal.get('reasoning', '')}")

                # è®°å½•ç»éªŒ
                self.memory.append({
                    "tick": self.step_count,
                    "goal": goal,
                    "result": action_result,
                    "timestamp": time.time()
                })

            except Exception as e:
                print(f"[Error] {e}")
                import traceback
                traceback.print_exc()

            # è‡ªä¸»èŠ‚å¥
            await asyncio.sleep(5)

    async def _autonomous_decision(self) -> Dict:
        """è‡ªä¸»å†³ç­– - V6.1 å¢å¼ºç‰ˆ"""
        context = {
            "tick": self.step_count,
            "memory_size": len(self.memory),
            "recent": self.memory[-3:] if self.memory else [],
            "error_patterns": self.error_patterns  # V6.1: ä¼ å…¥é”™è¯¯æ¨¡å¼
        }

        performance_summary = self._get_performance_summary()

        prompt = f"""You are an autonomous AGI system with self-reflection and deep reasoning capabilities (V6.1).

## Current State
- Tick: {context['tick']}
- Total Actions Taken: {context['memory_size']}

## Recent Performance Summary
{performance_summary}

## Error Patterns (V6.1)
{json.dumps(self.error_patterns, indent=2)}

## Decision Logic (Think Step-by-Step)
Before making your decision, analyze the situation:

1. **Check Previous Results**: Did the last action succeed or fail?
2. **Error Analysis**: Were there any syntax errors? Have we seen similar errors before?
3. **Quality Gate**: Does the output meet quality standards?
4. **Priority Assessment**:
   - If errors exist â†’ MUST choose "reflect" to fix them
   - If validation failed â†’ MUST choose "reflect" before creating new content
   - If all previous outputs are valid â†’ May choose "create_project" or "improve"

## Recent Actions History
{json.dumps(context['recent'], indent=2, default=str, ensure_ascii=False)}

## Instructions
- Think through this step-by-step before deciding
- Prioritize QUALITY over quantity
- Learn from error patterns
- Be honest about problems

Return JSON:
{{
    "thinking": "Your step-by-step reasoning process",
    "action": "create_project|reflect|improve",
    "reasoning": "Brief explanation",
    "confidence": 0.0-1.0,
    "project_description": "Detailed project description (only if action=create_project)"
}}"""

        try:
            response = await self.llm.generate(prompt, temperature=0.3, max_tokens=2000)
            decision = json.loads(self._extract_json(response))

            print(f"\n[Decision Thought Process]")
            print(f"{decision.get('thinking', 'N/A')}\n")
            print(f"[Decision] {decision['action']}: {decision.get('reasoning', '')}")
            print(f"[Confidence] {decision.get('confidence', 0.0)}")

            return decision

        except Exception as e:
            print(f"[Error] Decision failed: {e}")
            return {
                "thinking": "Decision system encountered error, need to reflect",
                "action": "reflect",
                "reasoning": "Error in decision process, switching to reflection mode",
                "confidence": 0.5
            }

    async def _create_project(self, goal: Dict) -> Dict:
        """åˆ›å»ºå¤šæ¨¡å—é¡¹ç›® - V6.1"""
        output_id = f"project_{int(time.time())}"
        output_dir = os.path.join(self.workspace, output_id)

        project_desc = goal.get("project_description", "")

        print(f"\n[Project] Output ID: {output_id}")
        print(f"[Project] Description: {project_desc[:150]}...")

        # ç”Ÿæˆé¡¹ç›®ï¼ˆV6.1 ä¼šè‡ªåŠ¨ä¿®å¤é”™è¯¯ï¼‰
        result = await self.generator.generate_project(project_desc, output_dir)

        # ä¿å­˜ç»“æœ
        result_file = os.path.join(output_dir, "generation_result.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, default=str)

        print(f"\n[Result] Project saved to: {output_dir}")

        return {
            "status": result.get("status", "unknown"),
            "output_id": output_id,
            "output_dir": output_dir,
            "files_generated": result.get("stats", {}).get("files_generated", 0),
            "validation": result.get("validation", {}),
            "stats": result.get("stats", {})
        }

    async def _self_reflection(self) -> Dict:
        """è‡ªæˆ‘åæ€ - V6.1 å¢å¼ºç‰ˆï¼ˆåŒ…å«é”™è¯¯æ¨¡å¼åˆ†æï¼‰"""

        print(f"\n[Reflection] Analyzing performance...")

        # ç»Ÿè®¡é¡¹ç›®
        total_projects = len([m for m in self.memory if m.get('goal', {}).get('action') == 'create_project'])
        print(f"[Reflection] Total projects created: {total_projects}")

        # åˆ†ææœ€è¿‘çš„é”™è¯¯
        issues = []
        for mem in self.memory[-3:]:
            result = mem.get('result', {})
            validation = result.get('validation', {})

            if not validation.get('all_valid', True):
                files = validation.get('files', {})
                for file_path, file_info in files.items():
                    if not file_info.get('valid', True):
                        error = file_info.get('error', 'Unknown error')
                        issues.append({
                            'tick': mem['tick'],
                            'file': file_path,
                            'error': error
                        })

                        # V6.1: ç»Ÿè®¡é”™è¯¯æ¨¡å¼
                        self._update_error_patterns(error)

        if issues:
            print(f"[Reflection] Found {len(issues)} issues:")
            for issue in issues:
                print(f"  - Tick {issue['tick']}: {issue['file']}")
                print(f"    Error: {issue['error'][:100]}...")

            return {
                "status": "issues_found",
                "issues_count": len(issues),
                "issues": issues[:5],
                "error_patterns": self.error_patterns  # V6.1
            }
        else:
            print(f"[Reflection] No issues found in recent outputs")
            return {
                "status": "no_issues",
                "total_projects": total_projects
            }

    def _update_error_patterns(self, error: str):
        """V6.1: æ›´æ–°é”™è¯¯æ¨¡å¼ç»Ÿè®¡"""
        error_lower = error.lower()

        # æå–é”™è¯¯ç±»å‹
        if 'unterminated' in error_lower and 'string' in error_lower:
            error_type = 'unterminated_string'
        elif 'indent' in error_lower:
            error_type = 'indentation'
        elif 'syntax' in error_lower:
            error_type = 'syntax_error'
        else:
            error_type = 'other'

        # æ›´æ–°è®¡æ•°
        self.error_patterns[error_type] = self.error_patterns.get(error_type, 0) + 1

    async def _improve_project(self) -> Dict:
        """æ”¹è¿›é¡¹ç›®"""
        print(f"\n[Improve] Scanning for previous projects...")

        project_memories = [m for m in self.memory if m.get('goal', {}).get('action') == 'create_project']

        if not project_memories:
            print(f"[Improve] No projects found to improve")
            return {"status": "no_projects"}

        last_project = project_memories[-1]
        output_dir = last_project.get('result', {}).get('output_dir', '')

        print(f"[Improve] Last project: {output_dir}")

        return {
            "status": "improvement_noted",
            "target_project": output_dir
        }

    def _get_performance_summary(self) -> str:
        """è·å–æ€§èƒ½æ‘˜è¦ - V6.1 å¢å¼º"""
        if not self.memory:
            return "No previous actions yet. This is your first action."

        last_action = self.memory[-1]
        goal = last_action.get('goal', {})
        result = last_action.get('result', {})

        summary_lines = []
        summary_lines.append(f"Last Action: {goal.get('action', 'unknown')}")

        if result:
            status = result.get('status', 'unknown')
            summary_lines.append(f"Status: {status}")

            if goal.get('action') == 'create_project':
                files_gen = result.get('files_generated', 0)
                summary_lines.append(f"Files Generated: {files_gen}")

                validation = result.get('validation', {})
                if not validation.get('all_valid', True):
                    files = validation.get('files', {})
                    invalid_count = sum(1 for f in files.values() if not f.get('valid', True))
                    summary_lines.append(f"Validation: âŒ {invalid_count} file(s) with errors")

                    for file_path, file_info in files.items():
                        if not file_info.get('valid', True):
                            error = file_info.get('error', 'Unknown error')
                            summary_lines.append(f"  - {file_path}")
                            summary_lines.append(f"    Error: {error[:80]}...")
                else:
                    summary_lines.append(f"Validation: âœ… All files valid")

                # V6.1: æ˜¾ç¤ºä¿®å¤ç»Ÿè®¡
                stats = result.get('stats', {})
                errors_fixed = stats.get('errors_fixed', 0)
                if errors_fixed > 0:
                    summary_lines.append(f"Errors Auto-Fixed: {errors_fixed} ğŸ”§")

        return "\n".join(summary_lines)

    def _extract_json(self, text: str) -> str:
        """æå– JSON"""
        try:
            if "```json" in text:
                return text.split("```json")[1].split("```")[0].strip()
            if "```" in text:
                return text.split("```")[1].split("```")[0].strip()
            if "{" in text and "}" in text:
                return text[text.find("{"):text.rfind("}")+1]
            return text
        except:
            return "{}"


if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸš€ AGI AUTONOMOUS CORE V6.1 - STARTING")
    print("="*70)
    print("\nKey Improvements:")
    print("  âœ… Auto syntax error fixing")
    print("  âœ… Smart API retry (exponential backoff)")
    print("  âœ… Full method implementation")
    print("  âœ… Error pattern learning")
    print("\n" + "="*70 + "\n")

    agi = AutonomousAGI_V6_1()
    asyncio.run(agi.autonomous_loop())
